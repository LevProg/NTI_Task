{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "onti_ai_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "de1-Sq6Fgy7n",
        "outputId": "913c4469-bd42-437e-877c-64d620ce8a6c"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: GeForce GTX 1080 Ti\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtruWYwHCJ6Q",
        "outputId": "e7855e59-28ea-4da7-949d-4c45984006bf"
      },
      "source": [
        "!wget https://onti2020.ai-academy.ru/task/rucos_val.jsonl\n",
        "!wget https://onti2020.ai-academy.ru/task/rucos_test.jsonl\n",
        "!wget https://onti2020.ai-academy.ru/task/rucos_train.jsonl.zip\n",
        "!unzip rucos_train.jsonl.zip -d ./\n",
        "\n",
        "!rm rucos_train.jsonl.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
            "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
            "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
            "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
            "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
            "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
            "\"unzip\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
            "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
            "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
            "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SJqbuV1CkFu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtZIEQkwCp_t"
      },
      "source": [
        "import json\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "FEATURES_COUNT = 190\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    \n",
        "    pattern = '\\(\\d+\\)'\n",
        "    text = re.sub(pattern, '', text)\n",
        "\n",
        "    text = text.replace('\\xad', ' ')\n",
        "    text = text.replace('\\u00ad', ' ')\n",
        "    text = text.replace('\\N{SOFT HYPHEN}', ' ')\n",
        "    text = text.replace(\"\\n@highlight\\n\", ' ')\n",
        "    text = text.replace(\"\\n@placeholder\\n\", ' ')\n",
        "\n",
        "    text = text.replace('«', ' ')\n",
        "    text = text.replace('»', ' ')  \n",
        "    text = text.replace('...', ' ') \n",
        "    text = text.replace('—', ' ') \n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def text_splitter(text, amount=FEATURES_COUNT): \n",
        "    tokens = clean_text(text).split(' ')\n",
        "    new_text = ' '.join(tokens[-amount:])\n",
        "    return new_text\n",
        "\n",
        "def get_X_y_for_bert(data_json_file):\n",
        "    X, y = [], []\n",
        "    with open(data_json_file, 'r', encoding='utf8') as json_file:\n",
        "        json_list = list(json_file)\n",
        "        for json_str in tqdm(json_list):\n",
        "            item = json.loads(json_str)\n",
        "            text = item['passage']['text']\n",
        "            query = item['qas'][0]['query']\n",
        "            ans = item['passage']['entities']\n",
        "\n",
        "            right_answers = []\n",
        "            for elem in item['qas'][0]['answers']:\n",
        "                right_answers.append(elem['text'])\n",
        "\n",
        "            for a in ans:\n",
        "                X.append('[CLS] '+ (text_splitter(query+' '+ ' textquestionseparator '+text)).replace('textquestionseparator', '[SEP]').replace('placeholder', item['passage']['text'][a['start']:a['end']]))\n",
        "                y.append(1 if item['passage']['text'][a['start']:a['end']] in right_answers else 0)\n",
        "    return X, y\n",
        "\n",
        "def get_X(data_json_file):\n",
        "    X = []\n",
        "    with open(data_json_file, 'r', encoding='utf8') as json_file:\n",
        "        json_list = list(json_file)\n",
        "        for json_str in tqdm(json_list):\n",
        "            item = json.loads(json_str)\n",
        "            text = item['passage']['text']\n",
        "            query = item['qas'][0]['query']\n",
        "            ans = item['passage']['entities']\n",
        "            for a in ans:\n",
        "                X.append('[CLS] '+ (text_splitter(query+' '+ ' textquestionseparator '+text)).replace('textquestionseparator', '[SEP]').replace('placeholder', item['passage']['text'][a['start']:a['end']]))\n",
        "                \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSokd2XkGTwW",
        "colab": {
          "referenced_widgets": [
            "e6ace8a1f9344c55b5e4a0c4b87bfd04",
            "13aa0739a0244fc6b972350c1e910203",
            "a79acfa38d124108b80bffaaf7c278c8"
          ]
        },
        "outputId": "de75bca5-d545-4d4f-b746-75e3ee8f08f5"
      },
      "source": [
        "X_train, y_train = get_X_y_for_bert('rucos_train.jsonl')\n",
        "X_valid, y_valid = get_X_y_for_bert('rucos_val.jsonl')\n",
        "X_test = get_X('rucos_test.jsonl') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6ace8a1f9344c55b5e4a0c4b87bfd04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=72193.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13aa0739a0244fc6b972350c1e910203",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7577.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a79acfa38d124108b80bffaaf7c278c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7257.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcFMKyLkJAzg",
        "outputId": "47153f5e-f69d-4f0a-d3f9-18b09fdd5c65"
      },
      "source": [
        "print(len(X_train), len(X_valid), len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "918625 108749 96996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZsPA_zEXR2p",
        "outputId": "9159cc02-a174-4af7-a2b1-ff1b7395f8d1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.3.3)\n",
            "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (2020.10.15)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzkRAxePXMG5",
        "outputId": "88303309-2257-4c13-a013-6fa7ab68230c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh1sK6SoXZ15",
        "outputId": "e1041ad0-7eae-4f7a-88cf-408a763e577c"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', X_train[100])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(X_train[100]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X_train[100])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  [CLS] разговаривала с журналистами с позиции силы но теперь с журналистами будут вести переговоры еще меньше а больше будут пытаться воздействовать силовым нажимом  отметил касютин  [SEP] инциденты с радиостанцией эхо москвы и телеканалом дождь стали поводом говорить о попытках власти оказать давление на прессу накануне президентских выборов в россии эксперты считают что пора бить тревогу последние события происходящие вокруг российских сми в частности изменения в руководстве радиостанции эхо москвы которые на этой неделе инициировал главный акционер  холдинг газпроммедиа дали повод для разговоров о попытках власти задушить оппозиционные сми в россии связанные одной цепью\n",
            "президент фонда защиты гласности член совета при президенте россии по содействию развитию гражданского общества и правам человека алексей симонов видит взаимосвязь событий происходящих в сми в большинстве конфликтов одной из сторон выступал холдинг газпроммедиа и все они происходили незадолго до или сразу после выборов отчетливо и ясно видно что газпром дал команду своим стреножить свои усилия в преддверии выборов  заявил симонов в интервью dw в швеции задержаны двое граждан рф в связи с нападением на чеченского блогера туризм в эпоху коронавируса куда поехать и ехать ли вообще комментарий россия накануне эпидемии  виноватые назначены заранее\n",
            "Tokenized:  ['[CLS]', 'раз', '##гов', '##ари', '##вала', 'с', 'журналист', '##ами', 'с', 'позиции', 'силы', 'но', 'теперь', 'с', 'журналист', '##ами', 'будут', 'вести', 'пер', '##еговоры', 'еще', 'меньше', 'а', 'больше', 'будут', 'п', '##ыта', '##ться', 'во', '##зд', '##еи', '##ствовать', 'сил', '##овым', 'на', '##жим', '##ом', 'от', '##метил', 'ка', '##сю', '##тин', '[SEP]', 'ин', '##ци', '##дент', '##ы', 'с', 'радио', '##стан', '##ци', '##еи', 'э', '##хо', 'м', '##ос', '##квы', 'и', 'теле', '##кана', '##лом', 'до', '##ж', '##дь', 'стали', 'пов', '##одом', 'говорить', 'о', 'поп', '##ыт', '##ках', 'власти', 'ок', '##аза', '##ть', 'дав', '##ление', 'на', 'пре', '##сс', '##у', 'на', '##кан', '##уне', 'президент', '##ских', 'выборов', 'в', 'рос', '##сии', 'э', '##кс', '##пер', '##ты', 'считают', 'что', 'пор', '##а', 'бит', '##ь', 'т', '##рев', '##огу', 'последние', 'события', 'про', '##ис', '##ход', '##ящие', 'вокруг', 'рос', '##сии', '##ских', 'см', '##и', 'в', 'частности', 'изменения', 'в', 'рук', '##ово', '##д', '##стве', 'радио', '##стан', '##ции', 'э', '##хо', 'м', '##ос', '##квы', 'которые', 'на', 'это', '##и', 'не', '##дел', '##е', 'ин', '##ици', '##ировал', 'гл', '##ав', '##ны', '##и', 'а', '##к', '##цио', '##нер', 'х', '##ол', '##дин', '##г', 'газ', '##про', '##м', '##мед', '##иа', 'дали', 'пов', '##од', 'для', 'раз', '##говор', '##ов', 'о', 'поп', '##ыт', '##ках', 'власти', 'за', '##ду', '##шить', 'о', '##п', '##по', '##зици', '##он', '##ные', 'см', '##и', 'в', 'рос', '##сии', 'св', '##язан', '##ные', 'одно', '##и', 'це', '##п', '##ью', 'президент', 'фонда', 'защиты', 'гл', '##ас', '##ности', 'член', 'совета', 'при', 'президент', '##е', 'рос', '##сии', 'по', 'со', '##де', '##ист', '##ви', '##ю', 'развитию', 'граждан', '##ского', 'общества', 'и', 'права', '##м', 'человека', 'але', '##кс', '##еи', 'си', '##мон', '##ов', 'види', '##т', 'в', '##за', '##имо', '##с', '##вя', '##зь', 'со', '##бы', '##тии', 'про', '##ис', '##ход', '##ящих', 'в', 'см', '##и', 'в', 'большинстве', 'конфликт', '##ов', 'одно', '##и', 'из', 'сторон', 'выступал', 'х', '##ол', '##дин', '##г', 'газ', '##про', '##м', '##мед', '##иа', 'и', 'все', 'они', 'про', '##ис', '##ходили', 'не', '##за', '##долго', 'до', 'или', 'сразу', 'после', 'выборов', 'от', '##чет', '##ливо', 'и', 'ясно', 'вид', '##но', 'что', 'газ', '##про', '##м', 'дал', 'команду', 'своим', 'стр', '##ено', '##жить', 'свои', 'у', '##сили', '##я', 'в', 'пред', '##д', '##вер', '##ии', 'выборов', 'заявил', 'си', '##мон', '##ов', 'в', 'интервью', 'd', '##w', 'в', 'ш', '##ве', '##ции', 'за', '##дер', '##жаны', 'двое', 'граждан', 'р', '##ф', 'в', 'связи', 'с', 'напад', '##ением', 'на', 'че', '##чен', '##ского', 'б', '##лог', '##ера', 'тур', '##изм', 'в', 'эпоху', 'кор', '##она', '##ви', '##рус', '##а', 'куда', 'по', '##ех', '##ать', 'и', 'еха', '##ть', 'ли', 'вообще', 'ко', '##м', '##мента', '##рии', 'рос', '##сия', 'на', '##кан', '##уне', 'э', '##пи', '##дем', '##ии', 'ви', '##нова', '##тые', 'назначен', '##ы', 'за', '##ране', '##е']\n",
            "Token IDs:  [101, 17257, 47204, 30090, 18046, 558, 59083, 12040, 558, 37714, 36963, 11279, 53243, 558, 59083, 12040, 52018, 59568, 61381, 108140, 72284, 68340, 541, 26368, 52018, 556, 86360, 14133, 10439, 62594, 36694, 76183, 23970, 42623, 10122, 101509, 10364, 10332, 78504, 56280, 105391, 25111, 102, 27796, 12012, 87161, 10292, 558, 31383, 23544, 12012, 36694, 570, 42940, 553, 17969, 65930, 549, 63721, 66317, 22089, 10344, 12025, 41237, 17465, 30148, 89332, 90526, 555, 48138, 51786, 20265, 21059, 40936, 34402, 11258, 95555, 20539, 10122, 38494, 33649, 10227, 10122, 17343, 86622, 27419, 12445, 64748, 543, 28171, 28445, 570, 18705, 29633, 12202, 96044, 10791, 41436, 10179, 97367, 10851, 559, 110442, 67456, 52419, 72764, 12709, 19120, 23089, 84216, 48181, 28171, 28445, 12445, 16541, 10191, 543, 27184, 51436, 543, 84043, 20007, 10746, 18746, 31383, 23544, 12559, 570, 42940, 553, 17969, 65930, 14028, 10122, 12999, 10191, 10375, 44030, 10205, 27796, 29297, 57542, 55367, 18197, 11307, 10191, 541, 10510, 86228, 28588, 562, 17010, 21657, 10823, 44352, 104082, 10241, 43300, 97843, 51483, 30148, 16625, 10520, 17257, 35153, 10433, 555, 48138, 51786, 20265, 21059, 10234, 15986, 61260, 555, 11078, 53204, 92522, 11579, 11194, 16541, 10191, 543, 28171, 28445, 37629, 93833, 11194, 41543, 10191, 15725, 11078, 27025, 27419, 92936, 51599, 55367, 18291, 15742, 16960, 30751, 10913, 27419, 10205, 28171, 28445, 10297, 10956, 12265, 24142, 13791, 10593, 97071, 77879, 11184, 27089, 549, 17319, 10241, 18035, 13166, 18705, 36694, 12662, 38902, 10433, 48304, 10351, 543, 13594, 106502, 10513, 84322, 42366, 10956, 18766, 59936, 12709, 19120, 23089, 56062, 543, 16541, 10191, 543, 101653, 86027, 10433, 41543, 10191, 10387, 90193, 36206, 562, 17010, 21657, 10823, 44352, 104082, 10241, 43300, 97843, 549, 13686, 14274, 12709, 19120, 88010, 10375, 13594, 91958, 10344, 10880, 41198, 11921, 64748, 10332, 54697, 49256, 549, 96947, 16133, 10636, 10791, 44352, 104082, 10241, 53213, 24539, 28365, 19240, 14781, 36760, 22003, 560, 94041, 10385, 543, 23807, 10746, 32418, 11905, 64748, 51633, 12662, 38902, 10433, 543, 64553, 172, 10874, 543, 565, 14149, 12559, 10234, 22605, 97331, 109037, 77879, 557, 13582, 543, 18940, 558, 78417, 50765, 10122, 14816, 16580, 11184, 542, 22141, 14961, 52049, 58493, 543, 88253, 80062, 14614, 13791, 39401, 10179, 68734, 10297, 44011, 18235, 549, 70841, 11258, 33190, 86860, 59781, 10241, 57772, 23502, 28171, 25269, 10122, 17343, 86622, 570, 20785, 109566, 11905, 88504, 36481, 41600, 20829, 10292, 10234, 36035, 10205]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFWr674ddFxD"
      },
      "source": [
        "def tokenize_texts(sentences):\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in tqdm(sentences):\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 512,           # Pad & truncate all sentences.\n",
        "                          #pad_to_max_length = True,\n",
        "                          padding='max_length',\n",
        "                          truncation=True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                          \n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  # Print sentence 0, now as a list of IDs.\n",
        "  print('Original: ', sentences[0])\n",
        "  print('Token IDs:', input_ids[0])\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAMNKNUXdM1U",
        "colab": {
          "referenced_widgets": [
            "fffb1183abf7426381ecbb2f7be723e5",
            "8a1c57250ad64ea4acf23545ffb859c2"
          ]
        },
        "outputId": "2aa705fc-e911-43ce-ac76-59af2e4406b5"
      },
      "source": [
        "X_train, X_train_masks = tokenize_texts(X_train)\n",
        "X_valid, X_valid_masks = tokenize_texts(X_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fffb1183abf7426381ecbb2f7be723e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=918625.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:  [CLS] кроме того серьезным вызовом для россии становится стремительно развивающийся китайеще в понедельник Домодедово в рамках спора о системе противоракетной обороны пригрозил размещением дополнительных ракетных комплексов  [SEP] наблюдатели полагают что подоплекой теракта в домодедово является провал кавказской политики российского правительства указывает немецкая печать немецкая печать продолжает комментировать теракт в домодедово так газета süddeutsche zeitung пишет\n",
            "ну конечно же после взрыва в домодедово вновь обнаруживается кавказский след его обнаруживают почти всегда когда в россии взрывается бомба в метро в поезде или на рынке и неважно что очевидцы нередко не в состоянии сказать был ли преступник женщиной в чадре или же мужчиной грозившим всех уничтожитьсреди жертв взрыва в домодедово есть граждане германии великобритании австрии ежедневно в москве совершают посадку более 3 десятков самолетов из германии немецкий менеджер аэропорта домодедово отвергает обвинения медведева теракт в домодедово системные просчеты комментарий провал российских спецслужб\n",
            "Token IDs: tensor([   101,  37213,  12409,  10277,  28301,  32934,  11692,  96195, 105098,\n",
            "         10241,  10520,  28171,  28445,  35970,  19240,  45307,  34136,  17257,\n",
            "         81251,  10593,  19682,  50092,  66991,  35912,  10205,  20904,    543,\n",
            "         10297,  10695,  70835,  11718,  21487,  82562,  30470,  10316,    543,\n",
            "         26062,    558,  60045,    555,  44914,  13488,  19553, 100176,  10636,\n",
            "         10191,  36812,  10913,  63596,  69914,  10517,  61002,  10241,  38300,\n",
            "         17010,  13862,  18737, 105560,  10970,  30592,  10433,    102,  10122,\n",
            "         61394,  94811,  24306,  80299,  11347,  13714,  10791,  11429,  58056,\n",
            "         30150,  26891,  13613,  28397,  10367,    543,  21487,  82562,  30470,\n",
            "         10316,  13414,  12709,  18979,  56280,  26198,  11571,  13566,  10191,\n",
            "         56325,  28171,  28445,  11184,  42471,  51941,  85815,  17213,  71961,\n",
            "           556, 106173,  11258,  17213,  71961,    556, 106173,  11258,  12709,\n",
            "         17961,  50856,  25471,  59781,  10241,  83630,  34234,  13613,  28397,\n",
            "         10351,    543,  21487,  82562,  30470,  10316,  12123,  38459,  11660,\n",
            "         70920,  10941,  36349,  76580,    554,  10227,  33023,  75051,  11815,\n",
            "         11921,    543,  11571,  84113,    543,  21487,  82562,  30470,  10316,\n",
            "         25698,  13248,  37235,  10227,  43764,  10625,  56280,  26198,  11571,\n",
            "         11434,  10191,  16246,  10933,  13248,  37235,  10227,  80629,  21797,\n",
            "         41073,  15283,    543,  28171,  28445,    543,  11571,  97794,  18481,\n",
            "        102644,    543,  60678,    543,  10297,  92686,  10880,  10122,    557,\n",
            "         12119,  11557,    549,  10375,  10852,  24751,  10791,    555,  32702,\n",
            "         22415,  12993,  10375, 104365,  10375,    543,  63631,    558,  41710,\n",
            "         18235,  10702,  33190,  38494,  63649,  11718,  24828,  26891,    543,\n",
            "           564,  20004,  14348,  10880,  11815,  29105,  26891,  55895,  69914,\n",
            "         83087,  16989,  68725,  18669,  10752,  36760,  10513,  63796, 103914,\n",
            "           543,  11571,  84113,    543,  21487,  82562,  30470,  10316,  17622,\n",
            "         77879,  10205,  65100,  52217,  11905,  75844,  11623,  37950, 101740,\n",
            "         10191,    541,  10541,  76727,  10191,    546,  15920,  10746,  10695,\n",
            "         24055,    543,    553,  17969,  10510,  14149,  98903,  11977,  13235,\n",
            "         13714,  10297,  75277,  11191,  13106,    124,  11323,  83125,  13036,\n",
            "         14847,  35025,  10433,  10387,  65100,  52217,  11905,  17213, 106072,\n",
            "         11905,  13667,  31742,  73739,  88867,  10179,  21487,  82562,  30470,\n",
            "         10316,  10332,  32418,  92013,  13248,  69913,  12268,    553,  31742,\n",
            "         76051,  10852,  13613,  28397,  10351,    543,  21487,  82562,  30470,\n",
            "         10316,  21297,  11194,  12709,  10513,  54697,  10292,  59781,  10241,\n",
            "         57772,  23502,  12709,  18979,  28171,  28445,  12445,    558,  19820,\n",
            "         12181,  87098,  12025,  12528,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a1c57250ad64ea4acf23545ffb859c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108749.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:  [CLS] в него вошли ООН россия украина и франция  [SEP] главной темой переговоров наряду с прежними спорными вопросами такими как отвод тяжелых вооружений и сохранение перемирия станет организация миротворческой миссии оон для донбасса header инициатива главы германского мида\n",
            "с инициативой собрать глав внешнеполитических ведомств стран нормандского формата в берлине выступил министр иностранных дел германии хайко мас heiko maas во время своего визита в украину находясь в мариуполе куда он приехал чтобы составить собственное впечатление о ситуации на востоке украины мас выразил надежду что на встрече которая пройдет после 15месячного перерыва удастся вдохнуть новую жизнь в процесс урегулирования войны в донбассе путин говорит порусски на переговорах в нормандском формате чтобы показать силу на самом же деле он демонстрирует одиночество в этой четверке считает политолог иван преображенский \n",
            "по словам маса главной темой переговоров наряду с прежними спорными вопросами такими как отвод тяжелых вооружений и сохранение перемирия станет организация миротворческой миссии оон для донбасса в германии за сутки выявлено более 100 новых заражений коронавирусом тысячи демонстрантов в гамбурге выступили за прием беженцев комментарий россия накануне эпидемии  виноватые назначены заранее\n",
            "Token IDs: tensor([   101,    543,  13981,  58557,    555,  11579,  28171,  25269,  20594,\n",
            "         35912,  10409,    549,  56596,  11502,    102,  69663,  10191,  19710,\n",
            "         26891,  61381,  69417,  73433,  82097,    558,  38494,  85307,  10191,\n",
            "           558,  42393,  14350,  67177,  10191,  56317,  10949,  10332,  45597,\n",
            "         37813,  15920,  56554,  10439,  32579,  35557,    549,  10956,  10353,\n",
            "        110511,  61381,  45307,  20110,  64698,  10351,  41317,  29345,  11016,\n",
            "         29973,  53562,  10191,  37140,  54243,    555,  11579,  10520,  10344,\n",
            "         10267,  91680,  12016,  13578,  10165,  27796,  29297,  16583,  10852,\n",
            "         82521,  65100,  52217,  11184,  37140,  10987,    558,  27796,  29297,\n",
            "         16583,  15275,  10191,  10956,  82045,  55367,  18197, 103072,  92954,\n",
            "         53204,  72020,  21871,    543,  31742,  10364,  19021,  32619, 110663,\n",
            "         16821,  11184, 100713,    543,  23845,  40913,  63155,  46661,  53813,\n",
            "         17497,  65100,  52217,  11905,    562,  35912,  11623,  97744,  10513,\n",
            "         10261,  18924,  49123,  10107,  10439,  11657,  18613,  88504, 107156,\n",
            "         10179,    543,  20594,  35912,  11752,  10122,  23089,  39269,    543,\n",
            "         97744,  11777,  53190,  64724,  68734,  11060,  10913,  60366,  15692,\n",
            "         13701,  15356,  10956,  12528,  57160,    543,  19820,  48579,  20539,\n",
            "           555,  81329,  10122,  38860,  20594,  35912,  11307,  97744,  10513,\n",
            "         96195,  90402,  12614,  49867,  15986,  10791,  10122,    543,  52685,\n",
            "         63077,  16510,  12709,  22415,  11613,  11921,  10208,  14689,  10625,\n",
            "         18088,  61381,  39490,  10852,    560,  10987,  11567,  10625,    543,\n",
            "         17961,  10353,  46769,  61554,  27264,    543,  45234,    560,  14348,\n",
            "         15528,  10783,  32875,  10439,  34652,    543,  10344,  10267,  91680,\n",
            "         13110,  35874,  10267,  53423,  41436,  19954,  11434,  10122,  61381,\n",
            "         69417, 106635,    543, 110663,  16821,  12154,  62762,  15692,  45899,\n",
            "         13594,  11258,  34145,  10122,  34086,  11815,  53930,  11060,  11323,\n",
            "         38902,  76727,  44179,  13713,  67741,  12232,    543,  12999,  10191,\n",
            "         14816,  35795,  91465,  84370,  23750,  39609,  22141,    549,  20427,\n",
            "         38494,  33276,  11079,  23855,  11434,  10191,  10297,  47510,  38782,\n",
            "         69663,  10191,  19710,  26891,  61381,  69417,  73433,  82097,    558,\n",
            "         38494,  85307,  10191,    558,  42393,  14350,  67177,  10191,  56317,\n",
            "         10949,  10332,  45597,  37813,  15920,  56554,  10439,  32579,  35557,\n",
            "           549,  10956,  10353, 110511,  61381,  45307,  20110,  64698,  10351,\n",
            "         41317,  29345,  11016,  29973,  53562,  10191,  37140,  54243,    555,\n",
            "         11579,  10520,  10344,  10267,  91680,  12016,    543,  65100,  52217,\n",
            "         11905,  10234,  10587,  23350,  96195,  51642,  25765,  13106,  10407,\n",
            "         31986,  10234,  11079,  35557,  80062,  14614,  13791,  39401,  10364,\n",
            "         59263,  11323,  38902,  34298,  41335,    543,  16616,  10241,  20928,\n",
            "         10205,  63155,  10191,  10234,  10913,  12579,    542,  49867,  10928,\n",
            "         16748,  59781,  10241,  57772,  23502,  28171,  25269,  10122,  17343,\n",
            "         86622,    570,  20785, 109566,  11905,  88504,  36481,  41600,  20829,\n",
            "         10292,  10234,  36035,  10205,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5vIS8UHdP9k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57-Z_1tDkE-3"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXq5UIavdPzJ"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(X_train, X_train_masks, torch.tensor(y_train))\n",
        "val_dataset = TensorDataset(X_valid, X_valid_masks, torch.tensor(y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XQV3IDOdSuI"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4x9HJZmdWiw",
        "outputId": "d355c171-228f-49db-d451-2851f84ae0d4"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    #\"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    MODEL_NAME,\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-93PUtmwdatC",
        "outputId": "debf54b3-b9f3-491d-fddf-f5672a9f65d2"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAAMpv_Vddpu"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  #lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  lr = 1e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lNeRgVIdfYY"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmiVZNEIdobg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUwWVBlydoLE"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Is8XLWdpRN"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epPgaQTYdsAD",
        "outputId": "df95d000-6fd8-4a73-ac09-6499566e814c"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        # loss, logits = model(b_input_ids, \n",
        "        #                      token_type_ids=None, \n",
        "        #                      attention_mask=b_input_mask, \n",
        "        #                      labels=b_labels)\n",
        "        output = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "\n",
        "            # (loss, logits) = model(b_input_ids, \n",
        "            #                        token_type_ids=None, \n",
        "            #                        attention_mask=b_input_mask,\n",
        "            #                        labels=b_labels)\n",
        "            output = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask, \n",
        "                           labels=b_labels)\n",
        "            loss = output.loss\n",
        "            logits = output.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  114,829.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  114,829.    Elapsed: 0:00:37.\n",
            "  Batch   120  of  114,829.    Elapsed: 0:00:55.\n",
            "  Batch   160  of  114,829.    Elapsed: 0:01:13.\n",
            "  Batch   200  of  114,829.    Elapsed: 0:01:31.\n",
            "  Batch   240  of  114,829.    Elapsed: 0:01:49.\n",
            "  Batch   280  of  114,829.    Elapsed: 0:02:07.\n",
            "  Batch   320  of  114,829.    Elapsed: 0:02:26.\n",
            "  Batch   360  of  114,829.    Elapsed: 0:02:44.\n",
            "  Batch   400  of  114,829.    Elapsed: 0:03:02.\n",
            "  Batch   440  of  114,829.    Elapsed: 0:03:21.\n",
            "  Batch   480  of  114,829.    Elapsed: 0:03:39.\n",
            "  Batch   520  of  114,829.    Elapsed: 0:03:57.\n",
            "  Batch   560  of  114,829.    Elapsed: 0:04:16.\n",
            "  Batch   600  of  114,829.    Elapsed: 0:04:34.\n",
            "  Batch   640  of  114,829.    Elapsed: 0:04:52.\n",
            "  Batch   680  of  114,829.    Elapsed: 0:05:11.\n",
            "  Batch   720  of  114,829.    Elapsed: 0:05:29.\n",
            "  Batch   760  of  114,829.    Elapsed: 0:05:47.\n",
            "  Batch   800  of  114,829.    Elapsed: 0:06:06.\n",
            "  Batch   840  of  114,829.    Elapsed: 0:06:24.\n",
            "  Batch   880  of  114,829.    Elapsed: 0:06:42.\n",
            "  Batch   920  of  114,829.    Elapsed: 0:07:01.\n",
            "  Batch   960  of  114,829.    Elapsed: 0:07:19.\n",
            "  Batch 1,000  of  114,829.    Elapsed: 0:07:37.\n",
            "  Batch 1,040  of  114,829.    Elapsed: 0:07:56.\n",
            "  Batch 1,080  of  114,829.    Elapsed: 0:08:14.\n",
            "  Batch 1,120  of  114,829.    Elapsed: 0:08:32.\n",
            "  Batch 1,160  of  114,829.    Elapsed: 0:08:51.\n",
            "  Batch 1,200  of  114,829.    Elapsed: 0:09:09.\n",
            "  Batch 1,240  of  114,829.    Elapsed: 0:09:27.\n",
            "  Batch 1,280  of  114,829.    Elapsed: 0:09:46.\n",
            "  Batch 1,320  of  114,829.    Elapsed: 0:10:04.\n",
            "  Batch 1,360  of  114,829.    Elapsed: 0:10:22.\n",
            "  Batch 1,400  of  114,829.    Elapsed: 0:10:41.\n",
            "  Batch 1,440  of  114,829.    Elapsed: 0:10:59.\n",
            "  Batch 1,480  of  114,829.    Elapsed: 0:11:17.\n",
            "  Batch 1,520  of  114,829.    Elapsed: 0:11:36.\n",
            "  Batch 1,560  of  114,829.    Elapsed: 0:11:54.\n",
            "  Batch 1,600  of  114,829.    Elapsed: 0:12:12.\n",
            "  Batch 1,640  of  114,829.    Elapsed: 0:12:31.\n",
            "  Batch 1,680  of  114,829.    Elapsed: 0:12:49.\n",
            "  Batch 1,720  of  114,829.    Elapsed: 0:13:07.\n",
            "  Batch 1,760  of  114,829.    Elapsed: 0:13:26.\n",
            "  Batch 1,800  of  114,829.    Elapsed: 0:13:44.\n",
            "  Batch 1,840  of  114,829.    Elapsed: 0:14:02.\n",
            "  Batch 1,880  of  114,829.    Elapsed: 0:14:21.\n",
            "  Batch 1,920  of  114,829.    Elapsed: 0:14:39.\n",
            "  Batch 1,960  of  114,829.    Elapsed: 0:14:57.\n",
            "  Batch 2,000  of  114,829.    Elapsed: 0:15:16.\n",
            "  Batch 2,040  of  114,829.    Elapsed: 0:15:34.\n",
            "  Batch 2,080  of  114,829.    Elapsed: 0:15:52.\n",
            "  Batch 2,120  of  114,829.    Elapsed: 0:16:11.\n",
            "  Batch 2,160  of  114,829.    Elapsed: 0:16:29.\n",
            "  Batch 2,200  of  114,829.    Elapsed: 0:16:47.\n",
            "  Batch 2,240  of  114,829.    Elapsed: 0:17:06.\n",
            "  Batch 2,280  of  114,829.    Elapsed: 0:17:24.\n",
            "  Batch 2,320  of  114,829.    Elapsed: 0:17:42.\n",
            "  Batch 2,360  of  114,829.    Elapsed: 0:18:00.\n",
            "  Batch 2,400  of  114,829.    Elapsed: 0:18:19.\n",
            "  Batch 2,440  of  114,829.    Elapsed: 0:18:37.\n",
            "  Batch 2,480  of  114,829.    Elapsed: 0:18:55.\n",
            "  Batch 2,520  of  114,829.    Elapsed: 0:19:14.\n",
            "  Batch 2,560  of  114,829.    Elapsed: 0:19:32.\n",
            "  Batch 2,600  of  114,829.    Elapsed: 0:19:50.\n",
            "  Batch 2,640  of  114,829.    Elapsed: 0:20:09.\n",
            "  Batch 2,680  of  114,829.    Elapsed: 0:20:27.\n",
            "  Batch 2,720  of  114,829.    Elapsed: 0:20:45.\n",
            "  Batch 2,760  of  114,829.    Elapsed: 0:21:04.\n",
            "  Batch 2,800  of  114,829.    Elapsed: 0:21:22.\n",
            "  Batch 2,840  of  114,829.    Elapsed: 0:21:40.\n",
            "  Batch 2,880  of  114,829.    Elapsed: 0:21:58.\n",
            "  Batch 2,920  of  114,829.    Elapsed: 0:22:17.\n",
            "  Batch 2,960  of  114,829.    Elapsed: 0:22:35.\n",
            "  Batch 3,000  of  114,829.    Elapsed: 0:22:54.\n",
            "  Batch 3,040  of  114,829.    Elapsed: 0:23:12.\n",
            "  Batch 3,080  of  114,829.    Elapsed: 0:23:30.\n",
            "  Batch 3,120  of  114,829.    Elapsed: 0:23:49.\n",
            "  Batch 3,160  of  114,829.    Elapsed: 0:24:07.\n",
            "  Batch 3,200  of  114,829.    Elapsed: 0:24:25.\n",
            "  Batch 3,240  of  114,829.    Elapsed: 0:24:44.\n",
            "  Batch 3,280  of  114,829.    Elapsed: 0:25:02.\n",
            "  Batch 3,320  of  114,829.    Elapsed: 0:25:20.\n",
            "  Batch 3,360  of  114,829.    Elapsed: 0:25:39.\n",
            "  Batch 3,400  of  114,829.    Elapsed: 0:25:57.\n",
            "  Batch 3,440  of  114,829.    Elapsed: 0:26:16.\n",
            "  Batch 3,480  of  114,829.    Elapsed: 0:26:34.\n",
            "  Batch 3,520  of  114,829.    Elapsed: 0:26:52.\n",
            "  Batch 3,560  of  114,829.    Elapsed: 0:27:11.\n",
            "  Batch 3,600  of  114,829.    Elapsed: 0:27:29.\n",
            "  Batch 3,640  of  114,829.    Elapsed: 0:27:47.\n",
            "  Batch 3,680  of  114,829.    Elapsed: 0:28:06.\n",
            "  Batch 3,720  of  114,829.    Elapsed: 0:28:24.\n",
            "  Batch 3,760  of  114,829.    Elapsed: 0:28:42.\n",
            "  Batch 3,800  of  114,829.    Elapsed: 0:29:01.\n",
            "  Batch 3,840  of  114,829.    Elapsed: 0:29:19.\n",
            "  Batch 3,880  of  114,829.    Elapsed: 0:29:38.\n",
            "  Batch 3,920  of  114,829.    Elapsed: 0:29:56.\n",
            "  Batch 3,960  of  114,829.    Elapsed: 0:30:14.\n",
            "  Batch 4,000  of  114,829.    Elapsed: 0:30:32.\n",
            "  Batch 4,040  of  114,829.    Elapsed: 0:30:51.\n",
            "  Batch 4,080  of  114,829.    Elapsed: 0:31:09.\n",
            "  Batch 4,120  of  114,829.    Elapsed: 0:31:28.\n",
            "  Batch 4,160  of  114,829.    Elapsed: 0:31:46.\n",
            "  Batch 4,200  of  114,829.    Elapsed: 0:32:04.\n",
            "  Batch 4,240  of  114,829.    Elapsed: 0:32:23.\n",
            "  Batch 4,280  of  114,829.    Elapsed: 0:32:41.\n",
            "  Batch 4,320  of  114,829.    Elapsed: 0:32:59.\n",
            "  Batch 4,360  of  114,829.    Elapsed: 0:33:18.\n",
            "  Batch 4,400  of  114,829.    Elapsed: 0:33:36.\n",
            "  Batch 4,440  of  114,829.    Elapsed: 0:33:54.\n",
            "  Batch 4,480  of  114,829.    Elapsed: 0:34:13.\n",
            "  Batch 4,520  of  114,829.    Elapsed: 0:34:31.\n",
            "  Batch 4,560  of  114,829.    Elapsed: 0:34:49.\n",
            "  Batch 4,600  of  114,829.    Elapsed: 0:35:08.\n",
            "  Batch 4,640  of  114,829.    Elapsed: 0:35:26.\n",
            "  Batch 4,680  of  114,829.    Elapsed: 0:35:44.\n",
            "  Batch 4,720  of  114,829.    Elapsed: 0:36:03.\n",
            "  Batch 4,760  of  114,829.    Elapsed: 0:36:21.\n",
            "  Batch 4,800  of  114,829.    Elapsed: 0:36:40.\n",
            "  Batch 4,840  of  114,829.    Elapsed: 0:36:58.\n",
            "  Batch 4,880  of  114,829.    Elapsed: 0:37:16.\n",
            "  Batch 4,920  of  114,829.    Elapsed: 0:37:35.\n",
            "  Batch 4,960  of  114,829.    Elapsed: 0:37:53.\n",
            "  Batch 5,000  of  114,829.    Elapsed: 0:38:11.\n",
            "  Batch 5,040  of  114,829.    Elapsed: 0:38:30.\n",
            "  Batch 5,080  of  114,829.    Elapsed: 0:38:48.\n",
            "  Batch 5,120  of  114,829.    Elapsed: 0:39:06.\n",
            "  Batch 5,160  of  114,829.    Elapsed: 0:39:25.\n",
            "  Batch 5,200  of  114,829.    Elapsed: 0:39:43.\n",
            "  Batch 5,240  of  114,829.    Elapsed: 0:40:02.\n",
            "  Batch 5,280  of  114,829.    Elapsed: 0:40:20.\n",
            "  Batch 5,320  of  114,829.    Elapsed: 0:40:38.\n",
            "  Batch 5,360  of  114,829.    Elapsed: 0:40:57.\n",
            "  Batch 5,400  of  114,829.    Elapsed: 0:41:15.\n",
            "  Batch 5,440  of  114,829.    Elapsed: 0:41:33.\n",
            "  Batch 5,480  of  114,829.    Elapsed: 0:41:52.\n",
            "  Batch 5,520  of  114,829.    Elapsed: 0:42:10.\n",
            "  Batch 5,560  of  114,829.    Elapsed: 0:42:29.\n",
            "  Batch 5,600  of  114,829.    Elapsed: 0:42:47.\n",
            "  Batch 5,640  of  114,829.    Elapsed: 0:43:05.\n",
            "  Batch 5,680  of  114,829.    Elapsed: 0:43:24.\n",
            "  Batch 5,720  of  114,829.    Elapsed: 0:43:42.\n",
            "  Batch 5,760  of  114,829.    Elapsed: 0:44:01.\n",
            "  Batch 5,800  of  114,829.    Elapsed: 0:44:19.\n",
            "  Batch 5,840  of  114,829.    Elapsed: 0:44:37.\n",
            "  Batch 5,880  of  114,829.    Elapsed: 0:44:56.\n",
            "  Batch 5,920  of  114,829.    Elapsed: 0:45:14.\n",
            "  Batch 5,960  of  114,829.    Elapsed: 0:45:33.\n",
            "  Batch 6,000  of  114,829.    Elapsed: 0:45:51.\n",
            "  Batch 6,040  of  114,829.    Elapsed: 0:46:09.\n",
            "  Batch 6,080  of  114,829.    Elapsed: 0:46:28.\n",
            "  Batch 6,120  of  114,829.    Elapsed: 0:46:46.\n",
            "  Batch 6,160  of  114,829.    Elapsed: 0:47:04.\n",
            "  Batch 6,200  of  114,829.    Elapsed: 0:47:23.\n",
            "  Batch 6,240  of  114,829.    Elapsed: 0:47:41.\n",
            "  Batch 6,280  of  114,829.    Elapsed: 0:48:00.\n",
            "  Batch 6,320  of  114,829.    Elapsed: 0:48:18.\n",
            "  Batch 6,360  of  114,829.    Elapsed: 0:48:36.\n",
            "  Batch 6,400  of  114,829.    Elapsed: 0:48:55.\n",
            "  Batch 6,440  of  114,829.    Elapsed: 0:49:13.\n",
            "  Batch 6,480  of  114,829.    Elapsed: 0:49:31.\n",
            "  Batch 6,520  of  114,829.    Elapsed: 0:49:50.\n",
            "  Batch 6,560  of  114,829.    Elapsed: 0:50:08.\n",
            "  Batch 6,600  of  114,829.    Elapsed: 0:50:26.\n",
            "  Batch 6,640  of  114,829.    Elapsed: 0:50:45.\n",
            "  Batch 6,680  of  114,829.    Elapsed: 0:51:03.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 6,720  of  114,829.    Elapsed: 0:51:22.\n",
            "  Batch 6,760  of  114,829.    Elapsed: 0:51:40.\n",
            "  Batch 6,800  of  114,829.    Elapsed: 0:51:58.\n",
            "  Batch 6,840  of  114,829.    Elapsed: 0:52:17.\n",
            "  Batch 6,880  of  114,829.    Elapsed: 0:52:35.\n",
            "  Batch 6,920  of  114,829.    Elapsed: 0:52:53.\n",
            "  Batch 6,960  of  114,829.    Elapsed: 0:53:12.\n",
            "  Batch 7,000  of  114,829.    Elapsed: 0:53:30.\n",
            "  Batch 7,040  of  114,829.    Elapsed: 0:53:48.\n",
            "  Batch 7,080  of  114,829.    Elapsed: 0:54:07.\n",
            "  Batch 7,120  of  114,829.    Elapsed: 0:54:25.\n",
            "  Batch 7,160  of  114,829.    Elapsed: 0:54:44.\n",
            "  Batch 7,200  of  114,829.    Elapsed: 0:55:02.\n",
            "  Batch 7,240  of  114,829.    Elapsed: 0:55:20.\n",
            "  Batch 7,280  of  114,829.    Elapsed: 0:55:39.\n",
            "  Batch 7,320  of  114,829.    Elapsed: 0:55:57.\n",
            "  Batch 7,360  of  114,829.    Elapsed: 0:56:16.\n",
            "  Batch 7,400  of  114,829.    Elapsed: 0:56:34.\n",
            "  Batch 7,440  of  114,829.    Elapsed: 0:56:52.\n",
            "  Batch 7,480  of  114,829.    Elapsed: 0:57:11.\n",
            "  Batch 7,520  of  114,829.    Elapsed: 0:57:29.\n",
            "  Batch 7,560  of  114,829.    Elapsed: 0:57:48.\n",
            "  Batch 7,600  of  114,829.    Elapsed: 0:58:06.\n",
            "  Batch 7,640  of  114,829.    Elapsed: 0:58:24.\n",
            "  Batch 7,680  of  114,829.    Elapsed: 0:58:43.\n",
            "  Batch 7,720  of  114,829.    Elapsed: 0:59:01.\n",
            "  Batch 7,760  of  114,829.    Elapsed: 0:59:19.\n",
            "  Batch 7,800  of  114,829.    Elapsed: 0:59:38.\n",
            "  Batch 7,840  of  114,829.    Elapsed: 0:59:56.\n",
            "  Batch 7,880  of  114,829.    Elapsed: 1:00:15.\n",
            "  Batch 7,920  of  114,829.    Elapsed: 1:00:33.\n",
            "  Batch 7,960  of  114,829.    Elapsed: 1:00:51.\n",
            "  Batch 8,000  of  114,829.    Elapsed: 1:01:10.\n",
            "  Batch 8,040  of  114,829.    Elapsed: 1:01:28.\n",
            "  Batch 8,080  of  114,829.    Elapsed: 1:01:47.\n",
            "  Batch 8,120  of  114,829.    Elapsed: 1:02:05.\n",
            "  Batch 8,160  of  114,829.    Elapsed: 1:02:23.\n",
            "  Batch 8,200  of  114,829.    Elapsed: 1:02:42.\n",
            "  Batch 8,240  of  114,829.    Elapsed: 1:03:00.\n",
            "  Batch 8,280  of  114,829.    Elapsed: 1:03:19.\n",
            "  Batch 8,320  of  114,829.    Elapsed: 1:03:37.\n",
            "  Batch 8,360  of  114,829.    Elapsed: 1:03:55.\n",
            "  Batch 8,400  of  114,829.    Elapsed: 1:04:14.\n",
            "  Batch 8,440  of  114,829.    Elapsed: 1:04:32.\n",
            "  Batch 8,480  of  114,829.    Elapsed: 1:04:51.\n",
            "  Batch 8,520  of  114,829.    Elapsed: 1:05:09.\n",
            "  Batch 8,560  of  114,829.    Elapsed: 1:05:27.\n",
            "  Batch 8,600  of  114,829.    Elapsed: 1:05:46.\n",
            "  Batch 8,640  of  114,829.    Elapsed: 1:06:04.\n",
            "  Batch 8,680  of  114,829.    Elapsed: 1:06:22.\n",
            "  Batch 8,720  of  114,829.    Elapsed: 1:06:41.\n",
            "  Batch 8,760  of  114,829.    Elapsed: 1:06:59.\n",
            "  Batch 8,800  of  114,829.    Elapsed: 1:07:18.\n",
            "  Batch 8,840  of  114,829.    Elapsed: 1:07:36.\n",
            "  Batch 8,880  of  114,829.    Elapsed: 1:07:54.\n",
            "  Batch 8,920  of  114,829.    Elapsed: 1:08:13.\n",
            "  Batch 8,960  of  114,829.    Elapsed: 1:08:31.\n",
            "  Batch 9,000  of  114,829.    Elapsed: 1:08:50.\n",
            "  Batch 9,040  of  114,829.    Elapsed: 1:09:08.\n",
            "  Batch 9,080  of  114,829.    Elapsed: 1:09:26.\n",
            "  Batch 9,120  of  114,829.    Elapsed: 1:09:45.\n",
            "  Batch 9,160  of  114,829.    Elapsed: 1:10:03.\n",
            "  Batch 9,200  of  114,829.    Elapsed: 1:10:22.\n",
            "  Batch 9,240  of  114,829.    Elapsed: 1:10:40.\n",
            "  Batch 9,280  of  114,829.    Elapsed: 1:10:58.\n",
            "  Batch 9,320  of  114,829.    Elapsed: 1:11:17.\n",
            "  Batch 9,360  of  114,829.    Elapsed: 1:11:35.\n",
            "  Batch 9,400  of  114,829.    Elapsed: 1:11:54.\n",
            "  Batch 9,440  of  114,829.    Elapsed: 1:12:12.\n",
            "  Batch 9,480  of  114,829.    Elapsed: 1:12:30.\n",
            "  Batch 9,520  of  114,829.    Elapsed: 1:12:49.\n",
            "  Batch 9,560  of  114,829.    Elapsed: 1:13:07.\n",
            "  Batch 9,600  of  114,829.    Elapsed: 1:13:26.\n",
            "  Batch 9,640  of  114,829.    Elapsed: 1:13:44.\n",
            "  Batch 9,680  of  114,829.    Elapsed: 1:14:02.\n",
            "  Batch 9,720  of  114,829.    Elapsed: 1:14:21.\n",
            "  Batch 9,760  of  114,829.    Elapsed: 1:14:39.\n",
            "  Batch 9,800  of  114,829.    Elapsed: 1:14:57.\n",
            "  Batch 9,840  of  114,829.    Elapsed: 1:15:16.\n",
            "  Batch 9,880  of  114,829.    Elapsed: 1:15:34.\n",
            "  Batch 9,920  of  114,829.    Elapsed: 1:15:53.\n",
            "  Batch 9,960  of  114,829.    Elapsed: 1:16:11.\n",
            "  Batch 10,000  of  114,829.    Elapsed: 1:16:29.\n",
            "  Batch 10,040  of  114,829.    Elapsed: 1:16:48.\n",
            "  Batch 10,080  of  114,829.    Elapsed: 1:17:06.\n",
            "  Batch 10,120  of  114,829.    Elapsed: 1:17:25.\n",
            "  Batch 10,160  of  114,829.    Elapsed: 1:17:43.\n",
            "  Batch 10,200  of  114,829.    Elapsed: 1:18:01.\n",
            "  Batch 10,240  of  114,829.    Elapsed: 1:18:20.\n",
            "  Batch 10,280  of  114,829.    Elapsed: 1:18:38.\n",
            "  Batch 10,320  of  114,829.    Elapsed: 1:18:57.\n",
            "  Batch 10,360  of  114,829.    Elapsed: 1:19:15.\n",
            "  Batch 10,400  of  114,829.    Elapsed: 1:19:33.\n",
            "  Batch 10,440  of  114,829.    Elapsed: 1:19:52.\n",
            "  Batch 10,480  of  114,829.    Elapsed: 1:20:10.\n",
            "  Batch 10,520  of  114,829.    Elapsed: 1:20:28.\n",
            "  Batch 10,560  of  114,829.    Elapsed: 1:20:47.\n",
            "  Batch 10,600  of  114,829.    Elapsed: 1:21:05.\n",
            "  Batch 10,640  of  114,829.    Elapsed: 1:21:24.\n",
            "  Batch 10,680  of  114,829.    Elapsed: 1:21:42.\n",
            "  Batch 10,720  of  114,829.    Elapsed: 1:22:00.\n",
            "  Batch 10,760  of  114,829.    Elapsed: 1:22:19.\n",
            "  Batch 10,800  of  114,829.    Elapsed: 1:22:37.\n",
            "  Batch 10,840  of  114,829.    Elapsed: 1:22:56.\n",
            "  Batch 10,880  of  114,829.    Elapsed: 1:23:14.\n",
            "  Batch 10,920  of  114,829.    Elapsed: 1:23:32.\n",
            "  Batch 10,960  of  114,829.    Elapsed: 1:23:51.\n",
            "  Batch 11,000  of  114,829.    Elapsed: 1:24:09.\n",
            "  Batch 11,040  of  114,829.    Elapsed: 1:24:28.\n",
            "  Batch 11,080  of  114,829.    Elapsed: 1:24:46.\n",
            "  Batch 11,120  of  114,829.    Elapsed: 1:25:04.\n",
            "  Batch 11,160  of  114,829.    Elapsed: 1:25:23.\n",
            "  Batch 11,200  of  114,829.    Elapsed: 1:25:41.\n",
            "  Batch 11,240  of  114,829.    Elapsed: 1:25:59.\n",
            "  Batch 11,280  of  114,829.    Elapsed: 1:26:18.\n",
            "  Batch 11,320  of  114,829.    Elapsed: 1:26:36.\n",
            "  Batch 11,360  of  114,829.    Elapsed: 1:26:55.\n",
            "  Batch 11,400  of  114,829.    Elapsed: 1:27:13.\n",
            "  Batch 11,440  of  114,829.    Elapsed: 1:27:31.\n",
            "  Batch 11,480  of  114,829.    Elapsed: 1:27:50.\n",
            "  Batch 11,520  of  114,829.    Elapsed: 1:28:08.\n",
            "  Batch 11,560  of  114,829.    Elapsed: 1:28:26.\n",
            "  Batch 11,600  of  114,829.    Elapsed: 1:28:45.\n",
            "  Batch 11,640  of  114,829.    Elapsed: 1:29:03.\n",
            "  Batch 11,680  of  114,829.    Elapsed: 1:29:21.\n",
            "  Batch 11,720  of  114,829.    Elapsed: 1:29:40.\n",
            "  Batch 11,760  of  114,829.    Elapsed: 1:29:58.\n",
            "  Batch 11,800  of  114,829.    Elapsed: 1:30:16.\n",
            "  Batch 11,840  of  114,829.    Elapsed: 1:30:35.\n",
            "  Batch 11,880  of  114,829.    Elapsed: 1:30:53.\n",
            "  Batch 11,920  of  114,829.    Elapsed: 1:31:12.\n",
            "  Batch 11,960  of  114,829.    Elapsed: 1:31:30.\n",
            "  Batch 12,000  of  114,829.    Elapsed: 1:31:48.\n",
            "  Batch 12,040  of  114,829.    Elapsed: 1:32:07.\n",
            "  Batch 12,080  of  114,829.    Elapsed: 1:32:25.\n",
            "  Batch 12,120  of  114,829.    Elapsed: 1:32:43.\n",
            "  Batch 12,160  of  114,829.    Elapsed: 1:33:02.\n",
            "  Batch 12,200  of  114,829.    Elapsed: 1:33:20.\n",
            "  Batch 12,240  of  114,829.    Elapsed: 1:33:38.\n",
            "  Batch 12,280  of  114,829.    Elapsed: 1:33:57.\n",
            "  Batch 12,320  of  114,829.    Elapsed: 1:34:15.\n",
            "  Batch 12,360  of  114,829.    Elapsed: 1:34:33.\n",
            "  Batch 12,400  of  114,829.    Elapsed: 1:34:52.\n",
            "  Batch 12,440  of  114,829.    Elapsed: 1:35:10.\n",
            "  Batch 12,480  of  114,829.    Elapsed: 1:35:29.\n",
            "  Batch 12,520  of  114,829.    Elapsed: 1:35:47.\n",
            "  Batch 12,560  of  114,829.    Elapsed: 1:36:05.\n",
            "  Batch 12,600  of  114,829.    Elapsed: 1:36:24.\n",
            "  Batch 12,640  of  114,829.    Elapsed: 1:36:42.\n",
            "  Batch 12,680  of  114,829.    Elapsed: 1:37:00.\n",
            "  Batch 12,720  of  114,829.    Elapsed: 1:37:19.\n",
            "  Batch 12,760  of  114,829.    Elapsed: 1:37:37.\n",
            "  Batch 12,800  of  114,829.    Elapsed: 1:37:56.\n",
            "  Batch 12,840  of  114,829.    Elapsed: 1:38:14.\n",
            "  Batch 12,880  of  114,829.    Elapsed: 1:38:32.\n",
            "  Batch 12,920  of  114,829.    Elapsed: 1:38:51.\n",
            "  Batch 12,960  of  114,829.    Elapsed: 1:39:09.\n",
            "  Batch 13,000  of  114,829.    Elapsed: 1:39:28.\n",
            "  Batch 13,040  of  114,829.    Elapsed: 1:39:46.\n",
            "  Batch 13,080  of  114,829.    Elapsed: 1:40:04.\n",
            "  Batch 13,120  of  114,829.    Elapsed: 1:40:23.\n",
            "  Batch 13,160  of  114,829.    Elapsed: 1:40:41.\n",
            "  Batch 13,200  of  114,829.    Elapsed: 1:40:59.\n",
            "  Batch 13,240  of  114,829.    Elapsed: 1:41:18.\n",
            "  Batch 13,280  of  114,829.    Elapsed: 1:41:36.\n",
            "  Batch 13,320  of  114,829.    Elapsed: 1:41:55.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 13,360  of  114,829.    Elapsed: 1:42:13.\n",
            "  Batch 13,400  of  114,829.    Elapsed: 1:42:31.\n",
            "  Batch 13,440  of  114,829.    Elapsed: 1:42:50.\n",
            "  Batch 13,480  of  114,829.    Elapsed: 1:43:08.\n",
            "  Batch 13,520  of  114,829.    Elapsed: 1:43:26.\n",
            "  Batch 13,560  of  114,829.    Elapsed: 1:43:45.\n",
            "  Batch 13,600  of  114,829.    Elapsed: 1:44:03.\n",
            "  Batch 13,640  of  114,829.    Elapsed: 1:44:21.\n",
            "  Batch 13,680  of  114,829.    Elapsed: 1:44:40.\n",
            "  Batch 13,720  of  114,829.    Elapsed: 1:44:58.\n",
            "  Batch 13,760  of  114,829.    Elapsed: 1:45:17.\n",
            "  Batch 13,800  of  114,829.    Elapsed: 1:45:35.\n",
            "  Batch 13,840  of  114,829.    Elapsed: 1:45:53.\n",
            "  Batch 13,880  of  114,829.    Elapsed: 1:46:12.\n",
            "  Batch 13,920  of  114,829.    Elapsed: 1:46:30.\n",
            "  Batch 13,960  of  114,829.    Elapsed: 1:46:49.\n",
            "  Batch 14,000  of  114,829.    Elapsed: 1:47:07.\n",
            "  Batch 14,040  of  114,829.    Elapsed: 1:47:25.\n",
            "  Batch 14,080  of  114,829.    Elapsed: 1:47:44.\n",
            "  Batch 14,120  of  114,829.    Elapsed: 1:48:02.\n",
            "  Batch 14,160  of  114,829.    Elapsed: 1:48:21.\n",
            "  Batch 14,200  of  114,829.    Elapsed: 1:48:39.\n",
            "  Batch 14,240  of  114,829.    Elapsed: 1:48:57.\n",
            "  Batch 14,280  of  114,829.    Elapsed: 1:49:16.\n",
            "  Batch 14,320  of  114,829.    Elapsed: 1:49:34.\n",
            "  Batch 14,360  of  114,829.    Elapsed: 1:49:53.\n",
            "  Batch 14,400  of  114,829.    Elapsed: 1:50:11.\n",
            "  Batch 14,440  of  114,829.    Elapsed: 1:50:29.\n",
            "  Batch 14,480  of  114,829.    Elapsed: 1:50:48.\n",
            "  Batch 14,520  of  114,829.    Elapsed: 1:51:06.\n",
            "  Batch 14,560  of  114,829.    Elapsed: 1:51:25.\n",
            "  Batch 14,600  of  114,829.    Elapsed: 1:51:43.\n",
            "  Batch 14,640  of  114,829.    Elapsed: 1:52:01.\n",
            "  Batch 14,680  of  114,829.    Elapsed: 1:52:20.\n",
            "  Batch 14,720  of  114,829.    Elapsed: 1:52:38.\n",
            "  Batch 14,760  of  114,829.    Elapsed: 1:52:57.\n",
            "  Batch 14,800  of  114,829.    Elapsed: 1:53:15.\n",
            "  Batch 14,840  of  114,829.    Elapsed: 1:53:33.\n",
            "  Batch 14,880  of  114,829.    Elapsed: 1:53:52.\n",
            "  Batch 14,920  of  114,829.    Elapsed: 1:54:10.\n",
            "  Batch 14,960  of  114,829.    Elapsed: 1:54:29.\n",
            "  Batch 15,000  of  114,829.    Elapsed: 1:54:47.\n",
            "  Batch 15,040  of  114,829.    Elapsed: 1:55:05.\n",
            "  Batch 15,080  of  114,829.    Elapsed: 1:55:24.\n",
            "  Batch 15,120  of  114,829.    Elapsed: 1:55:42.\n",
            "  Batch 15,160  of  114,829.    Elapsed: 1:56:00.\n",
            "  Batch 15,200  of  114,829.    Elapsed: 1:56:19.\n",
            "  Batch 15,240  of  114,829.    Elapsed: 1:56:37.\n",
            "  Batch 15,280  of  114,829.    Elapsed: 1:56:56.\n",
            "  Batch 15,320  of  114,829.    Elapsed: 1:57:14.\n",
            "  Batch 15,360  of  114,829.    Elapsed: 1:57:32.\n",
            "  Batch 15,400  of  114,829.    Elapsed: 1:57:51.\n",
            "  Batch 15,440  of  114,829.    Elapsed: 1:58:09.\n",
            "  Batch 15,480  of  114,829.    Elapsed: 1:58:28.\n",
            "  Batch 15,520  of  114,829.    Elapsed: 1:58:46.\n",
            "  Batch 15,560  of  114,829.    Elapsed: 1:59:04.\n",
            "  Batch 15,600  of  114,829.    Elapsed: 1:59:23.\n",
            "  Batch 15,640  of  114,829.    Elapsed: 1:59:41.\n",
            "  Batch 15,680  of  114,829.    Elapsed: 2:00:00.\n",
            "  Batch 15,720  of  114,829.    Elapsed: 2:00:18.\n",
            "  Batch 15,760  of  114,829.    Elapsed: 2:00:36.\n",
            "  Batch 15,800  of  114,829.    Elapsed: 2:00:55.\n",
            "  Batch 15,840  of  114,829.    Elapsed: 2:01:13.\n",
            "  Batch 15,880  of  114,829.    Elapsed: 2:01:31.\n",
            "  Batch 15,920  of  114,829.    Elapsed: 2:01:50.\n",
            "  Batch 15,960  of  114,829.    Elapsed: 2:02:08.\n",
            "  Batch 16,000  of  114,829.    Elapsed: 2:02:27.\n",
            "  Batch 16,040  of  114,829.    Elapsed: 2:02:45.\n",
            "  Batch 16,080  of  114,829.    Elapsed: 2:03:03.\n",
            "  Batch 16,120  of  114,829.    Elapsed: 2:03:22.\n",
            "  Batch 16,160  of  114,829.    Elapsed: 2:03:40.\n",
            "  Batch 16,200  of  114,829.    Elapsed: 2:03:59.\n",
            "  Batch 16,240  of  114,829.    Elapsed: 2:04:17.\n",
            "  Batch 16,280  of  114,829.    Elapsed: 2:04:35.\n",
            "  Batch 16,320  of  114,829.    Elapsed: 2:04:54.\n",
            "  Batch 16,360  of  114,829.    Elapsed: 2:05:12.\n",
            "  Batch 16,400  of  114,829.    Elapsed: 2:05:30.\n",
            "  Batch 16,440  of  114,829.    Elapsed: 2:05:49.\n",
            "  Batch 16,480  of  114,829.    Elapsed: 2:06:07.\n",
            "  Batch 16,520  of  114,829.    Elapsed: 2:06:25.\n",
            "  Batch 16,560  of  114,829.    Elapsed: 2:06:44.\n",
            "  Batch 16,600  of  114,829.    Elapsed: 2:07:02.\n",
            "  Batch 16,640  of  114,829.    Elapsed: 2:07:20.\n",
            "  Batch 16,680  of  114,829.    Elapsed: 2:07:39.\n",
            "  Batch 16,720  of  114,829.    Elapsed: 2:07:57.\n",
            "  Batch 16,760  of  114,829.    Elapsed: 2:08:16.\n",
            "  Batch 16,800  of  114,829.    Elapsed: 2:08:34.\n",
            "  Batch 16,840  of  114,829.    Elapsed: 2:08:52.\n",
            "  Batch 16,880  of  114,829.    Elapsed: 2:09:11.\n",
            "  Batch 16,920  of  114,829.    Elapsed: 2:09:29.\n",
            "  Batch 16,960  of  114,829.    Elapsed: 2:09:47.\n",
            "  Batch 17,000  of  114,829.    Elapsed: 2:10:06.\n",
            "  Batch 17,040  of  114,829.    Elapsed: 2:10:24.\n",
            "  Batch 17,080  of  114,829.    Elapsed: 2:10:42.\n",
            "  Batch 17,120  of  114,829.    Elapsed: 2:11:01.\n",
            "  Batch 17,160  of  114,829.    Elapsed: 2:11:19.\n",
            "  Batch 17,200  of  114,829.    Elapsed: 2:11:38.\n",
            "  Batch 17,240  of  114,829.    Elapsed: 2:11:56.\n",
            "  Batch 17,280  of  114,829.    Elapsed: 2:12:15.\n",
            "  Batch 17,320  of  114,829.    Elapsed: 2:12:33.\n",
            "  Batch 17,360  of  114,829.    Elapsed: 2:12:51.\n",
            "  Batch 17,400  of  114,829.    Elapsed: 2:13:10.\n",
            "  Batch 17,440  of  114,829.    Elapsed: 2:13:28.\n",
            "  Batch 17,480  of  114,829.    Elapsed: 2:13:46.\n",
            "  Batch 17,520  of  114,829.    Elapsed: 2:14:05.\n",
            "  Batch 17,560  of  114,829.    Elapsed: 2:14:23.\n",
            "  Batch 17,600  of  114,829.    Elapsed: 2:14:42.\n",
            "  Batch 17,640  of  114,829.    Elapsed: 2:15:00.\n",
            "  Batch 17,680  of  114,829.    Elapsed: 2:15:18.\n",
            "  Batch 17,720  of  114,829.    Elapsed: 2:15:37.\n",
            "  Batch 17,760  of  114,829.    Elapsed: 2:15:55.\n",
            "  Batch 17,800  of  114,829.    Elapsed: 2:16:14.\n",
            "  Batch 17,840  of  114,829.    Elapsed: 2:16:32.\n",
            "  Batch 17,880  of  114,829.    Elapsed: 2:16:50.\n",
            "  Batch 17,920  of  114,829.    Elapsed: 2:17:09.\n",
            "  Batch 17,960  of  114,829.    Elapsed: 2:17:27.\n",
            "  Batch 18,000  of  114,829.    Elapsed: 2:17:45.\n",
            "  Batch 18,040  of  114,829.    Elapsed: 2:18:04.\n",
            "  Batch 18,080  of  114,829.    Elapsed: 2:18:22.\n",
            "  Batch 18,120  of  114,829.    Elapsed: 2:18:41.\n",
            "  Batch 18,160  of  114,829.    Elapsed: 2:18:59.\n",
            "  Batch 18,200  of  114,829.    Elapsed: 2:19:17.\n",
            "  Batch 18,240  of  114,829.    Elapsed: 2:19:36.\n",
            "  Batch 18,280  of  114,829.    Elapsed: 2:19:54.\n",
            "  Batch 18,320  of  114,829.    Elapsed: 2:20:12.\n",
            "  Batch 18,360  of  114,829.    Elapsed: 2:20:31.\n",
            "  Batch 18,400  of  114,829.    Elapsed: 2:20:49.\n",
            "  Batch 18,440  of  114,829.    Elapsed: 2:21:08.\n",
            "  Batch 18,480  of  114,829.    Elapsed: 2:21:26.\n",
            "  Batch 18,520  of  114,829.    Elapsed: 2:21:44.\n",
            "  Batch 18,560  of  114,829.    Elapsed: 2:22:03.\n",
            "  Batch 18,600  of  114,829.    Elapsed: 2:22:21.\n",
            "  Batch 18,640  of  114,829.    Elapsed: 2:22:39.\n",
            "  Batch 18,680  of  114,829.    Elapsed: 2:22:58.\n",
            "  Batch 18,720  of  114,829.    Elapsed: 2:23:16.\n",
            "  Batch 18,760  of  114,829.    Elapsed: 2:23:35.\n",
            "  Batch 18,800  of  114,829.    Elapsed: 2:23:53.\n",
            "  Batch 18,840  of  114,829.    Elapsed: 2:24:11.\n",
            "  Batch 18,880  of  114,829.    Elapsed: 2:24:30.\n",
            "  Batch 18,920  of  114,829.    Elapsed: 2:24:48.\n",
            "  Batch 18,960  of  114,829.    Elapsed: 2:25:06.\n",
            "  Batch 19,000  of  114,829.    Elapsed: 2:25:25.\n",
            "  Batch 19,040  of  114,829.    Elapsed: 2:25:43.\n",
            "  Batch 19,080  of  114,829.    Elapsed: 2:26:02.\n",
            "  Batch 19,120  of  114,829.    Elapsed: 2:26:20.\n",
            "  Batch 19,160  of  114,829.    Elapsed: 2:26:38.\n",
            "  Batch 19,200  of  114,829.    Elapsed: 2:26:57.\n",
            "  Batch 19,240  of  114,829.    Elapsed: 2:27:15.\n",
            "  Batch 19,280  of  114,829.    Elapsed: 2:27:33.\n",
            "  Batch 19,320  of  114,829.    Elapsed: 2:27:52.\n",
            "  Batch 19,360  of  114,829.    Elapsed: 2:28:10.\n",
            "  Batch 19,400  of  114,829.    Elapsed: 2:28:29.\n",
            "  Batch 19,440  of  114,829.    Elapsed: 2:28:47.\n",
            "  Batch 19,480  of  114,829.    Elapsed: 2:29:05.\n",
            "  Batch 19,520  of  114,829.    Elapsed: 2:29:24.\n",
            "  Batch 19,560  of  114,829.    Elapsed: 2:29:42.\n",
            "  Batch 19,600  of  114,829.    Elapsed: 2:30:00.\n",
            "  Batch 19,640  of  114,829.    Elapsed: 2:30:19.\n",
            "  Batch 19,680  of  114,829.    Elapsed: 2:30:37.\n",
            "  Batch 19,720  of  114,829.    Elapsed: 2:30:56.\n",
            "  Batch 19,760  of  114,829.    Elapsed: 2:31:14.\n",
            "  Batch 19,800  of  114,829.    Elapsed: 2:31:32.\n",
            "  Batch 19,840  of  114,829.    Elapsed: 2:31:51.\n",
            "  Batch 19,880  of  114,829.    Elapsed: 2:32:09.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 19,920  of  114,829.    Elapsed: 2:32:27.\n",
            "  Batch 19,960  of  114,829.    Elapsed: 2:32:46.\n",
            "  Batch 20,000  of  114,829.    Elapsed: 2:33:04.\n",
            "  Batch 20,040  of  114,829.    Elapsed: 2:33:23.\n",
            "  Batch 20,080  of  114,829.    Elapsed: 2:33:41.\n",
            "  Batch 20,120  of  114,829.    Elapsed: 2:33:59.\n",
            "  Batch 20,160  of  114,829.    Elapsed: 2:34:18.\n",
            "  Batch 20,200  of  114,829.    Elapsed: 2:34:36.\n",
            "  Batch 20,240  of  114,829.    Elapsed: 2:34:54.\n",
            "  Batch 20,280  of  114,829.    Elapsed: 2:35:13.\n",
            "  Batch 20,320  of  114,829.    Elapsed: 2:35:31.\n",
            "  Batch 20,360  of  114,829.    Elapsed: 2:35:50.\n",
            "  Batch 20,400  of  114,829.    Elapsed: 2:36:08.\n",
            "  Batch 20,440  of  114,829.    Elapsed: 2:36:26.\n",
            "  Batch 20,480  of  114,829.    Elapsed: 2:36:45.\n",
            "  Batch 20,520  of  114,829.    Elapsed: 2:37:03.\n",
            "  Batch 20,560  of  114,829.    Elapsed: 2:37:22.\n",
            "  Batch 20,600  of  114,829.    Elapsed: 2:37:40.\n",
            "  Batch 20,640  of  114,829.    Elapsed: 2:37:58.\n",
            "  Batch 20,680  of  114,829.    Elapsed: 2:38:17.\n",
            "  Batch 20,720  of  114,829.    Elapsed: 2:38:35.\n",
            "  Batch 20,760  of  114,829.    Elapsed: 2:38:53.\n",
            "  Batch 20,800  of  114,829.    Elapsed: 2:39:12.\n",
            "  Batch 20,840  of  114,829.    Elapsed: 2:39:30.\n",
            "  Batch 20,880  of  114,829.    Elapsed: 2:39:48.\n",
            "  Batch 20,920  of  114,829.    Elapsed: 2:40:07.\n",
            "  Batch 20,960  of  114,829.    Elapsed: 2:40:25.\n",
            "  Batch 21,000  of  114,829.    Elapsed: 2:40:44.\n",
            "  Batch 21,040  of  114,829.    Elapsed: 2:41:02.\n",
            "  Batch 21,080  of  114,829.    Elapsed: 2:41:20.\n",
            "  Batch 21,120  of  114,829.    Elapsed: 2:41:39.\n",
            "  Batch 21,160  of  114,829.    Elapsed: 2:41:57.\n",
            "  Batch 21,200  of  114,829.    Elapsed: 2:42:15.\n",
            "  Batch 21,240  of  114,829.    Elapsed: 2:42:34.\n",
            "  Batch 21,280  of  114,829.    Elapsed: 2:42:52.\n",
            "  Batch 21,320  of  114,829.    Elapsed: 2:43:11.\n",
            "  Batch 21,360  of  114,829.    Elapsed: 2:43:29.\n",
            "  Batch 21,400  of  114,829.    Elapsed: 2:43:47.\n",
            "  Batch 21,440  of  114,829.    Elapsed: 2:44:06.\n",
            "  Batch 21,480  of  114,829.    Elapsed: 2:44:24.\n",
            "  Batch 21,520  of  114,829.    Elapsed: 2:44:42.\n",
            "  Batch 21,560  of  114,829.    Elapsed: 2:45:01.\n",
            "  Batch 21,600  of  114,829.    Elapsed: 2:45:19.\n",
            "  Batch 21,640  of  114,829.    Elapsed: 2:45:38.\n",
            "  Batch 21,680  of  114,829.    Elapsed: 2:45:56.\n",
            "  Batch 21,720  of  114,829.    Elapsed: 2:46:14.\n",
            "  Batch 21,760  of  114,829.    Elapsed: 2:46:33.\n",
            "  Batch 21,800  of  114,829.    Elapsed: 2:46:51.\n",
            "  Batch 21,840  of  114,829.    Elapsed: 2:47:09.\n",
            "  Batch 21,880  of  114,829.    Elapsed: 2:47:28.\n",
            "  Batch 21,920  of  114,829.    Elapsed: 2:47:46.\n",
            "  Batch 21,960  of  114,829.    Elapsed: 2:48:04.\n",
            "  Batch 22,000  of  114,829.    Elapsed: 2:48:23.\n",
            "  Batch 22,040  of  114,829.    Elapsed: 2:48:41.\n",
            "  Batch 22,080  of  114,829.    Elapsed: 2:49:00.\n",
            "  Batch 22,120  of  114,829.    Elapsed: 2:49:18.\n",
            "  Batch 22,160  of  114,829.    Elapsed: 2:49:36.\n",
            "  Batch 22,200  of  114,829.    Elapsed: 2:49:55.\n",
            "  Batch 22,240  of  114,829.    Elapsed: 2:50:13.\n",
            "  Batch 22,280  of  114,829.    Elapsed: 2:50:31.\n",
            "  Batch 22,320  of  114,829.    Elapsed: 2:50:50.\n",
            "  Batch 22,360  of  114,829.    Elapsed: 2:51:08.\n",
            "  Batch 22,400  of  114,829.    Elapsed: 2:51:27.\n",
            "  Batch 22,440  of  114,829.    Elapsed: 2:51:45.\n",
            "  Batch 22,480  of  114,829.    Elapsed: 2:52:03.\n",
            "  Batch 22,520  of  114,829.    Elapsed: 2:52:22.\n",
            "  Batch 22,560  of  114,829.    Elapsed: 2:52:40.\n",
            "  Batch 22,600  of  114,829.    Elapsed: 2:52:58.\n",
            "  Batch 22,640  of  114,829.    Elapsed: 2:53:17.\n",
            "  Batch 22,680  of  114,829.    Elapsed: 2:53:35.\n",
            "  Batch 22,720  of  114,829.    Elapsed: 2:53:54.\n",
            "  Batch 22,760  of  114,829.    Elapsed: 2:54:12.\n",
            "  Batch 22,800  of  114,829.    Elapsed: 2:54:30.\n",
            "  Batch 22,840  of  114,829.    Elapsed: 2:54:49.\n",
            "  Batch 22,880  of  114,829.    Elapsed: 2:55:07.\n",
            "  Batch 22,920  of  114,829.    Elapsed: 2:55:26.\n",
            "  Batch 22,960  of  114,829.    Elapsed: 2:55:44.\n",
            "  Batch 23,000  of  114,829.    Elapsed: 2:56:02.\n",
            "  Batch 23,040  of  114,829.    Elapsed: 2:56:21.\n",
            "  Batch 23,080  of  114,829.    Elapsed: 2:56:39.\n",
            "  Batch 23,120  of  114,829.    Elapsed: 2:56:57.\n",
            "  Batch 23,160  of  114,829.    Elapsed: 2:57:16.\n",
            "  Batch 23,200  of  114,829.    Elapsed: 2:57:34.\n",
            "  Batch 23,240  of  114,829.    Elapsed: 2:57:53.\n",
            "  Batch 23,280  of  114,829.    Elapsed: 2:58:11.\n",
            "  Batch 23,320  of  114,829.    Elapsed: 2:58:29.\n",
            "  Batch 23,360  of  114,829.    Elapsed: 2:58:48.\n",
            "  Batch 23,400  of  114,829.    Elapsed: 2:59:06.\n",
            "  Batch 23,440  of  114,829.    Elapsed: 2:59:24.\n",
            "  Batch 23,480  of  114,829.    Elapsed: 2:59:43.\n",
            "  Batch 23,520  of  114,829.    Elapsed: 3:00:01.\n",
            "  Batch 23,560  of  114,829.    Elapsed: 3:00:20.\n",
            "  Batch 23,600  of  114,829.    Elapsed: 3:00:38.\n",
            "  Batch 23,640  of  114,829.    Elapsed: 3:00:56.\n",
            "  Batch 23,680  of  114,829.    Elapsed: 3:01:15.\n",
            "  Batch 23,720  of  114,829.    Elapsed: 3:01:33.\n",
            "  Batch 23,760  of  114,829.    Elapsed: 3:01:52.\n",
            "  Batch 23,800  of  114,829.    Elapsed: 3:02:10.\n",
            "  Batch 23,840  of  114,829.    Elapsed: 3:02:28.\n",
            "  Batch 23,880  of  114,829.    Elapsed: 3:02:47.\n",
            "  Batch 23,920  of  114,829.    Elapsed: 3:03:05.\n",
            "  Batch 23,960  of  114,829.    Elapsed: 3:03:23.\n",
            "  Batch 24,000  of  114,829.    Elapsed: 3:03:42.\n",
            "  Batch 24,040  of  114,829.    Elapsed: 3:04:00.\n",
            "  Batch 24,080  of  114,829.    Elapsed: 3:04:18.\n",
            "  Batch 24,120  of  114,829.    Elapsed: 3:04:37.\n",
            "  Batch 24,160  of  114,829.    Elapsed: 3:04:55.\n",
            "  Batch 24,200  of  114,829.    Elapsed: 3:05:14.\n",
            "  Batch 24,240  of  114,829.    Elapsed: 3:05:32.\n",
            "  Batch 24,280  of  114,829.    Elapsed: 3:05:50.\n",
            "  Batch 24,320  of  114,829.    Elapsed: 3:06:09.\n",
            "  Batch 24,360  of  114,829.    Elapsed: 3:06:27.\n",
            "  Batch 24,400  of  114,829.    Elapsed: 3:06:46.\n",
            "  Batch 24,440  of  114,829.    Elapsed: 3:07:04.\n",
            "  Batch 24,480  of  114,829.    Elapsed: 3:07:22.\n",
            "  Batch 24,520  of  114,829.    Elapsed: 3:07:41.\n",
            "  Batch 24,560  of  114,829.    Elapsed: 3:07:59.\n",
            "  Batch 24,600  of  114,829.    Elapsed: 3:08:17.\n",
            "  Batch 24,640  of  114,829.    Elapsed: 3:08:36.\n",
            "  Batch 24,680  of  114,829.    Elapsed: 3:08:54.\n",
            "  Batch 24,720  of  114,829.    Elapsed: 3:09:13.\n",
            "  Batch 24,760  of  114,829.    Elapsed: 3:09:31.\n",
            "  Batch 24,800  of  114,829.    Elapsed: 3:09:49.\n",
            "  Batch 24,840  of  114,829.    Elapsed: 3:10:08.\n",
            "  Batch 24,880  of  114,829.    Elapsed: 3:10:26.\n",
            "  Batch 24,920  of  114,829.    Elapsed: 3:10:44.\n",
            "  Batch 24,960  of  114,829.    Elapsed: 3:11:03.\n",
            "  Batch 25,000  of  114,829.    Elapsed: 3:11:21.\n",
            "  Batch 25,040  of  114,829.    Elapsed: 3:11:40.\n",
            "  Batch 25,080  of  114,829.    Elapsed: 3:11:58.\n",
            "  Batch 25,120  of  114,829.    Elapsed: 3:12:16.\n",
            "  Batch 25,160  of  114,829.    Elapsed: 3:12:35.\n",
            "  Batch 25,200  of  114,829.    Elapsed: 3:12:53.\n",
            "  Batch 25,240  of  114,829.    Elapsed: 3:13:11.\n",
            "  Batch 25,280  of  114,829.    Elapsed: 3:13:30.\n",
            "  Batch 25,320  of  114,829.    Elapsed: 3:13:48.\n",
            "  Batch 25,360  of  114,829.    Elapsed: 3:14:07.\n",
            "  Batch 25,400  of  114,829.    Elapsed: 3:14:25.\n",
            "  Batch 25,440  of  114,829.    Elapsed: 3:14:44.\n",
            "  Batch 25,480  of  114,829.    Elapsed: 3:15:02.\n",
            "  Batch 25,520  of  114,829.    Elapsed: 3:15:20.\n",
            "  Batch 25,560  of  114,829.    Elapsed: 3:15:39.\n",
            "  Batch 25,600  of  114,829.    Elapsed: 3:15:57.\n",
            "  Batch 25,640  of  114,829.    Elapsed: 3:16:16.\n",
            "  Batch 25,680  of  114,829.    Elapsed: 3:16:34.\n",
            "  Batch 25,720  of  114,829.    Elapsed: 3:16:52.\n",
            "  Batch 25,760  of  114,829.    Elapsed: 3:17:11.\n",
            "  Batch 25,800  of  114,829.    Elapsed: 3:17:29.\n",
            "  Batch 25,840  of  114,829.    Elapsed: 3:17:48.\n",
            "  Batch 25,880  of  114,829.    Elapsed: 3:18:06.\n",
            "  Batch 25,920  of  114,829.    Elapsed: 3:18:24.\n",
            "  Batch 25,960  of  114,829.    Elapsed: 3:18:43.\n",
            "  Batch 26,000  of  114,829.    Elapsed: 3:19:01.\n",
            "  Batch 26,040  of  114,829.    Elapsed: 3:19:20.\n",
            "  Batch 26,080  of  114,829.    Elapsed: 3:19:38.\n",
            "  Batch 26,120  of  114,829.    Elapsed: 3:19:56.\n",
            "  Batch 26,160  of  114,829.    Elapsed: 3:20:15.\n",
            "  Batch 26,200  of  114,829.    Elapsed: 3:20:33.\n",
            "  Batch 26,240  of  114,829.    Elapsed: 3:20:52.\n",
            "  Batch 26,280  of  114,829.    Elapsed: 3:21:10.\n",
            "  Batch 26,320  of  114,829.    Elapsed: 3:21:28.\n",
            "  Batch 26,360  of  114,829.    Elapsed: 3:21:47.\n",
            "  Batch 26,400  of  114,829.    Elapsed: 3:22:05.\n",
            "  Batch 26,440  of  114,829.    Elapsed: 3:22:24.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 26,480  of  114,829.    Elapsed: 3:22:42.\n",
            "  Batch 26,520  of  114,829.    Elapsed: 3:23:00.\n",
            "  Batch 26,560  of  114,829.    Elapsed: 3:23:19.\n",
            "  Batch 26,600  of  114,829.    Elapsed: 3:23:37.\n",
            "  Batch 26,640  of  114,829.    Elapsed: 3:23:56.\n",
            "  Batch 26,680  of  114,829.    Elapsed: 3:24:14.\n",
            "  Batch 26,720  of  114,829.    Elapsed: 3:24:32.\n",
            "  Batch 26,760  of  114,829.    Elapsed: 3:24:51.\n",
            "  Batch 26,800  of  114,829.    Elapsed: 3:25:09.\n",
            "  Batch 26,840  of  114,829.    Elapsed: 3:25:28.\n",
            "  Batch 26,880  of  114,829.    Elapsed: 3:25:46.\n",
            "  Batch 26,920  of  114,829.    Elapsed: 3:26:04.\n",
            "  Batch 26,960  of  114,829.    Elapsed: 3:26:23.\n",
            "  Batch 27,000  of  114,829.    Elapsed: 3:26:41.\n",
            "  Batch 27,040  of  114,829.    Elapsed: 3:27:00.\n",
            "  Batch 27,080  of  114,829.    Elapsed: 3:27:18.\n",
            "  Batch 27,120  of  114,829.    Elapsed: 3:27:36.\n",
            "  Batch 27,160  of  114,829.    Elapsed: 3:27:55.\n",
            "  Batch 27,200  of  114,829.    Elapsed: 3:28:13.\n",
            "  Batch 27,240  of  114,829.    Elapsed: 3:28:32.\n",
            "  Batch 27,280  of  114,829.    Elapsed: 3:28:50.\n",
            "  Batch 27,320  of  114,829.    Elapsed: 3:29:08.\n",
            "  Batch 27,360  of  114,829.    Elapsed: 3:29:27.\n",
            "  Batch 27,400  of  114,829.    Elapsed: 3:29:45.\n",
            "  Batch 27,440  of  114,829.    Elapsed: 3:30:04.\n",
            "  Batch 27,480  of  114,829.    Elapsed: 3:30:22.\n",
            "  Batch 27,520  of  114,829.    Elapsed: 3:30:40.\n",
            "  Batch 27,560  of  114,829.    Elapsed: 3:30:59.\n",
            "  Batch 27,600  of  114,829.    Elapsed: 3:31:17.\n",
            "  Batch 27,640  of  114,829.    Elapsed: 3:31:36.\n",
            "  Batch 27,680  of  114,829.    Elapsed: 3:31:54.\n",
            "  Batch 27,720  of  114,829.    Elapsed: 3:32:13.\n",
            "  Batch 27,760  of  114,829.    Elapsed: 3:32:31.\n",
            "  Batch 27,800  of  114,829.    Elapsed: 3:32:49.\n",
            "  Batch 27,840  of  114,829.    Elapsed: 3:33:08.\n",
            "  Batch 27,880  of  114,829.    Elapsed: 3:33:26.\n",
            "  Batch 27,920  of  114,829.    Elapsed: 3:33:45.\n",
            "  Batch 27,960  of  114,829.    Elapsed: 3:34:03.\n",
            "  Batch 28,000  of  114,829.    Elapsed: 3:34:21.\n",
            "  Batch 28,040  of  114,829.    Elapsed: 3:34:40.\n",
            "  Batch 28,080  of  114,829.    Elapsed: 3:34:58.\n",
            "  Batch 28,120  of  114,829.    Elapsed: 3:35:16.\n",
            "  Batch 28,160  of  114,829.    Elapsed: 3:35:35.\n",
            "  Batch 28,200  of  114,829.    Elapsed: 3:35:53.\n",
            "  Batch 28,240  of  114,829.    Elapsed: 3:36:11.\n",
            "  Batch 28,280  of  114,829.    Elapsed: 3:36:30.\n",
            "  Batch 28,320  of  114,829.    Elapsed: 3:36:48.\n",
            "  Batch 28,360  of  114,829.    Elapsed: 3:37:07.\n",
            "  Batch 28,400  of  114,829.    Elapsed: 3:37:25.\n",
            "  Batch 28,440  of  114,829.    Elapsed: 3:37:43.\n",
            "  Batch 28,480  of  114,829.    Elapsed: 3:38:02.\n",
            "  Batch 28,520  of  114,829.    Elapsed: 3:38:20.\n",
            "  Batch 28,560  of  114,829.    Elapsed: 3:38:39.\n",
            "  Batch 28,600  of  114,829.    Elapsed: 3:38:57.\n",
            "  Batch 28,640  of  114,829.    Elapsed: 3:39:15.\n",
            "  Batch 28,680  of  114,829.    Elapsed: 3:39:34.\n",
            "  Batch 28,720  of  114,829.    Elapsed: 3:39:52.\n",
            "  Batch 28,760  of  114,829.    Elapsed: 3:40:10.\n",
            "  Batch 28,800  of  114,829.    Elapsed: 3:40:29.\n",
            "  Batch 28,840  of  114,829.    Elapsed: 3:40:47.\n",
            "  Batch 28,880  of  114,829.    Elapsed: 3:41:06.\n",
            "  Batch 28,920  of  114,829.    Elapsed: 3:41:24.\n",
            "  Batch 28,960  of  114,829.    Elapsed: 3:41:42.\n",
            "  Batch 29,000  of  114,829.    Elapsed: 3:42:01.\n",
            "  Batch 29,040  of  114,829.    Elapsed: 3:42:19.\n",
            "  Batch 29,080  of  114,829.    Elapsed: 3:42:37.\n",
            "  Batch 29,120  of  114,829.    Elapsed: 3:42:56.\n",
            "  Batch 29,160  of  114,829.    Elapsed: 3:43:14.\n",
            "  Batch 29,200  of  114,829.    Elapsed: 3:43:33.\n",
            "  Batch 29,240  of  114,829.    Elapsed: 3:43:51.\n",
            "  Batch 29,280  of  114,829.    Elapsed: 3:44:09.\n",
            "  Batch 29,320  of  114,829.    Elapsed: 3:44:28.\n",
            "  Batch 29,360  of  114,829.    Elapsed: 3:44:46.\n",
            "  Batch 29,400  of  114,829.    Elapsed: 3:45:04.\n",
            "  Batch 29,440  of  114,829.    Elapsed: 3:45:23.\n",
            "  Batch 29,480  of  114,829.    Elapsed: 3:45:41.\n",
            "  Batch 29,520  of  114,829.    Elapsed: 3:46:00.\n",
            "  Batch 29,560  of  114,829.    Elapsed: 3:46:18.\n",
            "  Batch 29,600  of  114,829.    Elapsed: 3:46:36.\n",
            "  Batch 29,640  of  114,829.    Elapsed: 3:46:55.\n",
            "  Batch 29,680  of  114,829.    Elapsed: 3:47:13.\n",
            "  Batch 29,720  of  114,829.    Elapsed: 3:47:31.\n",
            "  Batch 29,760  of  114,829.    Elapsed: 3:47:50.\n",
            "  Batch 29,800  of  114,829.    Elapsed: 3:48:08.\n",
            "  Batch 29,840  of  114,829.    Elapsed: 3:48:26.\n",
            "  Batch 29,880  of  114,829.    Elapsed: 3:48:45.\n",
            "  Batch 29,920  of  114,829.    Elapsed: 3:49:03.\n",
            "  Batch 29,960  of  114,829.    Elapsed: 3:49:22.\n",
            "  Batch 30,000  of  114,829.    Elapsed: 3:49:40.\n",
            "  Batch 30,040  of  114,829.    Elapsed: 3:49:58.\n",
            "  Batch 30,080  of  114,829.    Elapsed: 3:50:17.\n",
            "  Batch 30,120  of  114,829.    Elapsed: 3:50:35.\n",
            "  Batch 30,160  of  114,829.    Elapsed: 3:50:54.\n",
            "  Batch 30,200  of  114,829.    Elapsed: 3:51:12.\n",
            "  Batch 30,240  of  114,829.    Elapsed: 3:51:30.\n",
            "  Batch 30,280  of  114,829.    Elapsed: 3:51:49.\n",
            "  Batch 30,320  of  114,829.    Elapsed: 3:52:07.\n",
            "  Batch 30,360  of  114,829.    Elapsed: 3:52:25.\n",
            "  Batch 30,400  of  114,829.    Elapsed: 3:52:44.\n",
            "  Batch 30,440  of  114,829.    Elapsed: 3:53:02.\n",
            "  Batch 30,480  of  114,829.    Elapsed: 3:53:20.\n",
            "  Batch 30,520  of  114,829.    Elapsed: 3:53:39.\n",
            "  Batch 30,560  of  114,829.    Elapsed: 3:53:57.\n",
            "  Batch 30,600  of  114,829.    Elapsed: 3:54:16.\n",
            "  Batch 30,640  of  114,829.    Elapsed: 3:54:34.\n",
            "  Batch 30,680  of  114,829.    Elapsed: 3:54:52.\n",
            "  Batch 30,720  of  114,829.    Elapsed: 3:55:11.\n",
            "  Batch 30,760  of  114,829.    Elapsed: 3:55:29.\n",
            "  Batch 30,800  of  114,829.    Elapsed: 3:55:47.\n",
            "  Batch 30,840  of  114,829.    Elapsed: 3:56:06.\n",
            "  Batch 30,880  of  114,829.    Elapsed: 3:56:24.\n",
            "  Batch 30,920  of  114,829.    Elapsed: 3:56:43.\n",
            "  Batch 30,960  of  114,829.    Elapsed: 3:57:01.\n",
            "  Batch 31,000  of  114,829.    Elapsed: 3:57:19.\n",
            "  Batch 31,040  of  114,829.    Elapsed: 3:57:38.\n",
            "  Batch 31,080  of  114,829.    Elapsed: 3:57:56.\n",
            "  Batch 31,120  of  114,829.    Elapsed: 3:58:14.\n",
            "  Batch 31,160  of  114,829.    Elapsed: 3:58:33.\n",
            "  Batch 31,200  of  114,829.    Elapsed: 3:58:51.\n",
            "  Batch 31,240  of  114,829.    Elapsed: 3:59:09.\n",
            "  Batch 31,280  of  114,829.    Elapsed: 3:59:28.\n",
            "  Batch 31,320  of  114,829.    Elapsed: 3:59:46.\n",
            "  Batch 31,360  of  114,829.    Elapsed: 4:00:05.\n",
            "  Batch 31,400  of  114,829.    Elapsed: 4:00:23.\n",
            "  Batch 31,440  of  114,829.    Elapsed: 4:00:41.\n",
            "  Batch 31,480  of  114,829.    Elapsed: 4:01:00.\n",
            "  Batch 31,520  of  114,829.    Elapsed: 4:01:18.\n",
            "  Batch 31,560  of  114,829.    Elapsed: 4:01:37.\n",
            "  Batch 31,600  of  114,829.    Elapsed: 4:01:55.\n",
            "  Batch 31,640  of  114,829.    Elapsed: 4:02:13.\n",
            "  Batch 31,680  of  114,829.    Elapsed: 4:02:32.\n",
            "  Batch 31,720  of  114,829.    Elapsed: 4:02:50.\n",
            "  Batch 31,760  of  114,829.    Elapsed: 4:03:08.\n",
            "  Batch 31,800  of  114,829.    Elapsed: 4:03:27.\n",
            "  Batch 31,840  of  114,829.    Elapsed: 4:03:45.\n",
            "  Batch 31,880  of  114,829.    Elapsed: 4:04:03.\n",
            "  Batch 31,920  of  114,829.    Elapsed: 4:04:22.\n",
            "  Batch 31,960  of  114,829.    Elapsed: 4:04:40.\n",
            "  Batch 32,000  of  114,829.    Elapsed: 4:04:59.\n",
            "  Batch 32,040  of  114,829.    Elapsed: 4:05:17.\n",
            "  Batch 32,080  of  114,829.    Elapsed: 4:05:35.\n",
            "  Batch 32,120  of  114,829.    Elapsed: 4:05:54.\n",
            "  Batch 32,160  of  114,829.    Elapsed: 4:06:12.\n",
            "  Batch 32,200  of  114,829.    Elapsed: 4:06:30.\n",
            "  Batch 32,240  of  114,829.    Elapsed: 4:06:49.\n",
            "  Batch 32,280  of  114,829.    Elapsed: 4:07:07.\n",
            "  Batch 32,320  of  114,829.    Elapsed: 4:07:26.\n",
            "  Batch 32,360  of  114,829.    Elapsed: 4:07:44.\n",
            "  Batch 32,400  of  114,829.    Elapsed: 4:08:02.\n",
            "  Batch 32,440  of  114,829.    Elapsed: 4:08:21.\n",
            "  Batch 32,480  of  114,829.    Elapsed: 4:08:39.\n",
            "  Batch 32,520  of  114,829.    Elapsed: 4:08:57.\n",
            "  Batch 32,560  of  114,829.    Elapsed: 4:09:16.\n",
            "  Batch 32,600  of  114,829.    Elapsed: 4:09:34.\n",
            "  Batch 32,640  of  114,829.    Elapsed: 4:09:53.\n",
            "  Batch 32,680  of  114,829.    Elapsed: 4:10:11.\n",
            "  Batch 32,720  of  114,829.    Elapsed: 4:10:29.\n",
            "  Batch 32,760  of  114,829.    Elapsed: 4:10:48.\n",
            "  Batch 32,800  of  114,829.    Elapsed: 4:11:06.\n",
            "  Batch 32,840  of  114,829.    Elapsed: 4:11:24.\n",
            "  Batch 32,880  of  114,829.    Elapsed: 4:11:43.\n",
            "  Batch 32,920  of  114,829.    Elapsed: 4:12:01.\n",
            "  Batch 32,960  of  114,829.    Elapsed: 4:12:20.\n",
            "  Batch 33,000  of  114,829.    Elapsed: 4:12:38.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 33,040  of  114,829.    Elapsed: 4:12:56.\n",
            "  Batch 33,080  of  114,829.    Elapsed: 4:13:15.\n",
            "  Batch 33,120  of  114,829.    Elapsed: 4:13:33.\n",
            "  Batch 33,160  of  114,829.    Elapsed: 4:13:51.\n",
            "  Batch 33,200  of  114,829.    Elapsed: 4:14:10.\n",
            "  Batch 33,240  of  114,829.    Elapsed: 4:14:28.\n",
            "  Batch 33,280  of  114,829.    Elapsed: 4:14:46.\n",
            "  Batch 33,320  of  114,829.    Elapsed: 4:15:05.\n",
            "  Batch 33,360  of  114,829.    Elapsed: 4:15:23.\n",
            "  Batch 33,400  of  114,829.    Elapsed: 4:15:41.\n",
            "  Batch 33,440  of  114,829.    Elapsed: 4:16:00.\n",
            "  Batch 33,480  of  114,829.    Elapsed: 4:16:18.\n",
            "  Batch 33,520  of  114,829.    Elapsed: 4:16:37.\n",
            "  Batch 33,560  of  114,829.    Elapsed: 4:16:55.\n",
            "  Batch 33,600  of  114,829.    Elapsed: 4:17:13.\n",
            "  Batch 33,640  of  114,829.    Elapsed: 4:17:32.\n",
            "  Batch 33,680  of  114,829.    Elapsed: 4:17:50.\n",
            "  Batch 33,720  of  114,829.    Elapsed: 4:18:08.\n",
            "  Batch 33,760  of  114,829.    Elapsed: 4:18:27.\n",
            "  Batch 33,800  of  114,829.    Elapsed: 4:18:45.\n",
            "  Batch 33,840  of  114,829.    Elapsed: 4:19:03.\n",
            "  Batch 33,880  of  114,829.    Elapsed: 4:19:22.\n",
            "  Batch 33,920  of  114,829.    Elapsed: 4:19:40.\n",
            "  Batch 33,960  of  114,829.    Elapsed: 4:19:59.\n",
            "  Batch 34,000  of  114,829.    Elapsed: 4:20:17.\n",
            "  Batch 34,040  of  114,829.    Elapsed: 4:20:35.\n",
            "  Batch 34,080  of  114,829.    Elapsed: 4:20:54.\n",
            "  Batch 34,120  of  114,829.    Elapsed: 4:21:12.\n",
            "  Batch 34,160  of  114,829.    Elapsed: 4:21:30.\n",
            "  Batch 34,200  of  114,829.    Elapsed: 4:21:49.\n",
            "  Batch 34,240  of  114,829.    Elapsed: 4:22:07.\n",
            "  Batch 34,280  of  114,829.    Elapsed: 4:22:25.\n",
            "  Batch 34,320  of  114,829.    Elapsed: 4:22:44.\n",
            "  Batch 34,360  of  114,829.    Elapsed: 4:23:02.\n",
            "  Batch 34,400  of  114,829.    Elapsed: 4:23:21.\n",
            "  Batch 34,440  of  114,829.    Elapsed: 4:23:39.\n",
            "  Batch 34,480  of  114,829.    Elapsed: 4:23:57.\n",
            "  Batch 34,520  of  114,829.    Elapsed: 4:24:16.\n",
            "  Batch 34,560  of  114,829.    Elapsed: 4:24:34.\n",
            "  Batch 34,600  of  114,829.    Elapsed: 4:24:52.\n",
            "  Batch 34,640  of  114,829.    Elapsed: 4:25:11.\n",
            "  Batch 34,680  of  114,829.    Elapsed: 4:25:29.\n",
            "  Batch 34,720  of  114,829.    Elapsed: 4:25:47.\n",
            "  Batch 34,760  of  114,829.    Elapsed: 4:26:06.\n",
            "  Batch 34,800  of  114,829.    Elapsed: 4:26:24.\n",
            "  Batch 34,840  of  114,829.    Elapsed: 4:26:43.\n",
            "  Batch 34,880  of  114,829.    Elapsed: 4:27:01.\n",
            "  Batch 34,920  of  114,829.    Elapsed: 4:27:19.\n",
            "  Batch 34,960  of  114,829.    Elapsed: 4:27:38.\n",
            "  Batch 35,000  of  114,829.    Elapsed: 4:27:56.\n",
            "  Batch 35,040  of  114,829.    Elapsed: 4:28:14.\n",
            "  Batch 35,080  of  114,829.    Elapsed: 4:28:33.\n",
            "  Batch 35,120  of  114,829.    Elapsed: 4:28:51.\n",
            "  Batch 35,160  of  114,829.    Elapsed: 4:29:10.\n",
            "  Batch 35,200  of  114,829.    Elapsed: 4:29:28.\n",
            "  Batch 35,240  of  114,829.    Elapsed: 4:29:46.\n",
            "  Batch 35,280  of  114,829.    Elapsed: 4:30:05.\n",
            "  Batch 35,320  of  114,829.    Elapsed: 4:30:23.\n",
            "  Batch 35,360  of  114,829.    Elapsed: 4:30:41.\n",
            "  Batch 35,400  of  114,829.    Elapsed: 4:31:00.\n",
            "  Batch 35,440  of  114,829.    Elapsed: 4:31:18.\n",
            "  Batch 35,480  of  114,829.    Elapsed: 4:31:36.\n",
            "  Batch 35,520  of  114,829.    Elapsed: 4:31:55.\n",
            "  Batch 35,560  of  114,829.    Elapsed: 4:32:13.\n",
            "  Batch 35,600  of  114,829.    Elapsed: 4:32:31.\n",
            "  Batch 35,640  of  114,829.    Elapsed: 4:32:50.\n",
            "  Batch 35,680  of  114,829.    Elapsed: 4:33:08.\n",
            "  Batch 35,720  of  114,829.    Elapsed: 4:33:27.\n",
            "  Batch 35,760  of  114,829.    Elapsed: 4:33:45.\n",
            "  Batch 35,800  of  114,829.    Elapsed: 4:34:03.\n",
            "  Batch 35,840  of  114,829.    Elapsed: 4:34:22.\n",
            "  Batch 35,880  of  114,829.    Elapsed: 4:34:40.\n",
            "  Batch 35,920  of  114,829.    Elapsed: 4:34:58.\n",
            "  Batch 35,960  of  114,829.    Elapsed: 4:35:17.\n",
            "  Batch 36,000  of  114,829.    Elapsed: 4:35:35.\n",
            "  Batch 36,040  of  114,829.    Elapsed: 4:35:53.\n",
            "  Batch 36,080  of  114,829.    Elapsed: 4:36:12.\n",
            "  Batch 36,120  of  114,829.    Elapsed: 4:36:30.\n",
            "  Batch 36,160  of  114,829.    Elapsed: 4:36:48.\n",
            "  Batch 36,200  of  114,829.    Elapsed: 4:37:07.\n",
            "  Batch 36,240  of  114,829.    Elapsed: 4:37:25.\n",
            "  Batch 36,280  of  114,829.    Elapsed: 4:37:43.\n",
            "  Batch 36,320  of  114,829.    Elapsed: 4:38:02.\n",
            "  Batch 36,360  of  114,829.    Elapsed: 4:38:20.\n",
            "  Batch 36,400  of  114,829.    Elapsed: 4:38:38.\n",
            "  Batch 36,440  of  114,829.    Elapsed: 4:38:57.\n",
            "  Batch 36,480  of  114,829.    Elapsed: 4:39:15.\n",
            "  Batch 36,520  of  114,829.    Elapsed: 4:39:33.\n",
            "  Batch 36,560  of  114,829.    Elapsed: 4:39:52.\n",
            "  Batch 36,600  of  114,829.    Elapsed: 4:40:10.\n",
            "  Batch 36,640  of  114,829.    Elapsed: 4:40:28.\n",
            "  Batch 36,680  of  114,829.    Elapsed: 4:40:47.\n",
            "  Batch 36,720  of  114,829.    Elapsed: 4:41:05.\n",
            "  Batch 36,760  of  114,829.    Elapsed: 4:41:24.\n",
            "  Batch 36,800  of  114,829.    Elapsed: 4:41:42.\n",
            "  Batch 36,840  of  114,829.    Elapsed: 4:42:00.\n",
            "  Batch 36,880  of  114,829.    Elapsed: 4:42:19.\n",
            "  Batch 36,920  of  114,829.    Elapsed: 4:42:37.\n",
            "  Batch 36,960  of  114,829.    Elapsed: 4:42:55.\n",
            "  Batch 37,000  of  114,829.    Elapsed: 4:43:14.\n",
            "  Batch 37,040  of  114,829.    Elapsed: 4:43:32.\n",
            "  Batch 37,080  of  114,829.    Elapsed: 4:43:50.\n",
            "  Batch 37,120  of  114,829.    Elapsed: 4:44:09.\n",
            "  Batch 37,160  of  114,829.    Elapsed: 4:44:27.\n",
            "  Batch 37,200  of  114,829.    Elapsed: 4:44:45.\n",
            "  Batch 37,240  of  114,829.    Elapsed: 4:45:04.\n",
            "  Batch 37,280  of  114,829.    Elapsed: 4:45:22.\n",
            "  Batch 37,320  of  114,829.    Elapsed: 4:45:40.\n",
            "  Batch 37,360  of  114,829.    Elapsed: 4:45:59.\n",
            "  Batch 37,400  of  114,829.    Elapsed: 4:46:17.\n",
            "  Batch 37,440  of  114,829.    Elapsed: 4:46:35.\n",
            "  Batch 37,480  of  114,829.    Elapsed: 4:46:54.\n",
            "  Batch 37,520  of  114,829.    Elapsed: 4:47:12.\n",
            "  Batch 37,560  of  114,829.    Elapsed: 4:47:31.\n",
            "  Batch 37,600  of  114,829.    Elapsed: 4:47:50.\n",
            "  Batch 37,640  of  114,829.    Elapsed: 4:48:08.\n",
            "  Batch 37,680  of  114,829.    Elapsed: 4:48:27.\n",
            "  Batch 37,720  of  114,829.    Elapsed: 4:48:46.\n",
            "  Batch 37,760  of  114,829.    Elapsed: 4:49:05.\n",
            "  Batch 37,800  of  114,829.    Elapsed: 4:49:24.\n",
            "  Batch 37,840  of  114,829.    Elapsed: 4:49:43.\n",
            "  Batch 37,880  of  114,829.    Elapsed: 4:50:02.\n",
            "  Batch 37,920  of  114,829.    Elapsed: 4:50:20.\n",
            "  Batch 37,960  of  114,829.    Elapsed: 4:50:39.\n",
            "  Batch 38,000  of  114,829.    Elapsed: 4:50:57.\n",
            "  Batch 38,040  of  114,829.    Elapsed: 4:51:16.\n",
            "  Batch 38,080  of  114,829.    Elapsed: 4:51:34.\n",
            "  Batch 38,120  of  114,829.    Elapsed: 4:51:53.\n",
            "  Batch 38,160  of  114,829.    Elapsed: 4:52:11.\n",
            "  Batch 38,200  of  114,829.    Elapsed: 4:52:30.\n",
            "  Batch 38,240  of  114,829.    Elapsed: 4:52:48.\n",
            "  Batch 38,280  of  114,829.    Elapsed: 4:53:07.\n",
            "  Batch 38,320  of  114,829.    Elapsed: 4:53:25.\n",
            "  Batch 38,360  of  114,829.    Elapsed: 4:53:43.\n",
            "  Batch 38,400  of  114,829.    Elapsed: 4:54:02.\n",
            "  Batch 38,440  of  114,829.    Elapsed: 4:54:20.\n",
            "  Batch 38,480  of  114,829.    Elapsed: 4:54:38.\n",
            "  Batch 38,520  of  114,829.    Elapsed: 4:54:57.\n",
            "  Batch 38,560  of  114,829.    Elapsed: 4:55:15.\n",
            "  Batch 38,600  of  114,829.    Elapsed: 4:55:34.\n",
            "  Batch 38,640  of  114,829.    Elapsed: 4:55:52.\n",
            "  Batch 38,680  of  114,829.    Elapsed: 4:56:10.\n",
            "  Batch 38,720  of  114,829.    Elapsed: 4:56:29.\n",
            "  Batch 38,760  of  114,829.    Elapsed: 4:56:47.\n",
            "  Batch 38,800  of  114,829.    Elapsed: 4:57:05.\n",
            "  Batch 38,840  of  114,829.    Elapsed: 4:57:24.\n",
            "  Batch 38,880  of  114,829.    Elapsed: 4:57:42.\n",
            "  Batch 38,920  of  114,829.    Elapsed: 4:58:01.\n",
            "  Batch 38,960  of  114,829.    Elapsed: 4:58:19.\n",
            "  Batch 39,000  of  114,829.    Elapsed: 4:58:37.\n",
            "  Batch 39,040  of  114,829.    Elapsed: 4:58:56.\n",
            "  Batch 39,080  of  114,829.    Elapsed: 4:59:14.\n",
            "  Batch 39,120  of  114,829.    Elapsed: 4:59:32.\n",
            "  Batch 39,160  of  114,829.    Elapsed: 4:59:51.\n",
            "  Batch 39,200  of  114,829.    Elapsed: 5:00:09.\n",
            "  Batch 39,240  of  114,829.    Elapsed: 5:00:27.\n",
            "  Batch 39,280  of  114,829.    Elapsed: 5:00:46.\n",
            "  Batch 39,320  of  114,829.    Elapsed: 5:01:04.\n",
            "  Batch 39,360  of  114,829.    Elapsed: 5:01:23.\n",
            "  Batch 39,400  of  114,829.    Elapsed: 5:01:41.\n",
            "  Batch 39,440  of  114,829.    Elapsed: 5:01:59.\n",
            "  Batch 39,480  of  114,829.    Elapsed: 5:02:18.\n",
            "  Batch 39,520  of  114,829.    Elapsed: 5:02:36.\n",
            "  Batch 39,560  of  114,829.    Elapsed: 5:02:54.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 39,600  of  114,829.    Elapsed: 5:03:13.\n",
            "  Batch 39,640  of  114,829.    Elapsed: 5:03:31.\n",
            "  Batch 39,680  of  114,829.    Elapsed: 5:03:49.\n",
            "  Batch 39,720  of  114,829.    Elapsed: 5:04:08.\n",
            "  Batch 39,760  of  114,829.    Elapsed: 5:04:26.\n",
            "  Batch 39,800  of  114,829.    Elapsed: 5:04:44.\n",
            "  Batch 39,840  of  114,829.    Elapsed: 5:05:03.\n",
            "  Batch 39,880  of  114,829.    Elapsed: 5:05:21.\n",
            "  Batch 39,920  of  114,829.    Elapsed: 5:05:40.\n",
            "  Batch 39,960  of  114,829.    Elapsed: 5:05:58.\n",
            "  Batch 40,000  of  114,829.    Elapsed: 5:06:16.\n",
            "  Batch 40,040  of  114,829.    Elapsed: 5:06:35.\n",
            "  Batch 40,080  of  114,829.    Elapsed: 5:06:53.\n",
            "  Batch 40,120  of  114,829.    Elapsed: 5:07:11.\n",
            "  Batch 40,160  of  114,829.    Elapsed: 5:07:30.\n",
            "  Batch 40,200  of  114,829.    Elapsed: 5:07:48.\n",
            "  Batch 40,240  of  114,829.    Elapsed: 5:08:06.\n",
            "  Batch 40,280  of  114,829.    Elapsed: 5:08:25.\n",
            "  Batch 40,320  of  114,829.    Elapsed: 5:08:43.\n",
            "  Batch 40,360  of  114,829.    Elapsed: 5:09:02.\n",
            "  Batch 40,400  of  114,829.    Elapsed: 5:09:20.\n",
            "  Batch 40,440  of  114,829.    Elapsed: 5:09:38.\n",
            "  Batch 40,480  of  114,829.    Elapsed: 5:09:57.\n",
            "  Batch 40,520  of  114,829.    Elapsed: 5:10:15.\n",
            "  Batch 40,560  of  114,829.    Elapsed: 5:10:33.\n",
            "  Batch 40,600  of  114,829.    Elapsed: 5:10:52.\n",
            "  Batch 40,640  of  114,829.    Elapsed: 5:11:10.\n",
            "  Batch 40,680  of  114,829.    Elapsed: 5:11:28.\n",
            "  Batch 40,720  of  114,829.    Elapsed: 5:11:47.\n",
            "  Batch 40,760  of  114,829.    Elapsed: 5:12:05.\n",
            "  Batch 40,800  of  114,829.    Elapsed: 5:12:24.\n",
            "  Batch 40,840  of  114,829.    Elapsed: 5:12:42.\n",
            "  Batch 40,880  of  114,829.    Elapsed: 5:13:00.\n",
            "  Batch 40,920  of  114,829.    Elapsed: 5:13:19.\n",
            "  Batch 40,960  of  114,829.    Elapsed: 5:13:37.\n",
            "  Batch 41,000  of  114,829.    Elapsed: 5:13:55.\n",
            "  Batch 41,040  of  114,829.    Elapsed: 5:14:14.\n",
            "  Batch 41,080  of  114,829.    Elapsed: 5:14:32.\n",
            "  Batch 41,120  of  114,829.    Elapsed: 5:14:50.\n",
            "  Batch 41,160  of  114,829.    Elapsed: 5:15:09.\n",
            "  Batch 41,200  of  114,829.    Elapsed: 5:15:27.\n",
            "  Batch 41,240  of  114,829.    Elapsed: 5:15:46.\n",
            "  Batch 41,280  of  114,829.    Elapsed: 5:16:04.\n",
            "  Batch 41,320  of  114,829.    Elapsed: 5:16:22.\n",
            "  Batch 41,360  of  114,829.    Elapsed: 5:16:41.\n",
            "  Batch 41,400  of  114,829.    Elapsed: 5:16:59.\n",
            "  Batch 41,440  of  114,829.    Elapsed: 5:17:17.\n",
            "  Batch 41,480  of  114,829.    Elapsed: 5:17:36.\n",
            "  Batch 41,520  of  114,829.    Elapsed: 5:17:54.\n",
            "  Batch 41,560  of  114,829.    Elapsed: 5:18:12.\n",
            "  Batch 41,600  of  114,829.    Elapsed: 5:18:31.\n",
            "  Batch 41,640  of  114,829.    Elapsed: 5:18:49.\n",
            "  Batch 41,680  of  114,829.    Elapsed: 5:19:08.\n",
            "  Batch 41,720  of  114,829.    Elapsed: 5:19:26.\n",
            "  Batch 41,760  of  114,829.    Elapsed: 5:19:44.\n",
            "  Batch 41,800  of  114,829.    Elapsed: 5:20:03.\n",
            "  Batch 41,840  of  114,829.    Elapsed: 5:20:21.\n",
            "  Batch 41,880  of  114,829.    Elapsed: 5:20:39.\n",
            "  Batch 41,920  of  114,829.    Elapsed: 5:20:58.\n",
            "  Batch 41,960  of  114,829.    Elapsed: 5:21:16.\n",
            "  Batch 42,000  of  114,829.    Elapsed: 5:21:34.\n",
            "  Batch 42,040  of  114,829.    Elapsed: 5:21:53.\n",
            "  Batch 42,080  of  114,829.    Elapsed: 5:22:11.\n",
            "  Batch 42,120  of  114,829.    Elapsed: 5:22:29.\n",
            "  Batch 42,160  of  114,829.    Elapsed: 5:22:48.\n",
            "  Batch 42,200  of  114,829.    Elapsed: 5:23:06.\n",
            "  Batch 42,240  of  114,829.    Elapsed: 5:23:25.\n",
            "  Batch 42,280  of  114,829.    Elapsed: 5:23:43.\n",
            "  Batch 42,320  of  114,829.    Elapsed: 5:24:01.\n",
            "  Batch 42,360  of  114,829.    Elapsed: 5:24:20.\n",
            "  Batch 42,400  of  114,829.    Elapsed: 5:24:38.\n",
            "  Batch 42,440  of  114,829.    Elapsed: 5:24:56.\n",
            "  Batch 42,480  of  114,829.    Elapsed: 5:25:15.\n",
            "  Batch 42,520  of  114,829.    Elapsed: 5:25:33.\n",
            "  Batch 42,560  of  114,829.    Elapsed: 5:25:51.\n",
            "  Batch 42,600  of  114,829.    Elapsed: 5:26:10.\n",
            "  Batch 42,640  of  114,829.    Elapsed: 5:26:28.\n",
            "  Batch 42,680  of  114,829.    Elapsed: 5:26:46.\n",
            "  Batch 42,720  of  114,829.    Elapsed: 5:27:05.\n",
            "  Batch 42,760  of  114,829.    Elapsed: 5:27:23.\n",
            "  Batch 42,800  of  114,829.    Elapsed: 5:27:41.\n",
            "  Batch 42,840  of  114,829.    Elapsed: 5:28:00.\n",
            "  Batch 42,880  of  114,829.    Elapsed: 5:28:18.\n",
            "  Batch 42,920  of  114,829.    Elapsed: 5:28:37.\n",
            "  Batch 42,960  of  114,829.    Elapsed: 5:28:56.\n",
            "  Batch 43,000  of  114,829.    Elapsed: 5:29:14.\n",
            "  Batch 43,040  of  114,829.    Elapsed: 5:29:33.\n",
            "  Batch 43,080  of  114,829.    Elapsed: 5:29:51.\n",
            "  Batch 43,120  of  114,829.    Elapsed: 5:30:10.\n",
            "  Batch 43,160  of  114,829.    Elapsed: 5:30:28.\n",
            "  Batch 43,200  of  114,829.    Elapsed: 5:30:47.\n",
            "  Batch 43,240  of  114,829.    Elapsed: 5:31:05.\n",
            "  Batch 43,280  of  114,829.    Elapsed: 5:31:23.\n",
            "  Batch 43,320  of  114,829.    Elapsed: 5:31:42.\n",
            "  Batch 43,360  of  114,829.    Elapsed: 5:32:00.\n",
            "  Batch 43,400  of  114,829.    Elapsed: 5:32:19.\n",
            "  Batch 43,440  of  114,829.    Elapsed: 5:32:37.\n",
            "  Batch 43,480  of  114,829.    Elapsed: 5:32:55.\n",
            "  Batch 43,520  of  114,829.    Elapsed: 5:33:14.\n",
            "  Batch 43,560  of  114,829.    Elapsed: 5:33:33.\n",
            "  Batch 43,600  of  114,829.    Elapsed: 5:33:51.\n",
            "  Batch 43,640  of  114,829.    Elapsed: 5:34:10.\n",
            "  Batch 43,680  of  114,829.    Elapsed: 5:34:28.\n",
            "  Batch 43,720  of  114,829.    Elapsed: 5:34:47.\n",
            "  Batch 43,760  of  114,829.    Elapsed: 5:35:05.\n",
            "  Batch 43,800  of  114,829.    Elapsed: 5:35:23.\n",
            "  Batch 43,840  of  114,829.    Elapsed: 5:35:42.\n",
            "  Batch 43,880  of  114,829.    Elapsed: 5:36:00.\n",
            "  Batch 43,920  of  114,829.    Elapsed: 5:36:18.\n",
            "  Batch 43,960  of  114,829.    Elapsed: 5:36:37.\n",
            "  Batch 44,000  of  114,829.    Elapsed: 5:36:56.\n",
            "  Batch 44,040  of  114,829.    Elapsed: 5:37:15.\n",
            "  Batch 44,080  of  114,829.    Elapsed: 5:37:33.\n",
            "  Batch 44,120  of  114,829.    Elapsed: 5:37:52.\n",
            "  Batch 44,160  of  114,829.    Elapsed: 5:38:10.\n",
            "  Batch 44,200  of  114,829.    Elapsed: 5:38:29.\n",
            "  Batch 44,240  of  114,829.    Elapsed: 5:38:47.\n",
            "  Batch 44,280  of  114,829.    Elapsed: 5:39:05.\n",
            "  Batch 44,320  of  114,829.    Elapsed: 5:39:24.\n",
            "  Batch 44,360  of  114,829.    Elapsed: 5:39:42.\n",
            "  Batch 44,400  of  114,829.    Elapsed: 5:40:00.\n",
            "  Batch 44,440  of  114,829.    Elapsed: 5:40:19.\n",
            "  Batch 44,480  of  114,829.    Elapsed: 5:40:37.\n",
            "  Batch 44,520  of  114,829.    Elapsed: 5:40:56.\n",
            "  Batch 44,560  of  114,829.    Elapsed: 5:41:14.\n",
            "  Batch 44,600  of  114,829.    Elapsed: 5:41:32.\n",
            "  Batch 44,640  of  114,829.    Elapsed: 5:41:51.\n",
            "  Batch 44,680  of  114,829.    Elapsed: 5:42:09.\n",
            "  Batch 44,720  of  114,829.    Elapsed: 5:42:27.\n",
            "  Batch 44,760  of  114,829.    Elapsed: 5:42:46.\n",
            "  Batch 44,800  of  114,829.    Elapsed: 5:43:04.\n",
            "  Batch 44,840  of  114,829.    Elapsed: 5:43:22.\n",
            "  Batch 44,880  of  114,829.    Elapsed: 5:43:41.\n",
            "  Batch 44,920  of  114,829.    Elapsed: 5:43:59.\n",
            "  Batch 44,960  of  114,829.    Elapsed: 5:44:17.\n",
            "  Batch 45,000  of  114,829.    Elapsed: 5:44:36.\n",
            "  Batch 45,040  of  114,829.    Elapsed: 5:44:54.\n",
            "  Batch 45,080  of  114,829.    Elapsed: 5:45:12.\n",
            "  Batch 45,120  of  114,829.    Elapsed: 5:45:31.\n",
            "  Batch 45,160  of  114,829.    Elapsed: 5:45:49.\n",
            "  Batch 45,200  of  114,829.    Elapsed: 5:46:08.\n",
            "  Batch 45,240  of  114,829.    Elapsed: 5:46:26.\n",
            "  Batch 45,280  of  114,829.    Elapsed: 5:46:44.\n",
            "  Batch 45,320  of  114,829.    Elapsed: 5:47:03.\n",
            "  Batch 45,360  of  114,829.    Elapsed: 5:47:21.\n",
            "  Batch 45,400  of  114,829.    Elapsed: 5:47:39.\n",
            "  Batch 45,440  of  114,829.    Elapsed: 5:47:58.\n",
            "  Batch 45,480  of  114,829.    Elapsed: 5:48:16.\n",
            "  Batch 45,520  of  114,829.    Elapsed: 5:48:34.\n",
            "  Batch 45,560  of  114,829.    Elapsed: 5:48:53.\n",
            "  Batch 45,600  of  114,829.    Elapsed: 5:49:11.\n",
            "  Batch 45,640  of  114,829.    Elapsed: 5:49:29.\n",
            "  Batch 45,680  of  114,829.    Elapsed: 5:49:48.\n",
            "  Batch 45,720  of  114,829.    Elapsed: 5:50:06.\n",
            "  Batch 45,760  of  114,829.    Elapsed: 5:50:25.\n",
            "  Batch 45,800  of  114,829.    Elapsed: 5:50:43.\n",
            "  Batch 45,840  of  114,829.    Elapsed: 5:51:01.\n",
            "  Batch 45,880  of  114,829.    Elapsed: 5:51:20.\n",
            "  Batch 45,920  of  114,829.    Elapsed: 5:51:38.\n",
            "  Batch 45,960  of  114,829.    Elapsed: 5:51:56.\n",
            "  Batch 46,000  of  114,829.    Elapsed: 5:52:15.\n",
            "  Batch 46,040  of  114,829.    Elapsed: 5:52:33.\n",
            "  Batch 46,080  of  114,829.    Elapsed: 5:52:51.\n",
            "  Batch 46,120  of  114,829.    Elapsed: 5:53:10.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 46,160  of  114,829.    Elapsed: 5:53:28.\n",
            "  Batch 46,200  of  114,829.    Elapsed: 5:53:46.\n",
            "  Batch 46,240  of  114,829.    Elapsed: 5:54:05.\n",
            "  Batch 46,280  of  114,829.    Elapsed: 5:54:23.\n",
            "  Batch 46,320  of  114,829.    Elapsed: 5:54:42.\n",
            "  Batch 46,360  of  114,829.    Elapsed: 5:55:00.\n",
            "  Batch 46,400  of  114,829.    Elapsed: 5:55:18.\n",
            "  Batch 46,440  of  114,829.    Elapsed: 5:55:37.\n",
            "  Batch 46,480  of  114,829.    Elapsed: 5:55:55.\n",
            "  Batch 46,520  of  114,829.    Elapsed: 5:56:13.\n",
            "  Batch 46,560  of  114,829.    Elapsed: 5:56:32.\n",
            "  Batch 46,600  of  114,829.    Elapsed: 5:56:50.\n",
            "  Batch 46,640  of  114,829.    Elapsed: 5:57:08.\n",
            "  Batch 46,680  of  114,829.    Elapsed: 5:57:27.\n",
            "  Batch 46,720  of  114,829.    Elapsed: 5:57:45.\n",
            "  Batch 46,760  of  114,829.    Elapsed: 5:58:03.\n",
            "  Batch 46,800  of  114,829.    Elapsed: 5:58:22.\n",
            "  Batch 46,840  of  114,829.    Elapsed: 5:58:40.\n",
            "  Batch 46,880  of  114,829.    Elapsed: 5:58:59.\n",
            "  Batch 46,920  of  114,829.    Elapsed: 5:59:17.\n",
            "  Batch 46,960  of  114,829.    Elapsed: 5:59:35.\n",
            "  Batch 47,000  of  114,829.    Elapsed: 5:59:54.\n",
            "  Batch 47,040  of  114,829.    Elapsed: 6:00:12.\n",
            "  Batch 47,080  of  114,829.    Elapsed: 6:00:30.\n",
            "  Batch 47,120  of  114,829.    Elapsed: 6:00:49.\n",
            "  Batch 47,160  of  114,829.    Elapsed: 6:01:07.\n",
            "  Batch 47,200  of  114,829.    Elapsed: 6:01:25.\n",
            "  Batch 47,240  of  114,829.    Elapsed: 6:01:44.\n",
            "  Batch 47,280  of  114,829.    Elapsed: 6:02:02.\n",
            "  Batch 47,320  of  114,829.    Elapsed: 6:02:20.\n",
            "  Batch 47,360  of  114,829.    Elapsed: 6:02:39.\n",
            "  Batch 47,400  of  114,829.    Elapsed: 6:02:57.\n",
            "  Batch 47,440  of  114,829.    Elapsed: 6:03:16.\n",
            "  Batch 47,480  of  114,829.    Elapsed: 6:03:34.\n",
            "  Batch 47,520  of  114,829.    Elapsed: 6:03:52.\n",
            "  Batch 47,560  of  114,829.    Elapsed: 6:04:11.\n",
            "  Batch 47,600  of  114,829.    Elapsed: 6:04:29.\n",
            "  Batch 47,640  of  114,829.    Elapsed: 6:04:47.\n",
            "  Batch 47,680  of  114,829.    Elapsed: 6:05:06.\n",
            "  Batch 47,720  of  114,829.    Elapsed: 6:05:24.\n",
            "  Batch 47,760  of  114,829.    Elapsed: 6:05:42.\n",
            "  Batch 47,800  of  114,829.    Elapsed: 6:06:01.\n",
            "  Batch 47,840  of  114,829.    Elapsed: 6:06:19.\n",
            "  Batch 47,880  of  114,829.    Elapsed: 6:06:38.\n",
            "  Batch 47,920  of  114,829.    Elapsed: 6:06:56.\n",
            "  Batch 47,960  of  114,829.    Elapsed: 6:07:14.\n",
            "  Batch 48,000  of  114,829.    Elapsed: 6:07:33.\n",
            "  Batch 48,040  of  114,829.    Elapsed: 6:07:51.\n",
            "  Batch 48,080  of  114,829.    Elapsed: 6:08:09.\n",
            "  Batch 48,120  of  114,829.    Elapsed: 6:08:28.\n",
            "  Batch 48,160  of  114,829.    Elapsed: 6:08:46.\n",
            "  Batch 48,200  of  114,829.    Elapsed: 6:09:04.\n",
            "  Batch 48,240  of  114,829.    Elapsed: 6:09:23.\n",
            "  Batch 48,280  of  114,829.    Elapsed: 6:09:41.\n",
            "  Batch 48,320  of  114,829.    Elapsed: 6:10:00.\n",
            "  Batch 48,360  of  114,829.    Elapsed: 6:10:18.\n",
            "  Batch 48,400  of  114,829.    Elapsed: 6:10:36.\n",
            "  Batch 48,440  of  114,829.    Elapsed: 6:10:55.\n",
            "  Batch 48,480  of  114,829.    Elapsed: 6:11:13.\n",
            "  Batch 48,520  of  114,829.    Elapsed: 6:11:31.\n",
            "  Batch 48,560  of  114,829.    Elapsed: 6:11:50.\n",
            "  Batch 48,600  of  114,829.    Elapsed: 6:12:08.\n",
            "  Batch 48,640  of  114,829.    Elapsed: 6:12:26.\n",
            "  Batch 48,680  of  114,829.    Elapsed: 6:12:45.\n",
            "  Batch 48,720  of  114,829.    Elapsed: 6:13:03.\n",
            "  Batch 48,760  of  114,829.    Elapsed: 6:13:21.\n",
            "  Batch 48,800  of  114,829.    Elapsed: 6:13:40.\n",
            "  Batch 48,840  of  114,829.    Elapsed: 6:13:58.\n",
            "  Batch 48,880  of  114,829.    Elapsed: 6:14:17.\n",
            "  Batch 48,920  of  114,829.    Elapsed: 6:14:35.\n",
            "  Batch 48,960  of  114,829.    Elapsed: 6:14:53.\n",
            "  Batch 49,000  of  114,829.    Elapsed: 6:15:12.\n",
            "  Batch 49,040  of  114,829.    Elapsed: 6:15:30.\n",
            "  Batch 49,080  of  114,829.    Elapsed: 6:15:48.\n",
            "  Batch 49,120  of  114,829.    Elapsed: 6:16:07.\n",
            "  Batch 49,160  of  114,829.    Elapsed: 6:16:25.\n",
            "  Batch 49,200  of  114,829.    Elapsed: 6:16:43.\n",
            "  Batch 49,240  of  114,829.    Elapsed: 6:17:02.\n",
            "  Batch 49,280  of  114,829.    Elapsed: 6:17:20.\n",
            "  Batch 49,320  of  114,829.    Elapsed: 6:17:38.\n",
            "  Batch 49,360  of  114,829.    Elapsed: 6:17:57.\n",
            "  Batch 49,400  of  114,829.    Elapsed: 6:18:15.\n",
            "  Batch 49,440  of  114,829.    Elapsed: 6:18:33.\n",
            "  Batch 49,480  of  114,829.    Elapsed: 6:18:52.\n",
            "  Batch 49,520  of  114,829.    Elapsed: 6:19:10.\n",
            "  Batch 49,560  of  114,829.    Elapsed: 6:19:29.\n",
            "  Batch 49,600  of  114,829.    Elapsed: 6:19:47.\n",
            "  Batch 49,640  of  114,829.    Elapsed: 6:20:05.\n",
            "  Batch 49,680  of  114,829.    Elapsed: 6:20:24.\n",
            "  Batch 49,720  of  114,829.    Elapsed: 6:20:42.\n",
            "  Batch 49,760  of  114,829.    Elapsed: 6:21:00.\n",
            "  Batch 49,800  of  114,829.    Elapsed: 6:21:19.\n",
            "  Batch 49,840  of  114,829.    Elapsed: 6:21:37.\n",
            "  Batch 49,880  of  114,829.    Elapsed: 6:21:55.\n",
            "  Batch 49,920  of  114,829.    Elapsed: 6:22:14.\n",
            "  Batch 49,960  of  114,829.    Elapsed: 6:22:32.\n",
            "  Batch 50,000  of  114,829.    Elapsed: 6:22:50.\n",
            "  Batch 50,040  of  114,829.    Elapsed: 6:23:09.\n",
            "  Batch 50,080  of  114,829.    Elapsed: 6:23:27.\n",
            "  Batch 50,120  of  114,829.    Elapsed: 6:23:46.\n",
            "  Batch 50,160  of  114,829.    Elapsed: 6:24:04.\n",
            "  Batch 50,200  of  114,829.    Elapsed: 6:24:22.\n",
            "  Batch 50,240  of  114,829.    Elapsed: 6:24:41.\n",
            "  Batch 50,280  of  114,829.    Elapsed: 6:24:59.\n",
            "  Batch 50,320  of  114,829.    Elapsed: 6:25:17.\n",
            "  Batch 50,360  of  114,829.    Elapsed: 6:25:36.\n",
            "  Batch 50,400  of  114,829.    Elapsed: 6:25:54.\n",
            "  Batch 50,440  of  114,829.    Elapsed: 6:26:12.\n",
            "  Batch 50,480  of  114,829.    Elapsed: 6:26:31.\n",
            "  Batch 50,520  of  114,829.    Elapsed: 6:26:49.\n",
            "  Batch 50,560  of  114,829.    Elapsed: 6:27:08.\n",
            "  Batch 50,600  of  114,829.    Elapsed: 6:27:26.\n",
            "  Batch 50,640  of  114,829.    Elapsed: 6:27:44.\n",
            "  Batch 50,680  of  114,829.    Elapsed: 6:28:03.\n",
            "  Batch 50,720  of  114,829.    Elapsed: 6:28:21.\n",
            "  Batch 50,760  of  114,829.    Elapsed: 6:28:39.\n",
            "  Batch 50,800  of  114,829.    Elapsed: 6:28:58.\n",
            "  Batch 50,840  of  114,829.    Elapsed: 6:29:16.\n",
            "  Batch 50,880  of  114,829.    Elapsed: 6:29:34.\n",
            "  Batch 50,920  of  114,829.    Elapsed: 6:29:53.\n",
            "  Batch 50,960  of  114,829.    Elapsed: 6:30:11.\n",
            "  Batch 51,000  of  114,829.    Elapsed: 6:30:30.\n",
            "  Batch 51,040  of  114,829.    Elapsed: 6:30:48.\n",
            "  Batch 51,080  of  114,829.    Elapsed: 6:31:06.\n",
            "  Batch 51,120  of  114,829.    Elapsed: 6:31:25.\n",
            "  Batch 51,160  of  114,829.    Elapsed: 6:31:43.\n",
            "  Batch 51,200  of  114,829.    Elapsed: 6:32:01.\n",
            "  Batch 51,240  of  114,829.    Elapsed: 6:32:20.\n",
            "  Batch 51,280  of  114,829.    Elapsed: 6:32:38.\n",
            "  Batch 51,320  of  114,829.    Elapsed: 6:32:56.\n",
            "  Batch 51,360  of  114,829.    Elapsed: 6:33:15.\n",
            "  Batch 51,400  of  114,829.    Elapsed: 6:33:33.\n",
            "  Batch 51,440  of  114,829.    Elapsed: 6:33:51.\n",
            "  Batch 51,480  of  114,829.    Elapsed: 6:34:10.\n",
            "  Batch 51,520  of  114,829.    Elapsed: 6:34:28.\n",
            "  Batch 51,560  of  114,829.    Elapsed: 6:34:47.\n",
            "  Batch 51,600  of  114,829.    Elapsed: 6:35:05.\n",
            "  Batch 51,640  of  114,829.    Elapsed: 6:35:23.\n",
            "  Batch 51,680  of  114,829.    Elapsed: 6:35:42.\n",
            "  Batch 51,720  of  114,829.    Elapsed: 6:36:00.\n",
            "  Batch 51,760  of  114,829.    Elapsed: 6:36:18.\n",
            "  Batch 51,800  of  114,829.    Elapsed: 6:36:37.\n",
            "  Batch 51,840  of  114,829.    Elapsed: 6:36:55.\n",
            "  Batch 51,880  of  114,829.    Elapsed: 6:37:13.\n",
            "  Batch 51,920  of  114,829.    Elapsed: 6:37:32.\n",
            "  Batch 51,960  of  114,829.    Elapsed: 6:37:50.\n",
            "  Batch 52,000  of  114,829.    Elapsed: 6:38:08.\n",
            "  Batch 52,040  of  114,829.    Elapsed: 6:38:27.\n",
            "  Batch 52,080  of  114,829.    Elapsed: 6:38:45.\n",
            "  Batch 52,120  of  114,829.    Elapsed: 6:39:04.\n",
            "  Batch 52,160  of  114,829.    Elapsed: 6:39:22.\n",
            "  Batch 52,200  of  114,829.    Elapsed: 6:39:40.\n",
            "  Batch 52,240  of  114,829.    Elapsed: 6:39:59.\n",
            "  Batch 52,280  of  114,829.    Elapsed: 6:40:17.\n",
            "  Batch 52,320  of  114,829.    Elapsed: 6:40:35.\n",
            "  Batch 52,360  of  114,829.    Elapsed: 6:40:54.\n",
            "  Batch 52,400  of  114,829.    Elapsed: 6:41:12.\n",
            "  Batch 52,440  of  114,829.    Elapsed: 6:41:31.\n",
            "  Batch 52,480  of  114,829.    Elapsed: 6:41:49.\n",
            "  Batch 52,520  of  114,829.    Elapsed: 6:42:07.\n",
            "  Batch 52,560  of  114,829.    Elapsed: 6:42:26.\n",
            "  Batch 52,600  of  114,829.    Elapsed: 6:42:44.\n",
            "  Batch 52,640  of  114,829.    Elapsed: 6:43:03.\n",
            "  Batch 52,680  of  114,829.    Elapsed: 6:43:21.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 52,720  of  114,829.    Elapsed: 6:43:39.\n",
            "  Batch 52,760  of  114,829.    Elapsed: 6:43:58.\n",
            "  Batch 52,800  of  114,829.    Elapsed: 6:44:16.\n",
            "  Batch 52,840  of  114,829.    Elapsed: 6:44:34.\n",
            "  Batch 52,880  of  114,829.    Elapsed: 6:44:53.\n",
            "  Batch 52,920  of  114,829.    Elapsed: 6:45:11.\n",
            "  Batch 52,960  of  114,829.    Elapsed: 6:45:30.\n",
            "  Batch 53,000  of  114,829.    Elapsed: 6:45:48.\n",
            "  Batch 53,040  of  114,829.    Elapsed: 6:46:06.\n",
            "  Batch 53,080  of  114,829.    Elapsed: 6:46:25.\n",
            "  Batch 53,120  of  114,829.    Elapsed: 6:46:43.\n",
            "  Batch 53,160  of  114,829.    Elapsed: 6:47:01.\n",
            "  Batch 53,200  of  114,829.    Elapsed: 6:47:20.\n",
            "  Batch 53,240  of  114,829.    Elapsed: 6:47:38.\n",
            "  Batch 53,280  of  114,829.    Elapsed: 6:47:56.\n",
            "  Batch 53,320  of  114,829.    Elapsed: 6:48:15.\n",
            "  Batch 53,360  of  114,829.    Elapsed: 6:48:33.\n",
            "  Batch 53,400  of  114,829.    Elapsed: 6:48:52.\n",
            "  Batch 53,440  of  114,829.    Elapsed: 6:49:10.\n",
            "  Batch 53,480  of  114,829.    Elapsed: 6:49:28.\n",
            "  Batch 53,520  of  114,829.    Elapsed: 6:49:47.\n",
            "  Batch 53,560  of  114,829.    Elapsed: 6:50:05.\n",
            "  Batch 53,600  of  114,829.    Elapsed: 6:50:23.\n",
            "  Batch 53,640  of  114,829.    Elapsed: 6:50:42.\n",
            "  Batch 53,680  of  114,829.    Elapsed: 6:51:00.\n",
            "  Batch 53,720  of  114,829.    Elapsed: 6:51:19.\n",
            "  Batch 53,760  of  114,829.    Elapsed: 6:51:37.\n",
            "  Batch 53,800  of  114,829.    Elapsed: 6:51:55.\n",
            "  Batch 53,840  of  114,829.    Elapsed: 6:52:14.\n",
            "  Batch 53,880  of  114,829.    Elapsed: 6:52:32.\n",
            "  Batch 53,920  of  114,829.    Elapsed: 6:52:50.\n",
            "  Batch 53,960  of  114,829.    Elapsed: 6:53:09.\n",
            "  Batch 54,000  of  114,829.    Elapsed: 6:53:27.\n",
            "  Batch 54,040  of  114,829.    Elapsed: 6:53:46.\n",
            "  Batch 54,080  of  114,829.    Elapsed: 6:54:04.\n",
            "  Batch 54,120  of  114,829.    Elapsed: 6:54:22.\n",
            "  Batch 54,160  of  114,829.    Elapsed: 6:54:41.\n",
            "  Batch 54,200  of  114,829.    Elapsed: 6:54:59.\n",
            "  Batch 54,240  of  114,829.    Elapsed: 6:55:17.\n",
            "  Batch 54,280  of  114,829.    Elapsed: 6:55:36.\n",
            "  Batch 54,320  of  114,829.    Elapsed: 6:55:54.\n",
            "  Batch 54,360  of  114,829.    Elapsed: 6:56:12.\n",
            "  Batch 54,400  of  114,829.    Elapsed: 6:56:31.\n",
            "  Batch 54,440  of  114,829.    Elapsed: 6:56:49.\n",
            "  Batch 54,480  of  114,829.    Elapsed: 6:57:08.\n",
            "  Batch 54,520  of  114,829.    Elapsed: 6:57:26.\n",
            "  Batch 54,560  of  114,829.    Elapsed: 6:57:44.\n",
            "  Batch 54,600  of  114,829.    Elapsed: 6:58:03.\n",
            "  Batch 54,640  of  114,829.    Elapsed: 6:58:21.\n",
            "  Batch 54,680  of  114,829.    Elapsed: 6:58:39.\n",
            "  Batch 54,720  of  114,829.    Elapsed: 6:58:58.\n",
            "  Batch 54,760  of  114,829.    Elapsed: 6:59:16.\n",
            "  Batch 54,800  of  114,829.    Elapsed: 6:59:34.\n",
            "  Batch 54,840  of  114,829.    Elapsed: 6:59:53.\n",
            "  Batch 54,880  of  114,829.    Elapsed: 7:00:11.\n",
            "  Batch 54,920  of  114,829.    Elapsed: 7:00:29.\n",
            "  Batch 54,960  of  114,829.    Elapsed: 7:00:48.\n",
            "  Batch 55,000  of  114,829.    Elapsed: 7:01:06.\n",
            "  Batch 55,040  of  114,829.    Elapsed: 7:01:25.\n",
            "  Batch 55,080  of  114,829.    Elapsed: 7:01:43.\n",
            "  Batch 55,120  of  114,829.    Elapsed: 7:02:01.\n",
            "  Batch 55,160  of  114,829.    Elapsed: 7:02:20.\n",
            "  Batch 55,200  of  114,829.    Elapsed: 7:02:38.\n",
            "  Batch 55,240  of  114,829.    Elapsed: 7:02:56.\n",
            "  Batch 55,280  of  114,829.    Elapsed: 7:03:15.\n",
            "  Batch 55,320  of  114,829.    Elapsed: 7:03:33.\n",
            "  Batch 55,360  of  114,829.    Elapsed: 7:03:51.\n",
            "  Batch 55,400  of  114,829.    Elapsed: 7:04:10.\n",
            "  Batch 55,440  of  114,829.    Elapsed: 7:04:28.\n",
            "  Batch 55,480  of  114,829.    Elapsed: 7:04:46.\n",
            "  Batch 55,520  of  114,829.    Elapsed: 7:05:05.\n",
            "  Batch 55,560  of  114,829.    Elapsed: 7:05:23.\n",
            "  Batch 55,600  of  114,829.    Elapsed: 7:05:42.\n",
            "  Batch 55,640  of  114,829.    Elapsed: 7:06:00.\n",
            "  Batch 55,680  of  114,829.    Elapsed: 7:06:18.\n",
            "  Batch 55,720  of  114,829.    Elapsed: 7:06:37.\n",
            "  Batch 55,760  of  114,829.    Elapsed: 7:06:55.\n",
            "  Batch 55,800  of  114,829.    Elapsed: 7:07:13.\n",
            "  Batch 55,840  of  114,829.    Elapsed: 7:07:32.\n",
            "  Batch 55,880  of  114,829.    Elapsed: 7:07:50.\n",
            "  Batch 55,920  of  114,829.    Elapsed: 7:08:08.\n",
            "  Batch 55,960  of  114,829.    Elapsed: 7:08:27.\n",
            "  Batch 56,000  of  114,829.    Elapsed: 7:08:45.\n",
            "  Batch 56,040  of  114,829.    Elapsed: 7:09:03.\n",
            "  Batch 56,080  of  114,829.    Elapsed: 7:09:22.\n",
            "  Batch 56,120  of  114,829.    Elapsed: 7:09:40.\n",
            "  Batch 56,160  of  114,829.    Elapsed: 7:09:58.\n",
            "  Batch 56,200  of  114,829.    Elapsed: 7:10:17.\n",
            "  Batch 56,240  of  114,829.    Elapsed: 7:10:35.\n",
            "  Batch 56,280  of  114,829.    Elapsed: 7:10:54.\n",
            "  Batch 56,320  of  114,829.    Elapsed: 7:11:12.\n",
            "  Batch 56,360  of  114,829.    Elapsed: 7:11:30.\n",
            "  Batch 56,400  of  114,829.    Elapsed: 7:11:49.\n",
            "  Batch 56,440  of  114,829.    Elapsed: 7:12:07.\n",
            "  Batch 56,480  of  114,829.    Elapsed: 7:12:25.\n",
            "  Batch 56,520  of  114,829.    Elapsed: 7:12:44.\n",
            "  Batch 56,560  of  114,829.    Elapsed: 7:13:02.\n",
            "  Batch 56,600  of  114,829.    Elapsed: 7:13:21.\n",
            "  Batch 56,640  of  114,829.    Elapsed: 7:13:39.\n",
            "  Batch 56,680  of  114,829.    Elapsed: 7:13:57.\n",
            "  Batch 56,720  of  114,829.    Elapsed: 7:14:16.\n",
            "  Batch 56,760  of  114,829.    Elapsed: 7:14:34.\n",
            "  Batch 56,800  of  114,829.    Elapsed: 7:14:52.\n",
            "  Batch 56,840  of  114,829.    Elapsed: 7:15:11.\n",
            "  Batch 56,880  of  114,829.    Elapsed: 7:15:29.\n",
            "  Batch 56,920  of  114,829.    Elapsed: 7:15:47.\n",
            "  Batch 56,960  of  114,829.    Elapsed: 7:16:06.\n",
            "  Batch 57,000  of  114,829.    Elapsed: 7:16:24.\n",
            "  Batch 57,040  of  114,829.    Elapsed: 7:16:42.\n",
            "  Batch 57,080  of  114,829.    Elapsed: 7:17:01.\n",
            "  Batch 57,120  of  114,829.    Elapsed: 7:17:19.\n",
            "  Batch 57,160  of  114,829.    Elapsed: 7:17:37.\n",
            "  Batch 57,200  of  114,829.    Elapsed: 7:17:56.\n",
            "  Batch 57,240  of  114,829.    Elapsed: 7:18:14.\n",
            "  Batch 57,280  of  114,829.    Elapsed: 7:18:32.\n",
            "  Batch 57,320  of  114,829.    Elapsed: 7:18:51.\n",
            "  Batch 57,360  of  114,829.    Elapsed: 7:19:09.\n",
            "  Batch 57,400  of  114,829.    Elapsed: 7:19:28.\n",
            "  Batch 57,440  of  114,829.    Elapsed: 7:19:46.\n",
            "  Batch 57,480  of  114,829.    Elapsed: 7:20:04.\n",
            "  Batch 57,520  of  114,829.    Elapsed: 7:20:23.\n",
            "  Batch 57,560  of  114,829.    Elapsed: 7:20:41.\n",
            "  Batch 57,600  of  114,829.    Elapsed: 7:20:59.\n",
            "  Batch 57,640  of  114,829.    Elapsed: 7:21:18.\n",
            "  Batch 57,680  of  114,829.    Elapsed: 7:21:36.\n",
            "  Batch 57,720  of  114,829.    Elapsed: 7:21:54.\n",
            "  Batch 57,760  of  114,829.    Elapsed: 7:22:13.\n",
            "  Batch 57,800  of  114,829.    Elapsed: 7:22:31.\n",
            "  Batch 57,840  of  114,829.    Elapsed: 7:22:49.\n",
            "  Batch 57,880  of  114,829.    Elapsed: 7:23:08.\n",
            "  Batch 57,920  of  114,829.    Elapsed: 7:23:26.\n",
            "  Batch 57,960  of  114,829.    Elapsed: 7:23:45.\n",
            "  Batch 58,000  of  114,829.    Elapsed: 7:24:03.\n",
            "  Batch 58,040  of  114,829.    Elapsed: 7:24:21.\n",
            "  Batch 58,080  of  114,829.    Elapsed: 7:24:40.\n",
            "  Batch 58,120  of  114,829.    Elapsed: 7:24:58.\n",
            "  Batch 58,160  of  114,829.    Elapsed: 7:25:16.\n",
            "  Batch 58,200  of  114,829.    Elapsed: 7:25:35.\n",
            "  Batch 58,240  of  114,829.    Elapsed: 7:25:53.\n",
            "  Batch 58,280  of  114,829.    Elapsed: 7:26:12.\n",
            "  Batch 58,320  of  114,829.    Elapsed: 7:26:30.\n",
            "  Batch 58,360  of  114,829.    Elapsed: 7:26:48.\n",
            "  Batch 58,400  of  114,829.    Elapsed: 7:27:07.\n",
            "  Batch 58,440  of  114,829.    Elapsed: 7:27:25.\n",
            "  Batch 58,480  of  114,829.    Elapsed: 7:27:43.\n",
            "  Batch 58,520  of  114,829.    Elapsed: 7:28:02.\n",
            "  Batch 58,560  of  114,829.    Elapsed: 7:28:20.\n",
            "  Batch 58,600  of  114,829.    Elapsed: 7:28:38.\n",
            "  Batch 58,640  of  114,829.    Elapsed: 7:28:57.\n",
            "  Batch 58,680  of  114,829.    Elapsed: 7:29:15.\n",
            "  Batch 58,720  of  114,829.    Elapsed: 7:29:33.\n",
            "  Batch 58,760  of  114,829.    Elapsed: 7:29:52.\n",
            "  Batch 58,800  of  114,829.    Elapsed: 7:30:10.\n",
            "  Batch 58,840  of  114,829.    Elapsed: 7:30:29.\n",
            "  Batch 58,880  of  114,829.    Elapsed: 7:30:47.\n",
            "  Batch 58,920  of  114,829.    Elapsed: 7:31:05.\n",
            "  Batch 58,960  of  114,829.    Elapsed: 7:31:24.\n",
            "  Batch 59,000  of  114,829.    Elapsed: 7:31:42.\n",
            "  Batch 59,040  of  114,829.    Elapsed: 7:32:00.\n",
            "  Batch 59,080  of  114,829.    Elapsed: 7:32:19.\n",
            "  Batch 59,120  of  114,829.    Elapsed: 7:32:37.\n",
            "  Batch 59,160  of  114,829.    Elapsed: 7:32:55.\n",
            "  Batch 59,200  of  114,829.    Elapsed: 7:33:14.\n",
            "  Batch 59,240  of  114,829.    Elapsed: 7:33:32.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 59,280  of  114,829.    Elapsed: 7:33:51.\n",
            "  Batch 59,320  of  114,829.    Elapsed: 7:34:09.\n",
            "  Batch 59,360  of  114,829.    Elapsed: 7:34:27.\n",
            "  Batch 59,400  of  114,829.    Elapsed: 7:34:46.\n",
            "  Batch 59,440  of  114,829.    Elapsed: 7:35:04.\n",
            "  Batch 59,480  of  114,829.    Elapsed: 7:35:22.\n",
            "  Batch 59,520  of  114,829.    Elapsed: 7:35:41.\n",
            "  Batch 59,560  of  114,829.    Elapsed: 7:35:59.\n",
            "  Batch 59,600  of  114,829.    Elapsed: 7:36:17.\n",
            "  Batch 59,640  of  114,829.    Elapsed: 7:36:36.\n",
            "  Batch 59,680  of  114,829.    Elapsed: 7:36:54.\n",
            "  Batch 59,720  of  114,829.    Elapsed: 7:37:12.\n",
            "  Batch 59,760  of  114,829.    Elapsed: 7:37:31.\n",
            "  Batch 59,800  of  114,829.    Elapsed: 7:37:49.\n",
            "  Batch 59,840  of  114,829.    Elapsed: 7:38:07.\n",
            "  Batch 59,880  of  114,829.    Elapsed: 7:38:26.\n",
            "  Batch 59,920  of  114,829.    Elapsed: 7:38:44.\n",
            "  Batch 59,960  of  114,829.    Elapsed: 7:39:02.\n",
            "  Batch 60,000  of  114,829.    Elapsed: 7:39:21.\n",
            "  Batch 60,040  of  114,829.    Elapsed: 7:39:39.\n",
            "  Batch 60,080  of  114,829.    Elapsed: 7:39:58.\n",
            "  Batch 60,120  of  114,829.    Elapsed: 7:40:16.\n",
            "  Batch 60,160  of  114,829.    Elapsed: 7:40:34.\n",
            "  Batch 60,200  of  114,829.    Elapsed: 7:40:53.\n",
            "  Batch 60,240  of  114,829.    Elapsed: 7:41:11.\n",
            "  Batch 60,280  of  114,829.    Elapsed: 7:41:29.\n",
            "  Batch 60,320  of  114,829.    Elapsed: 7:41:48.\n",
            "  Batch 60,360  of  114,829.    Elapsed: 7:42:06.\n",
            "  Batch 60,400  of  114,829.    Elapsed: 7:42:24.\n",
            "  Batch 60,440  of  114,829.    Elapsed: 7:42:43.\n",
            "  Batch 60,480  of  114,829.    Elapsed: 7:43:01.\n",
            "  Batch 60,520  of  114,829.    Elapsed: 7:43:19.\n",
            "  Batch 60,560  of  114,829.    Elapsed: 7:43:38.\n",
            "  Batch 60,600  of  114,829.    Elapsed: 7:43:56.\n",
            "  Batch 60,640  of  114,829.    Elapsed: 7:44:15.\n",
            "  Batch 60,680  of  114,829.    Elapsed: 7:44:33.\n",
            "  Batch 60,720  of  114,829.    Elapsed: 7:44:51.\n",
            "  Batch 60,760  of  114,829.    Elapsed: 7:45:10.\n",
            "  Batch 60,800  of  114,829.    Elapsed: 7:45:28.\n",
            "  Batch 60,840  of  114,829.    Elapsed: 7:45:46.\n",
            "  Batch 60,880  of  114,829.    Elapsed: 7:46:05.\n",
            "  Batch 60,920  of  114,829.    Elapsed: 7:46:23.\n",
            "  Batch 60,960  of  114,829.    Elapsed: 7:46:42.\n",
            "  Batch 61,000  of  114,829.    Elapsed: 7:47:00.\n",
            "  Batch 61,040  of  114,829.    Elapsed: 7:47:18.\n",
            "  Batch 61,080  of  114,829.    Elapsed: 7:47:37.\n",
            "  Batch 61,120  of  114,829.    Elapsed: 7:47:55.\n",
            "  Batch 61,160  of  114,829.    Elapsed: 7:48:13.\n",
            "  Batch 61,200  of  114,829.    Elapsed: 7:48:32.\n",
            "  Batch 61,240  of  114,829.    Elapsed: 7:48:50.\n",
            "  Batch 61,280  of  114,829.    Elapsed: 7:49:08.\n",
            "  Batch 61,320  of  114,829.    Elapsed: 7:49:27.\n",
            "  Batch 61,360  of  114,829.    Elapsed: 7:49:45.\n",
            "  Batch 61,400  of  114,829.    Elapsed: 7:50:03.\n",
            "  Batch 61,440  of  114,829.    Elapsed: 7:50:22.\n",
            "  Batch 61,480  of  114,829.    Elapsed: 7:50:40.\n",
            "  Batch 61,520  of  114,829.    Elapsed: 7:50:59.\n",
            "  Batch 61,560  of  114,829.    Elapsed: 7:51:17.\n",
            "  Batch 61,600  of  114,829.    Elapsed: 7:51:35.\n",
            "  Batch 61,640  of  114,829.    Elapsed: 7:51:54.\n",
            "  Batch 61,680  of  114,829.    Elapsed: 7:52:12.\n",
            "  Batch 61,720  of  114,829.    Elapsed: 7:52:30.\n",
            "  Batch 61,760  of  114,829.    Elapsed: 7:52:49.\n",
            "  Batch 61,800  of  114,829.    Elapsed: 7:53:07.\n",
            "  Batch 61,840  of  114,829.    Elapsed: 7:53:25.\n",
            "  Batch 61,880  of  114,829.    Elapsed: 7:53:44.\n",
            "  Batch 61,920  of  114,829.    Elapsed: 7:54:02.\n",
            "  Batch 61,960  of  114,829.    Elapsed: 7:54:21.\n",
            "  Batch 62,000  of  114,829.    Elapsed: 7:54:39.\n",
            "  Batch 62,040  of  114,829.    Elapsed: 7:54:57.\n",
            "  Batch 62,080  of  114,829.    Elapsed: 7:55:16.\n",
            "  Batch 62,120  of  114,829.    Elapsed: 7:55:34.\n",
            "  Batch 62,160  of  114,829.    Elapsed: 7:55:52.\n",
            "  Batch 62,200  of  114,829.    Elapsed: 7:56:11.\n",
            "  Batch 62,240  of  114,829.    Elapsed: 7:56:29.\n",
            "  Batch 62,280  of  114,829.    Elapsed: 7:56:48.\n",
            "  Batch 62,320  of  114,829.    Elapsed: 7:57:06.\n",
            "  Batch 62,360  of  114,829.    Elapsed: 7:57:24.\n",
            "  Batch 62,400  of  114,829.    Elapsed: 7:57:43.\n",
            "  Batch 62,440  of  114,829.    Elapsed: 7:58:01.\n",
            "  Batch 62,480  of  114,829.    Elapsed: 7:58:19.\n",
            "  Batch 62,520  of  114,829.    Elapsed: 7:58:38.\n",
            "  Batch 62,560  of  114,829.    Elapsed: 7:58:56.\n",
            "  Batch 62,600  of  114,829.    Elapsed: 7:59:14.\n",
            "  Batch 62,640  of  114,829.    Elapsed: 7:59:33.\n",
            "  Batch 62,680  of  114,829.    Elapsed: 7:59:51.\n",
            "  Batch 62,720  of  114,829.    Elapsed: 8:00:10.\n",
            "  Batch 62,760  of  114,829.    Elapsed: 8:00:28.\n",
            "  Batch 62,800  of  114,829.    Elapsed: 8:00:46.\n",
            "  Batch 62,840  of  114,829.    Elapsed: 8:01:05.\n",
            "  Batch 62,880  of  114,829.    Elapsed: 8:01:23.\n",
            "  Batch 62,920  of  114,829.    Elapsed: 8:01:42.\n",
            "  Batch 62,960  of  114,829.    Elapsed: 8:02:00.\n",
            "  Batch 63,000  of  114,829.    Elapsed: 8:02:18.\n",
            "  Batch 63,040  of  114,829.    Elapsed: 8:02:37.\n",
            "  Batch 63,080  of  114,829.    Elapsed: 8:02:55.\n",
            "  Batch 63,120  of  114,829.    Elapsed: 8:03:13.\n",
            "  Batch 63,160  of  114,829.    Elapsed: 8:03:32.\n",
            "  Batch 63,200  of  114,829.    Elapsed: 8:03:50.\n",
            "  Batch 63,240  of  114,829.    Elapsed: 8:04:09.\n",
            "  Batch 63,280  of  114,829.    Elapsed: 8:04:27.\n",
            "  Batch 63,320  of  114,829.    Elapsed: 8:04:46.\n",
            "  Batch 63,360  of  114,829.    Elapsed: 8:05:04.\n",
            "  Batch 63,400  of  114,829.    Elapsed: 8:05:22.\n",
            "  Batch 63,440  of  114,829.    Elapsed: 8:05:41.\n",
            "  Batch 63,480  of  114,829.    Elapsed: 8:05:59.\n",
            "  Batch 63,520  of  114,829.    Elapsed: 8:06:18.\n",
            "  Batch 63,560  of  114,829.    Elapsed: 8:06:36.\n",
            "  Batch 63,600  of  114,829.    Elapsed: 8:06:54.\n",
            "  Batch 63,640  of  114,829.    Elapsed: 8:07:13.\n",
            "  Batch 63,680  of  114,829.    Elapsed: 8:07:31.\n",
            "  Batch 63,720  of  114,829.    Elapsed: 8:07:50.\n",
            "  Batch 63,760  of  114,829.    Elapsed: 8:08:08.\n",
            "  Batch 63,800  of  114,829.    Elapsed: 8:08:27.\n",
            "  Batch 63,840  of  114,829.    Elapsed: 8:08:45.\n",
            "  Batch 63,880  of  114,829.    Elapsed: 8:09:03.\n",
            "  Batch 63,920  of  114,829.    Elapsed: 8:09:22.\n",
            "  Batch 63,960  of  114,829.    Elapsed: 8:09:40.\n",
            "  Batch 64,000  of  114,829.    Elapsed: 8:09:59.\n",
            "  Batch 64,040  of  114,829.    Elapsed: 8:10:17.\n",
            "  Batch 64,080  of  114,829.    Elapsed: 8:10:35.\n",
            "  Batch 64,120  of  114,829.    Elapsed: 8:10:54.\n",
            "  Batch 64,160  of  114,829.    Elapsed: 8:11:12.\n",
            "  Batch 64,200  of  114,829.    Elapsed: 8:11:31.\n",
            "  Batch 64,240  of  114,829.    Elapsed: 8:11:49.\n",
            "  Batch 64,280  of  114,829.    Elapsed: 8:12:07.\n",
            "  Batch 64,320  of  114,829.    Elapsed: 8:12:26.\n",
            "  Batch 64,360  of  114,829.    Elapsed: 8:12:44.\n",
            "  Batch 64,400  of  114,829.    Elapsed: 8:13:03.\n",
            "  Batch 64,440  of  114,829.    Elapsed: 8:13:21.\n",
            "  Batch 64,480  of  114,829.    Elapsed: 8:13:39.\n",
            "  Batch 64,520  of  114,829.    Elapsed: 8:13:58.\n",
            "  Batch 64,560  of  114,829.    Elapsed: 8:14:16.\n",
            "  Batch 64,600  of  114,829.    Elapsed: 8:14:34.\n",
            "  Batch 64,640  of  114,829.    Elapsed: 8:14:53.\n",
            "  Batch 64,680  of  114,829.    Elapsed: 8:15:11.\n",
            "  Batch 64,720  of  114,829.    Elapsed: 8:15:29.\n",
            "  Batch 64,760  of  114,829.    Elapsed: 8:15:48.\n",
            "  Batch 64,800  of  114,829.    Elapsed: 8:16:06.\n",
            "  Batch 64,840  of  114,829.    Elapsed: 8:16:25.\n",
            "  Batch 64,880  of  114,829.    Elapsed: 8:16:43.\n",
            "  Batch 64,920  of  114,829.    Elapsed: 8:17:01.\n",
            "  Batch 64,960  of  114,829.    Elapsed: 8:17:20.\n",
            "  Batch 65,000  of  114,829.    Elapsed: 8:17:38.\n",
            "  Batch 65,040  of  114,829.    Elapsed: 8:17:56.\n",
            "  Batch 65,080  of  114,829.    Elapsed: 8:18:15.\n",
            "  Batch 65,120  of  114,829.    Elapsed: 8:18:33.\n",
            "  Batch 65,160  of  114,829.    Elapsed: 8:18:51.\n",
            "  Batch 65,200  of  114,829.    Elapsed: 8:19:10.\n",
            "  Batch 65,240  of  114,829.    Elapsed: 8:19:28.\n",
            "  Batch 65,280  of  114,829.    Elapsed: 8:19:46.\n",
            "  Batch 65,320  of  114,829.    Elapsed: 8:20:05.\n",
            "  Batch 65,360  of  114,829.    Elapsed: 8:20:23.\n",
            "  Batch 65,400  of  114,829.    Elapsed: 8:20:41.\n",
            "  Batch 65,440  of  114,829.    Elapsed: 8:21:00.\n",
            "  Batch 65,480  of  114,829.    Elapsed: 8:21:18.\n",
            "  Batch 65,520  of  114,829.    Elapsed: 8:21:37.\n",
            "  Batch 65,560  of  114,829.    Elapsed: 8:21:55.\n",
            "  Batch 65,600  of  114,829.    Elapsed: 8:22:13.\n",
            "  Batch 65,640  of  114,829.    Elapsed: 8:22:32.\n",
            "  Batch 65,680  of  114,829.    Elapsed: 8:22:50.\n",
            "  Batch 65,720  of  114,829.    Elapsed: 8:23:08.\n",
            "  Batch 65,760  of  114,829.    Elapsed: 8:23:27.\n",
            "  Batch 65,800  of  114,829.    Elapsed: 8:23:45.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 65,840  of  114,829.    Elapsed: 8:24:03.\n",
            "  Batch 65,880  of  114,829.    Elapsed: 8:24:22.\n",
            "  Batch 65,920  of  114,829.    Elapsed: 8:24:40.\n",
            "  Batch 65,960  of  114,829.    Elapsed: 8:24:58.\n",
            "  Batch 66,000  of  114,829.    Elapsed: 8:25:17.\n",
            "  Batch 66,040  of  114,829.    Elapsed: 8:25:35.\n",
            "  Batch 66,080  of  114,829.    Elapsed: 8:25:54.\n",
            "  Batch 66,120  of  114,829.    Elapsed: 8:26:12.\n",
            "  Batch 66,160  of  114,829.    Elapsed: 8:26:30.\n",
            "  Batch 66,200  of  114,829.    Elapsed: 8:26:49.\n",
            "  Batch 66,240  of  114,829.    Elapsed: 8:27:07.\n",
            "  Batch 66,280  of  114,829.    Elapsed: 8:27:25.\n",
            "  Batch 66,320  of  114,829.    Elapsed: 8:27:44.\n",
            "  Batch 66,360  of  114,829.    Elapsed: 8:28:02.\n",
            "  Batch 66,400  of  114,829.    Elapsed: 8:28:20.\n",
            "  Batch 66,440  of  114,829.    Elapsed: 8:28:39.\n",
            "  Batch 66,480  of  114,829.    Elapsed: 8:28:57.\n",
            "  Batch 66,520  of  114,829.    Elapsed: 8:29:15.\n",
            "  Batch 66,560  of  114,829.    Elapsed: 8:29:34.\n",
            "  Batch 66,600  of  114,829.    Elapsed: 8:29:52.\n",
            "  Batch 66,640  of  114,829.    Elapsed: 8:30:10.\n",
            "  Batch 66,680  of  114,829.    Elapsed: 8:30:29.\n",
            "  Batch 66,720  of  114,829.    Elapsed: 8:30:47.\n",
            "  Batch 66,760  of  114,829.    Elapsed: 8:31:06.\n",
            "  Batch 66,800  of  114,829.    Elapsed: 8:31:24.\n",
            "  Batch 66,840  of  114,829.    Elapsed: 8:31:42.\n",
            "  Batch 66,880  of  114,829.    Elapsed: 8:32:01.\n",
            "  Batch 66,920  of  114,829.    Elapsed: 8:32:19.\n",
            "  Batch 66,960  of  114,829.    Elapsed: 8:32:37.\n",
            "  Batch 67,000  of  114,829.    Elapsed: 8:32:56.\n",
            "  Batch 67,040  of  114,829.    Elapsed: 8:33:14.\n",
            "  Batch 67,080  of  114,829.    Elapsed: 8:33:32.\n",
            "  Batch 67,120  of  114,829.    Elapsed: 8:33:51.\n",
            "  Batch 67,160  of  114,829.    Elapsed: 8:34:09.\n",
            "  Batch 67,200  of  114,829.    Elapsed: 8:34:27.\n",
            "  Batch 67,240  of  114,829.    Elapsed: 8:34:46.\n",
            "  Batch 67,280  of  114,829.    Elapsed: 8:35:04.\n",
            "  Batch 67,320  of  114,829.    Elapsed: 8:35:23.\n",
            "  Batch 67,360  of  114,829.    Elapsed: 8:35:41.\n",
            "  Batch 67,400  of  114,829.    Elapsed: 8:35:59.\n",
            "  Batch 67,440  of  114,829.    Elapsed: 8:36:18.\n",
            "  Batch 67,480  of  114,829.    Elapsed: 8:36:36.\n",
            "  Batch 67,520  of  114,829.    Elapsed: 8:36:54.\n",
            "  Batch 67,560  of  114,829.    Elapsed: 8:37:13.\n",
            "  Batch 67,600  of  114,829.    Elapsed: 8:37:31.\n",
            "  Batch 67,640  of  114,829.    Elapsed: 8:37:49.\n",
            "  Batch 67,680  of  114,829.    Elapsed: 8:38:08.\n",
            "  Batch 67,720  of  114,829.    Elapsed: 8:38:26.\n",
            "  Batch 67,760  of  114,829.    Elapsed: 8:38:45.\n",
            "  Batch 67,800  of  114,829.    Elapsed: 8:39:03.\n",
            "  Batch 67,840  of  114,829.    Elapsed: 8:39:21.\n",
            "  Batch 67,880  of  114,829.    Elapsed: 8:39:40.\n",
            "  Batch 67,920  of  114,829.    Elapsed: 8:39:58.\n",
            "  Batch 67,960  of  114,829.    Elapsed: 8:40:16.\n",
            "  Batch 68,000  of  114,829.    Elapsed: 8:40:35.\n",
            "  Batch 68,040  of  114,829.    Elapsed: 8:40:53.\n",
            "  Batch 68,080  of  114,829.    Elapsed: 8:41:12.\n",
            "  Batch 68,120  of  114,829.    Elapsed: 8:41:30.\n",
            "  Batch 68,160  of  114,829.    Elapsed: 8:41:48.\n",
            "  Batch 68,200  of  114,829.    Elapsed: 8:42:07.\n",
            "  Batch 68,240  of  114,829.    Elapsed: 8:42:25.\n",
            "  Batch 68,280  of  114,829.    Elapsed: 8:42:43.\n",
            "  Batch 68,320  of  114,829.    Elapsed: 8:43:02.\n",
            "  Batch 68,360  of  114,829.    Elapsed: 8:43:20.\n",
            "  Batch 68,400  of  114,829.    Elapsed: 8:43:38.\n",
            "  Batch 68,440  of  114,829.    Elapsed: 8:43:57.\n",
            "  Batch 68,480  of  114,829.    Elapsed: 8:44:15.\n",
            "  Batch 68,520  of  114,829.    Elapsed: 8:44:34.\n",
            "  Batch 68,560  of  114,829.    Elapsed: 8:44:52.\n",
            "  Batch 68,600  of  114,829.    Elapsed: 8:45:10.\n",
            "  Batch 68,640  of  114,829.    Elapsed: 8:45:29.\n",
            "  Batch 68,680  of  114,829.    Elapsed: 8:45:47.\n",
            "  Batch 68,720  of  114,829.    Elapsed: 8:46:05.\n",
            "  Batch 68,760  of  114,829.    Elapsed: 8:46:24.\n",
            "  Batch 68,800  of  114,829.    Elapsed: 8:46:42.\n",
            "  Batch 68,840  of  114,829.    Elapsed: 8:47:00.\n",
            "  Batch 68,880  of  114,829.    Elapsed: 8:47:19.\n",
            "  Batch 68,920  of  114,829.    Elapsed: 8:47:37.\n",
            "  Batch 68,960  of  114,829.    Elapsed: 8:47:56.\n",
            "  Batch 69,000  of  114,829.    Elapsed: 8:48:14.\n",
            "  Batch 69,040  of  114,829.    Elapsed: 8:48:32.\n",
            "  Batch 69,080  of  114,829.    Elapsed: 8:48:51.\n",
            "  Batch 69,120  of  114,829.    Elapsed: 8:49:09.\n",
            "  Batch 69,160  of  114,829.    Elapsed: 8:49:27.\n",
            "  Batch 69,200  of  114,829.    Elapsed: 8:49:46.\n",
            "  Batch 69,240  of  114,829.    Elapsed: 8:50:04.\n",
            "  Batch 69,280  of  114,829.    Elapsed: 8:50:22.\n",
            "  Batch 69,320  of  114,829.    Elapsed: 8:50:41.\n",
            "  Batch 69,360  of  114,829.    Elapsed: 8:50:59.\n",
            "  Batch 69,400  of  114,829.    Elapsed: 8:51:18.\n",
            "  Batch 69,440  of  114,829.    Elapsed: 8:51:36.\n",
            "  Batch 69,480  of  114,829.    Elapsed: 8:51:54.\n",
            "  Batch 69,520  of  114,829.    Elapsed: 8:52:13.\n",
            "  Batch 69,560  of  114,829.    Elapsed: 8:52:31.\n",
            "  Batch 69,600  of  114,829.    Elapsed: 8:52:49.\n",
            "  Batch 69,640  of  114,829.    Elapsed: 8:53:08.\n",
            "  Batch 69,680  of  114,829.    Elapsed: 8:53:26.\n",
            "  Batch 69,720  of  114,829.    Elapsed: 8:53:44.\n",
            "  Batch 69,760  of  114,829.    Elapsed: 8:54:03.\n",
            "  Batch 69,800  of  114,829.    Elapsed: 8:54:21.\n",
            "  Batch 69,840  of  114,829.    Elapsed: 8:54:40.\n",
            "  Batch 69,880  of  114,829.    Elapsed: 8:54:58.\n",
            "  Batch 69,920  of  114,829.    Elapsed: 8:55:16.\n",
            "  Batch 69,960  of  114,829.    Elapsed: 8:55:35.\n",
            "  Batch 70,000  of  114,829.    Elapsed: 8:55:53.\n",
            "  Batch 70,040  of  114,829.    Elapsed: 8:56:11.\n",
            "  Batch 70,080  of  114,829.    Elapsed: 8:56:30.\n",
            "  Batch 70,120  of  114,829.    Elapsed: 8:56:48.\n",
            "  Batch 70,160  of  114,829.    Elapsed: 8:57:06.\n",
            "  Batch 70,200  of  114,829.    Elapsed: 8:57:25.\n",
            "  Batch 70,240  of  114,829.    Elapsed: 8:57:43.\n",
            "  Batch 70,280  of  114,829.    Elapsed: 8:58:01.\n",
            "  Batch 70,320  of  114,829.    Elapsed: 8:58:20.\n",
            "  Batch 70,360  of  114,829.    Elapsed: 8:58:38.\n",
            "  Batch 70,400  of  114,829.    Elapsed: 8:58:57.\n",
            "  Batch 70,440  of  114,829.    Elapsed: 8:59:15.\n",
            "  Batch 70,480  of  114,829.    Elapsed: 8:59:33.\n",
            "  Batch 70,520  of  114,829.    Elapsed: 8:59:52.\n",
            "  Batch 70,560  of  114,829.    Elapsed: 9:00:10.\n",
            "  Batch 70,600  of  114,829.    Elapsed: 9:00:28.\n",
            "  Batch 70,640  of  114,829.    Elapsed: 9:00:47.\n",
            "  Batch 70,680  of  114,829.    Elapsed: 9:01:05.\n",
            "  Batch 70,720  of  114,829.    Elapsed: 9:01:23.\n",
            "  Batch 70,760  of  114,829.    Elapsed: 9:01:42.\n",
            "  Batch 70,800  of  114,829.    Elapsed: 9:02:00.\n",
            "  Batch 70,840  of  114,829.    Elapsed: 9:02:19.\n",
            "  Batch 70,880  of  114,829.    Elapsed: 9:02:37.\n",
            "  Batch 70,920  of  114,829.    Elapsed: 9:02:55.\n",
            "  Batch 70,960  of  114,829.    Elapsed: 9:03:14.\n",
            "  Batch 71,000  of  114,829.    Elapsed: 9:03:32.\n",
            "  Batch 71,040  of  114,829.    Elapsed: 9:03:50.\n",
            "  Batch 71,080  of  114,829.    Elapsed: 9:04:09.\n",
            "  Batch 71,120  of  114,829.    Elapsed: 9:04:27.\n",
            "  Batch 71,160  of  114,829.    Elapsed: 9:04:45.\n",
            "  Batch 71,200  of  114,829.    Elapsed: 9:05:04.\n",
            "  Batch 71,240  of  114,829.    Elapsed: 9:05:22.\n",
            "  Batch 71,280  of  114,829.    Elapsed: 9:05:40.\n",
            "  Batch 71,320  of  114,829.    Elapsed: 9:05:59.\n",
            "  Batch 71,360  of  114,829.    Elapsed: 9:06:17.\n",
            "  Batch 71,400  of  114,829.    Elapsed: 9:06:36.\n",
            "  Batch 71,440  of  114,829.    Elapsed: 9:06:54.\n",
            "  Batch 71,480  of  114,829.    Elapsed: 9:07:12.\n",
            "  Batch 71,520  of  114,829.    Elapsed: 9:07:31.\n",
            "  Batch 71,560  of  114,829.    Elapsed: 9:07:49.\n",
            "  Batch 71,600  of  114,829.    Elapsed: 9:08:07.\n",
            "  Batch 71,640  of  114,829.    Elapsed: 9:08:26.\n",
            "  Batch 71,680  of  114,829.    Elapsed: 9:08:44.\n",
            "  Batch 71,720  of  114,829.    Elapsed: 9:09:02.\n",
            "  Batch 71,760  of  114,829.    Elapsed: 9:09:21.\n",
            "  Batch 71,800  of  114,829.    Elapsed: 9:09:39.\n",
            "  Batch 71,840  of  114,829.    Elapsed: 9:09:57.\n",
            "  Batch 71,880  of  114,829.    Elapsed: 9:10:16.\n",
            "  Batch 71,920  of  114,829.    Elapsed: 9:10:34.\n",
            "  Batch 71,960  of  114,829.    Elapsed: 9:10:53.\n",
            "  Batch 72,000  of  114,829.    Elapsed: 9:11:11.\n",
            "  Batch 72,040  of  114,829.    Elapsed: 9:11:29.\n",
            "  Batch 72,080  of  114,829.    Elapsed: 9:11:48.\n",
            "  Batch 72,120  of  114,829.    Elapsed: 9:12:06.\n",
            "  Batch 72,160  of  114,829.    Elapsed: 9:12:24.\n",
            "  Batch 72,200  of  114,829.    Elapsed: 9:12:43.\n",
            "  Batch 72,240  of  114,829.    Elapsed: 9:13:02.\n",
            "  Batch 72,280  of  114,829.    Elapsed: 9:13:20.\n",
            "  Batch 72,320  of  114,829.    Elapsed: 9:13:38.\n",
            "  Batch 72,360  of  114,829.    Elapsed: 9:13:57.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 72,400  of  114,829.    Elapsed: 9:14:15.\n",
            "  Batch 72,440  of  114,829.    Elapsed: 9:14:33.\n",
            "  Batch 72,480  of  114,829.    Elapsed: 9:14:52.\n",
            "  Batch 72,520  of  114,829.    Elapsed: 9:15:10.\n",
            "  Batch 72,560  of  114,829.    Elapsed: 9:15:29.\n",
            "  Batch 72,600  of  114,829.    Elapsed: 9:15:47.\n",
            "  Batch 72,640  of  114,829.    Elapsed: 9:16:05.\n",
            "  Batch 72,680  of  114,829.    Elapsed: 9:16:24.\n",
            "  Batch 72,720  of  114,829.    Elapsed: 9:16:42.\n",
            "  Batch 72,760  of  114,829.    Elapsed: 9:17:01.\n",
            "  Batch 72,800  of  114,829.    Elapsed: 9:17:19.\n",
            "  Batch 72,840  of  114,829.    Elapsed: 9:17:37.\n",
            "  Batch 72,880  of  114,829.    Elapsed: 9:17:56.\n",
            "  Batch 72,920  of  114,829.    Elapsed: 9:18:14.\n",
            "  Batch 72,960  of  114,829.    Elapsed: 9:18:32.\n",
            "  Batch 73,000  of  114,829.    Elapsed: 9:18:51.\n",
            "  Batch 73,040  of  114,829.    Elapsed: 9:19:09.\n",
            "  Batch 73,080  of  114,829.    Elapsed: 9:19:28.\n",
            "  Batch 73,120  of  114,829.    Elapsed: 9:19:46.\n",
            "  Batch 73,160  of  114,829.    Elapsed: 9:20:04.\n",
            "  Batch 73,200  of  114,829.    Elapsed: 9:20:23.\n",
            "  Batch 73,240  of  114,829.    Elapsed: 9:20:41.\n",
            "  Batch 73,280  of  114,829.    Elapsed: 9:20:59.\n",
            "  Batch 73,320  of  114,829.    Elapsed: 9:21:18.\n",
            "  Batch 73,360  of  114,829.    Elapsed: 9:21:36.\n",
            "  Batch 73,400  of  114,829.    Elapsed: 9:21:54.\n",
            "  Batch 73,440  of  114,829.    Elapsed: 9:22:13.\n",
            "  Batch 73,480  of  114,829.    Elapsed: 9:22:31.\n",
            "  Batch 73,520  of  114,829.    Elapsed: 9:22:50.\n",
            "  Batch 73,560  of  114,829.    Elapsed: 9:23:08.\n",
            "  Batch 73,600  of  114,829.    Elapsed: 9:23:26.\n",
            "  Batch 73,640  of  114,829.    Elapsed: 9:23:45.\n",
            "  Batch 73,680  of  114,829.    Elapsed: 9:24:03.\n",
            "  Batch 73,720  of  114,829.    Elapsed: 9:24:21.\n",
            "  Batch 73,760  of  114,829.    Elapsed: 9:24:40.\n",
            "  Batch 73,800  of  114,829.    Elapsed: 9:24:58.\n",
            "  Batch 73,840  of  114,829.    Elapsed: 9:25:16.\n",
            "  Batch 73,880  of  114,829.    Elapsed: 9:25:35.\n",
            "  Batch 73,920  of  114,829.    Elapsed: 9:25:53.\n",
            "  Batch 73,960  of  114,829.    Elapsed: 9:26:12.\n",
            "  Batch 74,000  of  114,829.    Elapsed: 9:26:30.\n",
            "  Batch 74,040  of  114,829.    Elapsed: 9:26:48.\n",
            "  Batch 74,080  of  114,829.    Elapsed: 9:27:07.\n",
            "  Batch 74,120  of  114,829.    Elapsed: 9:27:25.\n",
            "  Batch 74,160  of  114,829.    Elapsed: 9:27:43.\n",
            "  Batch 74,200  of  114,829.    Elapsed: 9:28:02.\n",
            "  Batch 74,240  of  114,829.    Elapsed: 9:28:20.\n",
            "  Batch 74,280  of  114,829.    Elapsed: 9:28:38.\n",
            "  Batch 74,320  of  114,829.    Elapsed: 9:28:57.\n",
            "  Batch 74,360  of  114,829.    Elapsed: 9:29:15.\n",
            "  Batch 74,400  of  114,829.    Elapsed: 9:29:34.\n",
            "  Batch 74,440  of  114,829.    Elapsed: 9:29:52.\n",
            "  Batch 74,480  of  114,829.    Elapsed: 9:30:10.\n",
            "  Batch 74,520  of  114,829.    Elapsed: 9:30:29.\n",
            "  Batch 74,560  of  114,829.    Elapsed: 9:30:47.\n",
            "  Batch 74,600  of  114,829.    Elapsed: 9:31:06.\n",
            "  Batch 74,640  of  114,829.    Elapsed: 9:31:24.\n",
            "  Batch 74,680  of  114,829.    Elapsed: 9:31:42.\n",
            "  Batch 74,720  of  114,829.    Elapsed: 9:32:01.\n",
            "  Batch 74,760  of  114,829.    Elapsed: 9:32:19.\n",
            "  Batch 74,800  of  114,829.    Elapsed: 9:32:37.\n",
            "  Batch 74,840  of  114,829.    Elapsed: 9:32:56.\n",
            "  Batch 74,880  of  114,829.    Elapsed: 9:33:14.\n",
            "  Batch 74,920  of  114,829.    Elapsed: 9:33:33.\n",
            "  Batch 74,960  of  114,829.    Elapsed: 9:33:51.\n",
            "  Batch 75,000  of  114,829.    Elapsed: 9:34:09.\n",
            "  Batch 75,040  of  114,829.    Elapsed: 9:34:28.\n",
            "  Batch 75,080  of  114,829.    Elapsed: 9:34:46.\n",
            "  Batch 75,120  of  114,829.    Elapsed: 9:35:05.\n",
            "  Batch 75,160  of  114,829.    Elapsed: 9:35:23.\n",
            "  Batch 75,200  of  114,829.    Elapsed: 9:35:41.\n",
            "  Batch 75,240  of  114,829.    Elapsed: 9:36:00.\n",
            "  Batch 75,280  of  114,829.    Elapsed: 9:36:18.\n",
            "  Batch 75,320  of  114,829.    Elapsed: 9:36:36.\n",
            "  Batch 75,360  of  114,829.    Elapsed: 9:36:55.\n",
            "  Batch 75,400  of  114,829.    Elapsed: 9:37:13.\n",
            "  Batch 75,440  of  114,829.    Elapsed: 9:37:31.\n",
            "  Batch 75,480  of  114,829.    Elapsed: 9:37:50.\n",
            "  Batch 75,520  of  114,829.    Elapsed: 9:38:08.\n",
            "  Batch 75,560  of  114,829.    Elapsed: 9:38:27.\n",
            "  Batch 75,600  of  114,829.    Elapsed: 9:38:45.\n",
            "  Batch 75,640  of  114,829.    Elapsed: 9:39:03.\n",
            "  Batch 75,680  of  114,829.    Elapsed: 9:39:22.\n",
            "  Batch 75,720  of  114,829.    Elapsed: 9:39:40.\n",
            "  Batch 75,760  of  114,829.    Elapsed: 9:39:58.\n",
            "  Batch 75,800  of  114,829.    Elapsed: 9:40:17.\n",
            "  Batch 75,840  of  114,829.    Elapsed: 9:40:35.\n",
            "  Batch 75,880  of  114,829.    Elapsed: 9:40:54.\n",
            "  Batch 75,920  of  114,829.    Elapsed: 9:41:12.\n",
            "  Batch 75,960  of  114,829.    Elapsed: 9:41:30.\n",
            "  Batch 76,000  of  114,829.    Elapsed: 9:41:49.\n",
            "  Batch 76,040  of  114,829.    Elapsed: 9:42:07.\n",
            "  Batch 76,080  of  114,829.    Elapsed: 9:42:25.\n",
            "  Batch 76,120  of  114,829.    Elapsed: 9:42:44.\n",
            "  Batch 76,160  of  114,829.    Elapsed: 9:43:02.\n",
            "  Batch 76,200  of  114,829.    Elapsed: 9:43:21.\n",
            "  Batch 76,240  of  114,829.    Elapsed: 9:43:39.\n",
            "  Batch 76,280  of  114,829.    Elapsed: 9:43:57.\n",
            "  Batch 76,320  of  114,829.    Elapsed: 9:44:16.\n",
            "  Batch 76,360  of  114,829.    Elapsed: 9:44:34.\n",
            "  Batch 76,400  of  114,829.    Elapsed: 9:44:52.\n",
            "  Batch 76,440  of  114,829.    Elapsed: 9:45:11.\n",
            "  Batch 76,480  of  114,829.    Elapsed: 9:45:29.\n",
            "  Batch 76,520  of  114,829.    Elapsed: 9:45:47.\n",
            "  Batch 76,560  of  114,829.    Elapsed: 9:46:06.\n",
            "  Batch 76,600  of  114,829.    Elapsed: 9:46:24.\n",
            "  Batch 76,640  of  114,829.    Elapsed: 9:46:42.\n",
            "  Batch 76,680  of  114,829.    Elapsed: 9:47:01.\n",
            "  Batch 76,720  of  114,829.    Elapsed: 9:47:19.\n",
            "  Batch 76,760  of  114,829.    Elapsed: 9:47:38.\n",
            "  Batch 76,800  of  114,829.    Elapsed: 9:47:56.\n",
            "  Batch 76,840  of  114,829.    Elapsed: 9:48:14.\n",
            "  Batch 76,880  of  114,829.    Elapsed: 9:48:33.\n",
            "  Batch 76,920  of  114,829.    Elapsed: 9:48:51.\n",
            "  Batch 76,960  of  114,829.    Elapsed: 9:49:09.\n",
            "  Batch 77,000  of  114,829.    Elapsed: 9:49:28.\n",
            "  Batch 77,040  of  114,829.    Elapsed: 9:49:46.\n",
            "  Batch 77,080  of  114,829.    Elapsed: 9:50:05.\n",
            "  Batch 77,120  of  114,829.    Elapsed: 9:50:23.\n",
            "  Batch 77,160  of  114,829.    Elapsed: 9:50:41.\n",
            "  Batch 77,200  of  114,829.    Elapsed: 9:51:00.\n",
            "  Batch 77,240  of  114,829.    Elapsed: 9:51:18.\n",
            "  Batch 77,280  of  114,829.    Elapsed: 9:51:37.\n",
            "  Batch 77,320  of  114,829.    Elapsed: 9:51:55.\n",
            "  Batch 77,360  of  114,829.    Elapsed: 9:52:13.\n",
            "  Batch 77,400  of  114,829.    Elapsed: 9:52:32.\n",
            "  Batch 77,440  of  114,829.    Elapsed: 9:52:50.\n",
            "  Batch 77,480  of  114,829.    Elapsed: 9:53:09.\n",
            "  Batch 77,520  of  114,829.    Elapsed: 9:53:27.\n",
            "  Batch 77,560  of  114,829.    Elapsed: 9:53:45.\n",
            "  Batch 77,600  of  114,829.    Elapsed: 9:54:04.\n",
            "  Batch 77,640  of  114,829.    Elapsed: 9:54:22.\n",
            "  Batch 77,680  of  114,829.    Elapsed: 9:54:41.\n",
            "  Batch 77,720  of  114,829.    Elapsed: 9:54:59.\n",
            "  Batch 77,760  of  114,829.    Elapsed: 9:55:17.\n",
            "  Batch 77,800  of  114,829.    Elapsed: 9:55:36.\n",
            "  Batch 77,840  of  114,829.    Elapsed: 9:55:54.\n",
            "  Batch 77,880  of  114,829.    Elapsed: 9:56:13.\n",
            "  Batch 77,920  of  114,829.    Elapsed: 9:56:31.\n",
            "  Batch 77,960  of  114,829.    Elapsed: 9:56:49.\n",
            "  Batch 78,000  of  114,829.    Elapsed: 9:57:08.\n",
            "  Batch 78,040  of  114,829.    Elapsed: 9:57:26.\n",
            "  Batch 78,080  of  114,829.    Elapsed: 9:57:45.\n",
            "  Batch 78,120  of  114,829.    Elapsed: 9:58:03.\n",
            "  Batch 78,160  of  114,829.    Elapsed: 9:58:21.\n",
            "  Batch 78,200  of  114,829.    Elapsed: 9:58:40.\n",
            "  Batch 78,240  of  114,829.    Elapsed: 9:58:58.\n",
            "  Batch 78,280  of  114,829.    Elapsed: 9:59:17.\n",
            "  Batch 78,320  of  114,829.    Elapsed: 9:59:35.\n",
            "  Batch 78,360  of  114,829.    Elapsed: 9:59:53.\n",
            "  Batch 78,400  of  114,829.    Elapsed: 10:00:12.\n",
            "  Batch 78,440  of  114,829.    Elapsed: 10:00:30.\n",
            "  Batch 78,480  of  114,829.    Elapsed: 10:00:49.\n",
            "  Batch 78,520  of  114,829.    Elapsed: 10:01:07.\n",
            "  Batch 78,560  of  114,829.    Elapsed: 10:01:25.\n",
            "  Batch 78,600  of  114,829.    Elapsed: 10:01:44.\n",
            "  Batch 78,640  of  114,829.    Elapsed: 10:02:02.\n",
            "  Batch 78,680  of  114,829.    Elapsed: 10:02:20.\n",
            "  Batch 78,720  of  114,829.    Elapsed: 10:02:39.\n",
            "  Batch 78,760  of  114,829.    Elapsed: 10:02:57.\n",
            "  Batch 78,800  of  114,829.    Elapsed: 10:03:16.\n",
            "  Batch 78,840  of  114,829.    Elapsed: 10:03:34.\n",
            "  Batch 78,880  of  114,829.    Elapsed: 10:03:52.\n",
            "  Batch 78,920  of  114,829.    Elapsed: 10:04:11.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 78,960  of  114,829.    Elapsed: 10:04:29.\n",
            "  Batch 79,000  of  114,829.    Elapsed: 10:04:48.\n",
            "  Batch 79,040  of  114,829.    Elapsed: 10:05:06.\n",
            "  Batch 79,080  of  114,829.    Elapsed: 10:05:24.\n",
            "  Batch 79,120  of  114,829.    Elapsed: 10:05:43.\n",
            "  Batch 79,160  of  114,829.    Elapsed: 10:06:01.\n",
            "  Batch 79,200  of  114,829.    Elapsed: 10:06:19.\n",
            "  Batch 79,240  of  114,829.    Elapsed: 10:06:38.\n",
            "  Batch 79,280  of  114,829.    Elapsed: 10:06:56.\n",
            "  Batch 79,320  of  114,829.    Elapsed: 10:07:15.\n",
            "  Batch 79,360  of  114,829.    Elapsed: 10:07:33.\n",
            "  Batch 79,400  of  114,829.    Elapsed: 10:07:51.\n",
            "  Batch 79,440  of  114,829.    Elapsed: 10:08:10.\n",
            "  Batch 79,480  of  114,829.    Elapsed: 10:08:28.\n",
            "  Batch 79,520  of  114,829.    Elapsed: 10:08:47.\n",
            "  Batch 79,560  of  114,829.    Elapsed: 10:09:05.\n",
            "  Batch 79,600  of  114,829.    Elapsed: 10:09:23.\n",
            "  Batch 79,640  of  114,829.    Elapsed: 10:09:42.\n",
            "  Batch 79,680  of  114,829.    Elapsed: 10:10:00.\n",
            "  Batch 79,720  of  114,829.    Elapsed: 10:10:19.\n",
            "  Batch 79,760  of  114,829.    Elapsed: 10:10:37.\n",
            "  Batch 79,800  of  114,829.    Elapsed: 10:10:55.\n",
            "  Batch 79,840  of  114,829.    Elapsed: 10:11:14.\n",
            "  Batch 79,880  of  114,829.    Elapsed: 10:11:32.\n",
            "  Batch 79,920  of  114,829.    Elapsed: 10:11:51.\n",
            "  Batch 79,960  of  114,829.    Elapsed: 10:12:09.\n",
            "  Batch 80,000  of  114,829.    Elapsed: 10:12:27.\n",
            "  Batch 80,040  of  114,829.    Elapsed: 10:12:46.\n",
            "  Batch 80,080  of  114,829.    Elapsed: 10:13:04.\n",
            "  Batch 80,120  of  114,829.    Elapsed: 10:13:22.\n",
            "  Batch 80,160  of  114,829.    Elapsed: 10:13:41.\n",
            "  Batch 80,200  of  114,829.    Elapsed: 10:13:59.\n",
            "  Batch 80,240  of  114,829.    Elapsed: 10:14:18.\n",
            "  Batch 80,280  of  114,829.    Elapsed: 10:14:36.\n",
            "  Batch 80,320  of  114,829.    Elapsed: 10:14:54.\n",
            "  Batch 80,360  of  114,829.    Elapsed: 10:15:13.\n",
            "  Batch 80,400  of  114,829.    Elapsed: 10:15:31.\n",
            "  Batch 80,440  of  114,829.    Elapsed: 10:15:49.\n",
            "  Batch 80,480  of  114,829.    Elapsed: 10:16:08.\n",
            "  Batch 80,520  of  114,829.    Elapsed: 10:16:26.\n",
            "  Batch 80,560  of  114,829.    Elapsed: 10:16:44.\n",
            "  Batch 80,600  of  114,829.    Elapsed: 10:17:03.\n",
            "  Batch 80,640  of  114,829.    Elapsed: 10:17:21.\n",
            "  Batch 80,680  of  114,829.    Elapsed: 10:17:40.\n",
            "  Batch 80,720  of  114,829.    Elapsed: 10:17:58.\n",
            "  Batch 80,760  of  114,829.    Elapsed: 10:18:16.\n",
            "  Batch 80,800  of  114,829.    Elapsed: 10:18:35.\n",
            "  Batch 80,840  of  114,829.    Elapsed: 10:18:53.\n",
            "  Batch 80,880  of  114,829.    Elapsed: 10:19:11.\n",
            "  Batch 80,920  of  114,829.    Elapsed: 10:19:30.\n",
            "  Batch 80,960  of  114,829.    Elapsed: 10:19:48.\n",
            "  Batch 81,000  of  114,829.    Elapsed: 10:20:06.\n",
            "  Batch 81,040  of  114,829.    Elapsed: 10:20:25.\n",
            "  Batch 81,080  of  114,829.    Elapsed: 10:20:43.\n",
            "  Batch 81,120  of  114,829.    Elapsed: 10:21:02.\n",
            "  Batch 81,160  of  114,829.    Elapsed: 10:21:20.\n",
            "  Batch 81,200  of  114,829.    Elapsed: 10:21:38.\n",
            "  Batch 81,240  of  114,829.    Elapsed: 10:21:57.\n",
            "  Batch 81,280  of  114,829.    Elapsed: 10:22:15.\n",
            "  Batch 81,320  of  114,829.    Elapsed: 10:22:33.\n",
            "  Batch 81,360  of  114,829.    Elapsed: 10:22:52.\n",
            "  Batch 81,400  of  114,829.    Elapsed: 10:23:10.\n",
            "  Batch 81,440  of  114,829.    Elapsed: 10:23:29.\n",
            "  Batch 81,480  of  114,829.    Elapsed: 10:23:47.\n",
            "  Batch 81,520  of  114,829.    Elapsed: 10:24:05.\n",
            "  Batch 81,560  of  114,829.    Elapsed: 10:24:24.\n",
            "  Batch 81,600  of  114,829.    Elapsed: 10:24:42.\n",
            "  Batch 81,640  of  114,829.    Elapsed: 10:25:00.\n",
            "  Batch 81,680  of  114,829.    Elapsed: 10:25:19.\n",
            "  Batch 81,720  of  114,829.    Elapsed: 10:25:37.\n",
            "  Batch 81,760  of  114,829.    Elapsed: 10:25:55.\n",
            "  Batch 81,800  of  114,829.    Elapsed: 10:26:14.\n",
            "  Batch 81,840  of  114,829.    Elapsed: 10:26:32.\n",
            "  Batch 81,880  of  114,829.    Elapsed: 10:26:51.\n",
            "  Batch 81,920  of  114,829.    Elapsed: 10:27:09.\n",
            "  Batch 81,960  of  114,829.    Elapsed: 10:27:27.\n",
            "  Batch 82,000  of  114,829.    Elapsed: 10:27:46.\n",
            "  Batch 82,040  of  114,829.    Elapsed: 10:28:04.\n",
            "  Batch 82,080  of  114,829.    Elapsed: 10:28:22.\n",
            "  Batch 82,120  of  114,829.    Elapsed: 10:28:41.\n",
            "  Batch 82,160  of  114,829.    Elapsed: 10:28:59.\n",
            "  Batch 82,200  of  114,829.    Elapsed: 10:29:18.\n",
            "  Batch 82,240  of  114,829.    Elapsed: 10:29:36.\n",
            "  Batch 82,280  of  114,829.    Elapsed: 10:29:54.\n",
            "  Batch 82,320  of  114,829.    Elapsed: 10:30:13.\n",
            "  Batch 82,360  of  114,829.    Elapsed: 10:30:31.\n",
            "  Batch 82,400  of  114,829.    Elapsed: 10:30:49.\n",
            "  Batch 82,440  of  114,829.    Elapsed: 10:31:08.\n",
            "  Batch 82,480  of  114,829.    Elapsed: 10:31:26.\n",
            "  Batch 82,520  of  114,829.    Elapsed: 10:31:45.\n",
            "  Batch 82,560  of  114,829.    Elapsed: 10:32:03.\n",
            "  Batch 82,600  of  114,829.    Elapsed: 10:32:21.\n",
            "  Batch 82,640  of  114,829.    Elapsed: 10:32:40.\n",
            "  Batch 82,680  of  114,829.    Elapsed: 10:32:58.\n",
            "  Batch 82,720  of  114,829.    Elapsed: 10:33:16.\n",
            "  Batch 82,760  of  114,829.    Elapsed: 10:33:35.\n",
            "  Batch 82,800  of  114,829.    Elapsed: 10:33:53.\n",
            "  Batch 82,840  of  114,829.    Elapsed: 10:34:11.\n",
            "  Batch 82,880  of  114,829.    Elapsed: 10:34:30.\n",
            "  Batch 82,920  of  114,829.    Elapsed: 10:34:48.\n",
            "  Batch 82,960  of  114,829.    Elapsed: 10:35:07.\n",
            "  Batch 83,000  of  114,829.    Elapsed: 10:35:25.\n",
            "  Batch 83,040  of  114,829.    Elapsed: 10:35:43.\n",
            "  Batch 83,080  of  114,829.    Elapsed: 10:36:02.\n",
            "  Batch 83,120  of  114,829.    Elapsed: 10:36:20.\n",
            "  Batch 83,160  of  114,829.    Elapsed: 10:36:39.\n",
            "  Batch 83,200  of  114,829.    Elapsed: 10:36:57.\n",
            "  Batch 83,240  of  114,829.    Elapsed: 10:37:15.\n",
            "  Batch 83,280  of  114,829.    Elapsed: 10:37:34.\n",
            "  Batch 83,320  of  114,829.    Elapsed: 10:37:52.\n",
            "  Batch 83,360  of  114,829.    Elapsed: 10:38:10.\n",
            "  Batch 83,400  of  114,829.    Elapsed: 10:38:29.\n",
            "  Batch 83,440  of  114,829.    Elapsed: 10:38:47.\n",
            "  Batch 83,480  of  114,829.    Elapsed: 10:39:06.\n",
            "  Batch 83,520  of  114,829.    Elapsed: 10:39:24.\n",
            "  Batch 83,560  of  114,829.    Elapsed: 10:39:42.\n",
            "  Batch 83,600  of  114,829.    Elapsed: 10:40:01.\n",
            "  Batch 83,640  of  114,829.    Elapsed: 10:40:19.\n",
            "  Batch 83,680  of  114,829.    Elapsed: 10:40:37.\n",
            "  Batch 83,720  of  114,829.    Elapsed: 10:40:56.\n",
            "  Batch 83,760  of  114,829.    Elapsed: 10:41:14.\n",
            "  Batch 83,800  of  114,829.    Elapsed: 10:41:33.\n",
            "  Batch 83,840  of  114,829.    Elapsed: 10:41:51.\n",
            "  Batch 83,880  of  114,829.    Elapsed: 10:42:09.\n",
            "  Batch 83,920  of  114,829.    Elapsed: 10:42:28.\n",
            "  Batch 83,960  of  114,829.    Elapsed: 10:42:46.\n",
            "  Batch 84,000  of  114,829.    Elapsed: 10:43:04.\n",
            "  Batch 84,040  of  114,829.    Elapsed: 10:43:23.\n",
            "  Batch 84,080  of  114,829.    Elapsed: 10:43:41.\n",
            "  Batch 84,120  of  114,829.    Elapsed: 10:43:59.\n",
            "  Batch 84,160  of  114,829.    Elapsed: 10:44:18.\n",
            "  Batch 84,200  of  114,829.    Elapsed: 10:44:36.\n",
            "  Batch 84,240  of  114,829.    Elapsed: 10:44:54.\n",
            "  Batch 84,280  of  114,829.    Elapsed: 10:45:13.\n",
            "  Batch 84,320  of  114,829.    Elapsed: 10:45:31.\n",
            "  Batch 84,360  of  114,829.    Elapsed: 10:45:50.\n",
            "  Batch 84,400  of  114,829.    Elapsed: 10:46:08.\n",
            "  Batch 84,440  of  114,829.    Elapsed: 10:46:26.\n",
            "  Batch 84,480  of  114,829.    Elapsed: 10:46:45.\n",
            "  Batch 84,520  of  114,829.    Elapsed: 10:47:03.\n",
            "  Batch 84,560  of  114,829.    Elapsed: 10:47:22.\n",
            "  Batch 84,600  of  114,829.    Elapsed: 10:47:40.\n",
            "  Batch 84,640  of  114,829.    Elapsed: 10:47:58.\n",
            "  Batch 84,680  of  114,829.    Elapsed: 10:48:17.\n",
            "  Batch 84,720  of  114,829.    Elapsed: 10:48:35.\n",
            "  Batch 84,760  of  114,829.    Elapsed: 10:48:53.\n",
            "  Batch 84,800  of  114,829.    Elapsed: 10:49:12.\n",
            "  Batch 84,840  of  114,829.    Elapsed: 10:49:30.\n",
            "  Batch 84,880  of  114,829.    Elapsed: 10:49:48.\n",
            "  Batch 84,920  of  114,829.    Elapsed: 10:50:07.\n",
            "  Batch 84,960  of  114,829.    Elapsed: 10:50:25.\n",
            "  Batch 85,000  of  114,829.    Elapsed: 10:50:44.\n",
            "  Batch 85,040  of  114,829.    Elapsed: 10:51:02.\n",
            "  Batch 85,080  of  114,829.    Elapsed: 10:51:20.\n",
            "  Batch 85,120  of  114,829.    Elapsed: 10:51:39.\n",
            "  Batch 85,160  of  114,829.    Elapsed: 10:51:57.\n",
            "  Batch 85,200  of  114,829.    Elapsed: 10:52:15.\n",
            "  Batch 85,240  of  114,829.    Elapsed: 10:52:34.\n",
            "  Batch 85,280  of  114,829.    Elapsed: 10:52:52.\n",
            "  Batch 85,320  of  114,829.    Elapsed: 10:53:11.\n",
            "  Batch 85,360  of  114,829.    Elapsed: 10:53:29.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 85,400  of  114,829.    Elapsed: 10:53:47.\n",
            "  Batch 85,440  of  114,829.    Elapsed: 10:54:06.\n",
            "  Batch 85,480  of  114,829.    Elapsed: 10:54:24.\n",
            "  Batch 85,520  of  114,829.    Elapsed: 10:54:42.\n",
            "  Batch 85,560  of  114,829.    Elapsed: 10:55:01.\n",
            "  Batch 85,600  of  114,829.    Elapsed: 10:55:19.\n",
            "  Batch 85,640  of  114,829.    Elapsed: 10:55:38.\n",
            "  Batch 85,680  of  114,829.    Elapsed: 10:55:56.\n",
            "  Batch 85,720  of  114,829.    Elapsed: 10:56:14.\n",
            "  Batch 85,760  of  114,829.    Elapsed: 10:56:33.\n",
            "  Batch 85,800  of  114,829.    Elapsed: 10:56:51.\n",
            "  Batch 85,840  of  114,829.    Elapsed: 10:57:09.\n",
            "  Batch 85,880  of  114,829.    Elapsed: 10:57:28.\n",
            "  Batch 85,920  of  114,829.    Elapsed: 10:57:46.\n",
            "  Batch 85,960  of  114,829.    Elapsed: 10:58:04.\n",
            "  Batch 86,000  of  114,829.    Elapsed: 10:58:23.\n",
            "  Batch 86,040  of  114,829.    Elapsed: 10:58:41.\n",
            "  Batch 86,080  of  114,829.    Elapsed: 10:59:00.\n",
            "  Batch 86,120  of  114,829.    Elapsed: 10:59:18.\n",
            "  Batch 86,160  of  114,829.    Elapsed: 10:59:36.\n",
            "  Batch 86,200  of  114,829.    Elapsed: 10:59:55.\n",
            "  Batch 86,240  of  114,829.    Elapsed: 11:00:13.\n",
            "  Batch 86,280  of  114,829.    Elapsed: 11:00:31.\n",
            "  Batch 86,320  of  114,829.    Elapsed: 11:00:50.\n",
            "  Batch 86,360  of  114,829.    Elapsed: 11:01:08.\n",
            "  Batch 86,400  of  114,829.    Elapsed: 11:01:27.\n",
            "  Batch 86,440  of  114,829.    Elapsed: 11:01:45.\n",
            "  Batch 86,480  of  114,829.    Elapsed: 11:02:03.\n",
            "  Batch 86,520  of  114,829.    Elapsed: 11:02:22.\n",
            "  Batch 86,560  of  114,829.    Elapsed: 11:02:40.\n",
            "  Batch 86,600  of  114,829.    Elapsed: 11:02:58.\n",
            "  Batch 86,640  of  114,829.    Elapsed: 11:03:17.\n",
            "  Batch 86,680  of  114,829.    Elapsed: 11:03:35.\n",
            "  Batch 86,720  of  114,829.    Elapsed: 11:03:53.\n",
            "  Batch 86,760  of  114,829.    Elapsed: 11:04:12.\n",
            "  Batch 86,800  of  114,829.    Elapsed: 11:04:30.\n",
            "  Batch 86,840  of  114,829.    Elapsed: 11:04:48.\n",
            "  Batch 86,880  of  114,829.    Elapsed: 11:05:07.\n",
            "  Batch 86,920  of  114,829.    Elapsed: 11:05:25.\n",
            "  Batch 86,960  of  114,829.    Elapsed: 11:05:44.\n",
            "  Batch 87,000  of  114,829.    Elapsed: 11:06:02.\n",
            "  Batch 87,040  of  114,829.    Elapsed: 11:06:20.\n",
            "  Batch 87,080  of  114,829.    Elapsed: 11:06:39.\n",
            "  Batch 87,120  of  114,829.    Elapsed: 11:06:57.\n",
            "  Batch 87,160  of  114,829.    Elapsed: 11:07:15.\n",
            "  Batch 87,200  of  114,829.    Elapsed: 11:07:34.\n",
            "  Batch 87,240  of  114,829.    Elapsed: 11:07:52.\n",
            "  Batch 87,280  of  114,829.    Elapsed: 11:08:11.\n",
            "  Batch 87,320  of  114,829.    Elapsed: 11:08:29.\n",
            "  Batch 87,360  of  114,829.    Elapsed: 11:08:47.\n",
            "  Batch 87,400  of  114,829.    Elapsed: 11:09:06.\n",
            "  Batch 87,440  of  114,829.    Elapsed: 11:09:24.\n",
            "  Batch 87,480  of  114,829.    Elapsed: 11:09:42.\n",
            "  Batch 87,520  of  114,829.    Elapsed: 11:10:01.\n",
            "  Batch 87,560  of  114,829.    Elapsed: 11:10:19.\n",
            "  Batch 87,600  of  114,829.    Elapsed: 11:10:38.\n",
            "  Batch 87,640  of  114,829.    Elapsed: 11:10:56.\n",
            "  Batch 87,680  of  114,829.    Elapsed: 11:11:14.\n",
            "  Batch 87,720  of  114,829.    Elapsed: 11:11:33.\n",
            "  Batch 87,760  of  114,829.    Elapsed: 11:11:51.\n",
            "  Batch 87,800  of  114,829.    Elapsed: 11:12:09.\n",
            "  Batch 87,840  of  114,829.    Elapsed: 11:12:28.\n",
            "  Batch 87,880  of  114,829.    Elapsed: 11:12:46.\n",
            "  Batch 87,920  of  114,829.    Elapsed: 11:13:05.\n",
            "  Batch 87,960  of  114,829.    Elapsed: 11:13:23.\n",
            "  Batch 88,000  of  114,829.    Elapsed: 11:13:41.\n",
            "  Batch 88,040  of  114,829.    Elapsed: 11:14:00.\n",
            "  Batch 88,080  of  114,829.    Elapsed: 11:14:18.\n",
            "  Batch 88,120  of  114,829.    Elapsed: 11:14:36.\n",
            "  Batch 88,160  of  114,829.    Elapsed: 11:14:55.\n",
            "  Batch 88,200  of  114,829.    Elapsed: 11:15:13.\n",
            "  Batch 88,240  of  114,829.    Elapsed: 11:15:32.\n",
            "  Batch 88,280  of  114,829.    Elapsed: 11:15:50.\n",
            "  Batch 88,320  of  114,829.    Elapsed: 11:16:09.\n",
            "  Batch 88,360  of  114,829.    Elapsed: 11:16:27.\n",
            "  Batch 88,400  of  114,829.    Elapsed: 11:16:45.\n",
            "  Batch 88,440  of  114,829.    Elapsed: 11:17:04.\n",
            "  Batch 88,480  of  114,829.    Elapsed: 11:17:22.\n",
            "  Batch 88,520  of  114,829.    Elapsed: 11:17:41.\n",
            "  Batch 88,560  of  114,829.    Elapsed: 11:17:59.\n",
            "  Batch 88,600  of  114,829.    Elapsed: 11:18:18.\n",
            "  Batch 88,640  of  114,829.    Elapsed: 11:18:36.\n",
            "  Batch 88,680  of  114,829.    Elapsed: 11:18:54.\n",
            "  Batch 88,720  of  114,829.    Elapsed: 11:19:13.\n",
            "  Batch 88,760  of  114,829.    Elapsed: 11:19:31.\n",
            "  Batch 88,800  of  114,829.    Elapsed: 11:19:50.\n",
            "  Batch 88,840  of  114,829.    Elapsed: 11:20:08.\n",
            "  Batch 88,880  of  114,829.    Elapsed: 11:20:27.\n",
            "  Batch 88,920  of  114,829.    Elapsed: 11:20:45.\n",
            "  Batch 88,960  of  114,829.    Elapsed: 11:21:03.\n",
            "  Batch 89,000  of  114,829.    Elapsed: 11:21:22.\n",
            "  Batch 89,040  of  114,829.    Elapsed: 11:21:40.\n",
            "  Batch 89,080  of  114,829.    Elapsed: 11:21:59.\n",
            "  Batch 89,120  of  114,829.    Elapsed: 11:22:17.\n",
            "  Batch 89,160  of  114,829.    Elapsed: 11:22:36.\n",
            "  Batch 89,200  of  114,829.    Elapsed: 11:22:54.\n",
            "  Batch 89,240  of  114,829.    Elapsed: 11:23:12.\n",
            "  Batch 89,280  of  114,829.    Elapsed: 11:23:31.\n",
            "  Batch 89,320  of  114,829.    Elapsed: 11:23:49.\n",
            "  Batch 89,360  of  114,829.    Elapsed: 11:24:08.\n",
            "  Batch 89,400  of  114,829.    Elapsed: 11:24:26.\n",
            "  Batch 89,440  of  114,829.    Elapsed: 11:24:44.\n",
            "  Batch 89,480  of  114,829.    Elapsed: 11:25:03.\n",
            "  Batch 89,520  of  114,829.    Elapsed: 11:25:21.\n",
            "  Batch 89,560  of  114,829.    Elapsed: 11:25:40.\n",
            "  Batch 89,600  of  114,829.    Elapsed: 11:25:58.\n",
            "  Batch 89,640  of  114,829.    Elapsed: 11:26:17.\n",
            "  Batch 89,680  of  114,829.    Elapsed: 11:26:35.\n",
            "  Batch 89,720  of  114,829.    Elapsed: 11:26:53.\n",
            "  Batch 89,760  of  114,829.    Elapsed: 11:27:12.\n",
            "  Batch 89,800  of  114,829.    Elapsed: 11:27:30.\n",
            "  Batch 89,840  of  114,829.    Elapsed: 11:27:49.\n",
            "  Batch 89,880  of  114,829.    Elapsed: 11:28:07.\n",
            "  Batch 89,920  of  114,829.    Elapsed: 11:28:26.\n",
            "  Batch 89,960  of  114,829.    Elapsed: 11:28:44.\n",
            "  Batch 90,000  of  114,829.    Elapsed: 11:29:02.\n",
            "  Batch 90,040  of  114,829.    Elapsed: 11:29:21.\n",
            "  Batch 90,080  of  114,829.    Elapsed: 11:29:39.\n",
            "  Batch 90,120  of  114,829.    Elapsed: 11:29:58.\n",
            "  Batch 90,160  of  114,829.    Elapsed: 11:30:16.\n",
            "  Batch 90,200  of  114,829.    Elapsed: 11:30:34.\n",
            "  Batch 90,240  of  114,829.    Elapsed: 11:30:53.\n",
            "  Batch 90,280  of  114,829.    Elapsed: 11:31:11.\n",
            "  Batch 90,320  of  114,829.    Elapsed: 11:31:30.\n",
            "  Batch 90,360  of  114,829.    Elapsed: 11:31:48.\n",
            "  Batch 90,400  of  114,829.    Elapsed: 11:32:07.\n",
            "  Batch 90,440  of  114,829.    Elapsed: 11:32:25.\n",
            "  Batch 90,480  of  114,829.    Elapsed: 11:32:43.\n",
            "  Batch 90,520  of  114,829.    Elapsed: 11:33:02.\n",
            "  Batch 90,560  of  114,829.    Elapsed: 11:33:20.\n",
            "  Batch 90,600  of  114,829.    Elapsed: 11:33:39.\n",
            "  Batch 90,640  of  114,829.    Elapsed: 11:33:57.\n",
            "  Batch 90,680  of  114,829.    Elapsed: 11:34:15.\n",
            "  Batch 90,720  of  114,829.    Elapsed: 11:34:34.\n",
            "  Batch 90,760  of  114,829.    Elapsed: 11:34:52.\n",
            "  Batch 90,800  of  114,829.    Elapsed: 11:35:11.\n",
            "  Batch 90,840  of  114,829.    Elapsed: 11:35:29.\n",
            "  Batch 90,880  of  114,829.    Elapsed: 11:35:48.\n",
            "  Batch 90,920  of  114,829.    Elapsed: 11:36:06.\n",
            "  Batch 90,960  of  114,829.    Elapsed: 11:36:24.\n",
            "  Batch 91,000  of  114,829.    Elapsed: 11:36:43.\n",
            "  Batch 91,040  of  114,829.    Elapsed: 11:37:01.\n",
            "  Batch 91,080  of  114,829.    Elapsed: 11:37:20.\n",
            "  Batch 91,120  of  114,829.    Elapsed: 11:37:38.\n",
            "  Batch 91,160  of  114,829.    Elapsed: 11:37:56.\n",
            "  Batch 91,200  of  114,829.    Elapsed: 11:38:15.\n",
            "  Batch 91,240  of  114,829.    Elapsed: 11:38:33.\n",
            "  Batch 91,280  of  114,829.    Elapsed: 11:38:52.\n",
            "  Batch 91,320  of  114,829.    Elapsed: 11:39:10.\n",
            "  Batch 91,360  of  114,829.    Elapsed: 11:39:28.\n",
            "  Batch 91,400  of  114,829.    Elapsed: 11:39:47.\n",
            "  Batch 91,440  of  114,829.    Elapsed: 11:40:05.\n",
            "  Batch 91,480  of  114,829.    Elapsed: 11:40:24.\n",
            "  Batch 91,520  of  114,829.    Elapsed: 11:40:42.\n",
            "  Batch 91,560  of  114,829.    Elapsed: 11:41:01.\n",
            "  Batch 91,600  of  114,829.    Elapsed: 11:41:19.\n",
            "  Batch 91,640  of  114,829.    Elapsed: 11:41:37.\n",
            "  Batch 91,680  of  114,829.    Elapsed: 11:41:56.\n",
            "  Batch 91,720  of  114,829.    Elapsed: 11:42:14.\n",
            "  Batch 91,760  of  114,829.    Elapsed: 11:42:33.\n",
            "  Batch 91,800  of  114,829.    Elapsed: 11:42:51.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 91,840  of  114,829.    Elapsed: 11:43:10.\n",
            "  Batch 91,880  of  114,829.    Elapsed: 11:43:28.\n",
            "  Batch 91,920  of  114,829.    Elapsed: 11:43:46.\n",
            "  Batch 91,960  of  114,829.    Elapsed: 11:44:05.\n",
            "  Batch 92,000  of  114,829.    Elapsed: 11:44:23.\n",
            "  Batch 92,040  of  114,829.    Elapsed: 11:44:42.\n",
            "  Batch 92,080  of  114,829.    Elapsed: 11:45:00.\n",
            "  Batch 92,120  of  114,829.    Elapsed: 11:45:18.\n",
            "  Batch 92,160  of  114,829.    Elapsed: 11:45:37.\n",
            "  Batch 92,200  of  114,829.    Elapsed: 11:45:55.\n",
            "  Batch 92,240  of  114,829.    Elapsed: 11:46:14.\n",
            "  Batch 92,280  of  114,829.    Elapsed: 11:46:32.\n",
            "  Batch 92,320  of  114,829.    Elapsed: 11:46:51.\n",
            "  Batch 92,360  of  114,829.    Elapsed: 11:47:09.\n",
            "  Batch 92,400  of  114,829.    Elapsed: 11:47:27.\n",
            "  Batch 92,440  of  114,829.    Elapsed: 11:47:46.\n",
            "  Batch 92,480  of  114,829.    Elapsed: 11:48:04.\n",
            "  Batch 92,520  of  114,829.    Elapsed: 11:48:23.\n",
            "  Batch 92,560  of  114,829.    Elapsed: 11:48:41.\n",
            "  Batch 92,600  of  114,829.    Elapsed: 11:49:00.\n",
            "  Batch 92,640  of  114,829.    Elapsed: 11:49:18.\n",
            "  Batch 92,680  of  114,829.    Elapsed: 11:49:36.\n",
            "  Batch 92,720  of  114,829.    Elapsed: 11:49:55.\n",
            "  Batch 92,760  of  114,829.    Elapsed: 11:50:13.\n",
            "  Batch 92,800  of  114,829.    Elapsed: 11:50:32.\n",
            "  Batch 92,840  of  114,829.    Elapsed: 11:50:50.\n",
            "  Batch 92,880  of  114,829.    Elapsed: 11:51:08.\n",
            "  Batch 92,920  of  114,829.    Elapsed: 11:51:27.\n",
            "  Batch 92,960  of  114,829.    Elapsed: 11:51:45.\n",
            "  Batch 93,000  of  114,829.    Elapsed: 11:52:04.\n",
            "  Batch 93,040  of  114,829.    Elapsed: 11:52:22.\n",
            "  Batch 93,080  of  114,829.    Elapsed: 11:52:41.\n",
            "  Batch 93,120  of  114,829.    Elapsed: 11:52:59.\n",
            "  Batch 93,160  of  114,829.    Elapsed: 11:53:17.\n",
            "  Batch 93,200  of  114,829.    Elapsed: 11:53:36.\n",
            "  Batch 93,240  of  114,829.    Elapsed: 11:53:54.\n",
            "  Batch 93,280  of  114,829.    Elapsed: 11:54:13.\n",
            "  Batch 93,320  of  114,829.    Elapsed: 11:54:31.\n",
            "  Batch 93,360  of  114,829.    Elapsed: 11:54:49.\n",
            "  Batch 93,400  of  114,829.    Elapsed: 11:55:08.\n",
            "  Batch 93,440  of  114,829.    Elapsed: 11:55:26.\n",
            "  Batch 93,480  of  114,829.    Elapsed: 11:55:45.\n",
            "  Batch 93,520  of  114,829.    Elapsed: 11:56:04.\n",
            "  Batch 93,560  of  114,829.    Elapsed: 11:56:22.\n",
            "  Batch 93,600  of  114,829.    Elapsed: 11:56:41.\n",
            "  Batch 93,640  of  114,829.    Elapsed: 11:56:59.\n",
            "  Batch 93,680  of  114,829.    Elapsed: 11:57:18.\n",
            "  Batch 93,720  of  114,829.    Elapsed: 11:57:36.\n",
            "  Batch 93,760  of  114,829.    Elapsed: 11:57:54.\n",
            "  Batch 93,800  of  114,829.    Elapsed: 11:58:13.\n",
            "  Batch 93,840  of  114,829.    Elapsed: 11:58:31.\n",
            "  Batch 93,880  of  114,829.    Elapsed: 11:58:50.\n",
            "  Batch 93,920  of  114,829.    Elapsed: 11:59:08.\n",
            "  Batch 93,960  of  114,829.    Elapsed: 11:59:26.\n",
            "  Batch 94,000  of  114,829.    Elapsed: 11:59:45.\n",
            "  Batch 94,040  of  114,829.    Elapsed: 12:00:03.\n",
            "  Batch 94,080  of  114,829.    Elapsed: 12:00:22.\n",
            "  Batch 94,120  of  114,829.    Elapsed: 12:00:40.\n",
            "  Batch 94,160  of  114,829.    Elapsed: 12:00:58.\n",
            "  Batch 94,200  of  114,829.    Elapsed: 12:01:17.\n",
            "  Batch 94,240  of  114,829.    Elapsed: 12:01:35.\n",
            "  Batch 94,280  of  114,829.    Elapsed: 12:01:54.\n",
            "  Batch 94,320  of  114,829.    Elapsed: 12:02:12.\n",
            "  Batch 94,360  of  114,829.    Elapsed: 12:02:30.\n",
            "  Batch 94,400  of  114,829.    Elapsed: 12:02:49.\n",
            "  Batch 94,440  of  114,829.    Elapsed: 12:03:07.\n",
            "  Batch 94,480  of  114,829.    Elapsed: 12:03:26.\n",
            "  Batch 94,520  of  114,829.    Elapsed: 12:03:44.\n",
            "  Batch 94,560  of  114,829.    Elapsed: 12:04:02.\n",
            "  Batch 94,600  of  114,829.    Elapsed: 12:04:21.\n",
            "  Batch 94,640  of  114,829.    Elapsed: 12:04:39.\n",
            "  Batch 94,680  of  114,829.    Elapsed: 12:04:58.\n",
            "  Batch 94,720  of  114,829.    Elapsed: 12:05:16.\n",
            "  Batch 94,760  of  114,829.    Elapsed: 12:05:34.\n",
            "  Batch 94,800  of  114,829.    Elapsed: 12:05:53.\n",
            "  Batch 94,840  of  114,829.    Elapsed: 12:06:11.\n",
            "  Batch 94,880  of  114,829.    Elapsed: 12:06:29.\n",
            "  Batch 94,920  of  114,829.    Elapsed: 12:06:48.\n",
            "  Batch 94,960  of  114,829.    Elapsed: 12:07:06.\n",
            "  Batch 95,000  of  114,829.    Elapsed: 12:07:25.\n",
            "  Batch 95,040  of  114,829.    Elapsed: 12:07:43.\n",
            "  Batch 95,080  of  114,829.    Elapsed: 12:08:01.\n",
            "  Batch 95,120  of  114,829.    Elapsed: 12:08:20.\n",
            "  Batch 95,160  of  114,829.    Elapsed: 12:08:38.\n",
            "  Batch 95,200  of  114,829.    Elapsed: 12:08:57.\n",
            "  Batch 95,240  of  114,829.    Elapsed: 12:09:15.\n",
            "  Batch 95,280  of  114,829.    Elapsed: 12:09:33.\n",
            "  Batch 95,320  of  114,829.    Elapsed: 12:09:52.\n",
            "  Batch 95,360  of  114,829.    Elapsed: 12:10:10.\n",
            "  Batch 95,400  of  114,829.    Elapsed: 12:10:28.\n",
            "  Batch 95,440  of  114,829.    Elapsed: 12:10:47.\n",
            "  Batch 95,480  of  114,829.    Elapsed: 12:11:05.\n",
            "  Batch 95,520  of  114,829.    Elapsed: 12:11:24.\n",
            "  Batch 95,560  of  114,829.    Elapsed: 12:11:42.\n",
            "  Batch 95,600  of  114,829.    Elapsed: 12:12:01.\n",
            "  Batch 95,640  of  114,829.    Elapsed: 12:12:20.\n",
            "  Batch 95,680  of  114,829.    Elapsed: 12:12:38.\n",
            "  Batch 95,720  of  114,829.    Elapsed: 12:12:57.\n",
            "  Batch 95,760  of  114,829.    Elapsed: 12:13:15.\n",
            "  Batch 95,800  of  114,829.    Elapsed: 12:13:34.\n",
            "  Batch 95,840  of  114,829.    Elapsed: 12:13:52.\n",
            "  Batch 95,880  of  114,829.    Elapsed: 12:14:11.\n",
            "  Batch 95,920  of  114,829.    Elapsed: 12:14:29.\n",
            "  Batch 95,960  of  114,829.    Elapsed: 12:14:48.\n",
            "  Batch 96,000  of  114,829.    Elapsed: 12:15:07.\n",
            "  Batch 96,040  of  114,829.    Elapsed: 12:15:25.\n",
            "  Batch 96,080  of  114,829.    Elapsed: 12:15:44.\n",
            "  Batch 96,120  of  114,829.    Elapsed: 12:16:02.\n",
            "  Batch 96,160  of  114,829.    Elapsed: 12:16:20.\n",
            "  Batch 96,200  of  114,829.    Elapsed: 12:16:39.\n",
            "  Batch 96,240  of  114,829.    Elapsed: 12:16:58.\n",
            "  Batch 96,280  of  114,829.    Elapsed: 12:17:17.\n",
            "  Batch 96,320  of  114,829.    Elapsed: 12:17:36.\n",
            "  Batch 96,360  of  114,829.    Elapsed: 12:17:55.\n",
            "  Batch 96,400  of  114,829.    Elapsed: 12:18:13.\n",
            "  Batch 96,440  of  114,829.    Elapsed: 12:18:32.\n",
            "  Batch 96,480  of  114,829.    Elapsed: 12:18:51.\n",
            "  Batch 96,520  of  114,829.    Elapsed: 12:19:10.\n",
            "  Batch 96,560  of  114,829.    Elapsed: 12:19:29.\n",
            "  Batch 96,600  of  114,829.    Elapsed: 12:19:47.\n",
            "  Batch 96,640  of  114,829.    Elapsed: 12:20:06.\n",
            "  Batch 96,680  of  114,829.    Elapsed: 12:20:25.\n",
            "  Batch 96,720  of  114,829.    Elapsed: 12:20:43.\n",
            "  Batch 96,760  of  114,829.    Elapsed: 12:21:02.\n",
            "  Batch 96,800  of  114,829.    Elapsed: 12:21:21.\n",
            "  Batch 96,840  of  114,829.    Elapsed: 12:21:39.\n",
            "  Batch 96,880  of  114,829.    Elapsed: 12:21:58.\n",
            "  Batch 96,920  of  114,829.    Elapsed: 12:22:16.\n",
            "  Batch 96,960  of  114,829.    Elapsed: 12:22:35.\n",
            "  Batch 97,000  of  114,829.    Elapsed: 12:22:53.\n",
            "  Batch 97,040  of  114,829.    Elapsed: 12:23:12.\n",
            "  Batch 97,080  of  114,829.    Elapsed: 12:23:30.\n",
            "  Batch 97,120  of  114,829.    Elapsed: 12:23:49.\n",
            "  Batch 97,160  of  114,829.    Elapsed: 12:24:07.\n",
            "  Batch 97,200  of  114,829.    Elapsed: 12:24:25.\n",
            "  Batch 97,240  of  114,829.    Elapsed: 12:24:44.\n",
            "  Batch 97,280  of  114,829.    Elapsed: 12:25:02.\n",
            "  Batch 97,320  of  114,829.    Elapsed: 12:25:21.\n",
            "  Batch 97,360  of  114,829.    Elapsed: 12:25:39.\n",
            "  Batch 97,400  of  114,829.    Elapsed: 12:25:58.\n",
            "  Batch 97,440  of  114,829.    Elapsed: 12:26:17.\n",
            "  Batch 97,480  of  114,829.    Elapsed: 12:26:35.\n",
            "  Batch 97,520  of  114,829.    Elapsed: 12:26:54.\n",
            "  Batch 97,560  of  114,829.    Elapsed: 12:27:13.\n",
            "  Batch 97,600  of  114,829.    Elapsed: 12:27:31.\n",
            "  Batch 97,640  of  114,829.    Elapsed: 12:27:50.\n",
            "  Batch 97,680  of  114,829.    Elapsed: 12:28:08.\n",
            "  Batch 97,720  of  114,829.    Elapsed: 12:28:27.\n",
            "  Batch 97,760  of  114,829.    Elapsed: 12:28:46.\n",
            "  Batch 97,800  of  114,829.    Elapsed: 12:29:04.\n",
            "  Batch 97,840  of  114,829.    Elapsed: 12:29:23.\n",
            "  Batch 97,880  of  114,829.    Elapsed: 12:29:42.\n",
            "  Batch 97,920  of  114,829.    Elapsed: 12:30:01.\n",
            "  Batch 97,960  of  114,829.    Elapsed: 12:30:19.\n",
            "  Batch 98,000  of  114,829.    Elapsed: 12:30:38.\n",
            "  Batch 98,040  of  114,829.    Elapsed: 12:30:56.\n",
            "  Batch 98,080  of  114,829.    Elapsed: 12:31:15.\n",
            "  Batch 98,120  of  114,829.    Elapsed: 12:31:33.\n",
            "  Batch 98,160  of  114,829.    Elapsed: 12:31:52.\n",
            "  Batch 98,200  of  114,829.    Elapsed: 12:32:10.\n",
            "  Batch 98,240  of  114,829.    Elapsed: 12:32:28.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 98,280  of  114,829.    Elapsed: 12:32:47.\n",
            "  Batch 98,320  of  114,829.    Elapsed: 12:33:05.\n",
            "  Batch 98,360  of  114,829.    Elapsed: 12:33:24.\n",
            "  Batch 98,400  of  114,829.    Elapsed: 12:33:42.\n",
            "  Batch 98,440  of  114,829.    Elapsed: 12:34:01.\n",
            "  Batch 98,480  of  114,829.    Elapsed: 12:34:20.\n",
            "  Batch 98,520  of  114,829.    Elapsed: 12:34:38.\n",
            "  Batch 98,560  of  114,829.    Elapsed: 12:34:57.\n",
            "  Batch 98,600  of  114,829.    Elapsed: 12:35:15.\n",
            "  Batch 98,640  of  114,829.    Elapsed: 12:35:34.\n",
            "  Batch 98,680  of  114,829.    Elapsed: 12:35:52.\n",
            "  Batch 98,720  of  114,829.    Elapsed: 12:36:11.\n",
            "  Batch 98,760  of  114,829.    Elapsed: 12:36:29.\n",
            "  Batch 98,800  of  114,829.    Elapsed: 12:36:47.\n",
            "  Batch 98,840  of  114,829.    Elapsed: 12:37:06.\n",
            "  Batch 98,880  of  114,829.    Elapsed: 12:37:24.\n",
            "  Batch 98,920  of  114,829.    Elapsed: 12:37:43.\n",
            "  Batch 98,960  of  114,829.    Elapsed: 12:38:01.\n",
            "  Batch 99,000  of  114,829.    Elapsed: 12:38:20.\n",
            "  Batch 99,040  of  114,829.    Elapsed: 12:38:38.\n",
            "  Batch 99,080  of  114,829.    Elapsed: 12:38:55.\n",
            "  Batch 99,120  of  114,829.    Elapsed: 12:39:14.\n",
            "  Batch 99,160  of  114,829.    Elapsed: 12:39:32.\n",
            "  Batch 99,200  of  114,829.    Elapsed: 12:39:51.\n",
            "  Batch 99,240  of  114,829.    Elapsed: 12:40:09.\n",
            "  Batch 99,280  of  114,829.    Elapsed: 12:40:27.\n",
            "  Batch 99,320  of  114,829.    Elapsed: 12:40:46.\n",
            "  Batch 99,360  of  114,829.    Elapsed: 12:41:04.\n",
            "  Batch 99,400  of  114,829.    Elapsed: 12:41:22.\n",
            "  Batch 99,440  of  114,829.    Elapsed: 12:41:41.\n",
            "  Batch 99,480  of  114,829.    Elapsed: 12:41:59.\n",
            "  Batch 99,520  of  114,829.    Elapsed: 12:42:18.\n",
            "  Batch 99,560  of  114,829.    Elapsed: 12:42:36.\n",
            "  Batch 99,600  of  114,829.    Elapsed: 12:42:55.\n",
            "  Batch 99,640  of  114,829.    Elapsed: 12:43:13.\n",
            "  Batch 99,680  of  114,829.    Elapsed: 12:43:32.\n",
            "  Batch 99,720  of  114,829.    Elapsed: 12:43:50.\n",
            "  Batch 99,760  of  114,829.    Elapsed: 12:44:09.\n",
            "  Batch 99,800  of  114,829.    Elapsed: 12:44:27.\n",
            "  Batch 99,840  of  114,829.    Elapsed: 12:44:45.\n",
            "  Batch 99,880  of  114,829.    Elapsed: 12:45:04.\n",
            "  Batch 99,920  of  114,829.    Elapsed: 12:45:22.\n",
            "  Batch 99,960  of  114,829.    Elapsed: 12:45:41.\n",
            "  Batch 100,000  of  114,829.    Elapsed: 12:45:59.\n",
            "  Batch 100,040  of  114,829.    Elapsed: 12:46:17.\n",
            "  Batch 100,080  of  114,829.    Elapsed: 12:46:36.\n",
            "  Batch 100,120  of  114,829.    Elapsed: 12:46:54.\n",
            "  Batch 100,160  of  114,829.    Elapsed: 12:47:12.\n",
            "  Batch 100,200  of  114,829.    Elapsed: 12:47:31.\n",
            "  Batch 100,240  of  114,829.    Elapsed: 12:47:49.\n",
            "  Batch 100,280  of  114,829.    Elapsed: 12:48:07.\n",
            "  Batch 100,320  of  114,829.    Elapsed: 12:48:26.\n",
            "  Batch 100,360  of  114,829.    Elapsed: 12:48:45.\n",
            "  Batch 100,400  of  114,829.    Elapsed: 12:49:04.\n",
            "  Batch 100,440  of  114,829.    Elapsed: 12:49:23.\n",
            "  Batch 100,480  of  114,829.    Elapsed: 12:49:42.\n",
            "  Batch 100,520  of  114,829.    Elapsed: 12:50:01.\n",
            "  Batch 100,560  of  114,829.    Elapsed: 12:50:19.\n",
            "  Batch 100,600  of  114,829.    Elapsed: 12:50:38.\n",
            "  Batch 100,640  of  114,829.    Elapsed: 12:50:56.\n",
            "  Batch 100,680  of  114,829.    Elapsed: 12:51:15.\n",
            "  Batch 100,720  of  114,829.    Elapsed: 12:51:33.\n",
            "  Batch 100,760  of  114,829.    Elapsed: 12:51:52.\n",
            "  Batch 100,800  of  114,829.    Elapsed: 12:52:10.\n",
            "  Batch 100,840  of  114,829.    Elapsed: 12:52:29.\n",
            "  Batch 100,880  of  114,829.    Elapsed: 12:52:47.\n",
            "  Batch 100,920  of  114,829.    Elapsed: 12:53:05.\n",
            "  Batch 100,960  of  114,829.    Elapsed: 12:53:24.\n",
            "  Batch 101,000  of  114,829.    Elapsed: 12:53:42.\n",
            "  Batch 101,040  of  114,829.    Elapsed: 12:54:00.\n",
            "  Batch 101,080  of  114,829.    Elapsed: 12:54:19.\n",
            "  Batch 101,120  of  114,829.    Elapsed: 12:54:37.\n",
            "  Batch 101,160  of  114,829.    Elapsed: 12:54:55.\n",
            "  Batch 101,200  of  114,829.    Elapsed: 12:55:14.\n",
            "  Batch 101,240  of  114,829.    Elapsed: 12:55:32.\n",
            "  Batch 101,280  of  114,829.    Elapsed: 12:55:50.\n",
            "  Batch 101,320  of  114,829.    Elapsed: 12:56:09.\n",
            "  Batch 101,360  of  114,829.    Elapsed: 12:56:27.\n",
            "  Batch 101,400  of  114,829.    Elapsed: 12:56:45.\n",
            "  Batch 101,440  of  114,829.    Elapsed: 12:57:03.\n",
            "  Batch 101,480  of  114,829.    Elapsed: 12:57:22.\n",
            "  Batch 101,520  of  114,829.    Elapsed: 12:57:40.\n",
            "  Batch 101,560  of  114,829.    Elapsed: 12:57:58.\n",
            "  Batch 101,600  of  114,829.    Elapsed: 12:58:17.\n",
            "  Batch 101,640  of  114,829.    Elapsed: 12:58:35.\n",
            "  Batch 101,680  of  114,829.    Elapsed: 12:58:53.\n",
            "  Batch 101,720  of  114,829.    Elapsed: 12:59:12.\n",
            "  Batch 101,760  of  114,829.    Elapsed: 12:59:30.\n",
            "  Batch 101,800  of  114,829.    Elapsed: 12:59:48.\n",
            "  Batch 101,840  of  114,829.    Elapsed: 13:00:07.\n",
            "  Batch 101,880  of  114,829.    Elapsed: 13:00:25.\n",
            "  Batch 101,920  of  114,829.    Elapsed: 13:00:43.\n",
            "  Batch 101,960  of  114,829.    Elapsed: 13:01:01.\n",
            "  Batch 102,000  of  114,829.    Elapsed: 13:01:20.\n",
            "  Batch 102,040  of  114,829.    Elapsed: 13:01:38.\n",
            "  Batch 102,080  of  114,829.    Elapsed: 13:01:56.\n",
            "  Batch 102,120  of  114,829.    Elapsed: 13:02:15.\n",
            "  Batch 102,160  of  114,829.    Elapsed: 13:02:33.\n",
            "  Batch 102,200  of  114,829.    Elapsed: 13:02:51.\n",
            "  Batch 102,240  of  114,829.    Elapsed: 13:03:09.\n",
            "  Batch 102,280  of  114,829.    Elapsed: 13:03:28.\n",
            "  Batch 102,320  of  114,829.    Elapsed: 13:03:46.\n",
            "  Batch 102,360  of  114,829.    Elapsed: 13:04:04.\n",
            "  Batch 102,400  of  114,829.    Elapsed: 13:04:23.\n",
            "  Batch 102,440  of  114,829.    Elapsed: 13:04:41.\n",
            "  Batch 102,480  of  114,829.    Elapsed: 13:04:59.\n",
            "  Batch 102,520  of  114,829.    Elapsed: 13:05:18.\n",
            "  Batch 102,560  of  114,829.    Elapsed: 13:05:36.\n",
            "  Batch 102,600  of  114,829.    Elapsed: 13:05:54.\n",
            "  Batch 102,640  of  114,829.    Elapsed: 13:06:12.\n",
            "  Batch 102,680  of  114,829.    Elapsed: 13:06:31.\n",
            "  Batch 102,720  of  114,829.    Elapsed: 13:06:49.\n",
            "  Batch 102,760  of  114,829.    Elapsed: 13:07:07.\n",
            "  Batch 102,800  of  114,829.    Elapsed: 13:07:25.\n",
            "  Batch 102,840  of  114,829.    Elapsed: 13:07:44.\n",
            "  Batch 102,880  of  114,829.    Elapsed: 13:08:02.\n",
            "  Batch 102,920  of  114,829.    Elapsed: 13:08:20.\n",
            "  Batch 102,960  of  114,829.    Elapsed: 13:08:39.\n",
            "  Batch 103,000  of  114,829.    Elapsed: 13:08:57.\n",
            "  Batch 103,040  of  114,829.    Elapsed: 13:09:15.\n",
            "  Batch 103,080  of  114,829.    Elapsed: 13:09:34.\n",
            "  Batch 103,120  of  114,829.    Elapsed: 13:09:52.\n",
            "  Batch 103,160  of  114,829.    Elapsed: 13:10:10.\n",
            "  Batch 103,200  of  114,829.    Elapsed: 13:10:29.\n",
            "  Batch 103,240  of  114,829.    Elapsed: 13:10:47.\n",
            "  Batch 103,280  of  114,829.    Elapsed: 13:11:05.\n",
            "  Batch 103,320  of  114,829.    Elapsed: 13:11:24.\n",
            "  Batch 103,360  of  114,829.    Elapsed: 13:11:42.\n",
            "  Batch 103,400  of  114,829.    Elapsed: 13:12:00.\n",
            "  Batch 103,440  of  114,829.    Elapsed: 13:12:19.\n",
            "  Batch 103,480  of  114,829.    Elapsed: 13:12:37.\n",
            "  Batch 103,520  of  114,829.    Elapsed: 13:12:55.\n",
            "  Batch 103,560  of  114,829.    Elapsed: 13:13:14.\n",
            "  Batch 103,600  of  114,829.    Elapsed: 13:13:32.\n",
            "  Batch 103,640  of  114,829.    Elapsed: 13:13:50.\n",
            "  Batch 103,680  of  114,829.    Elapsed: 13:14:09.\n",
            "  Batch 103,720  of  114,829.    Elapsed: 13:14:27.\n",
            "  Batch 103,760  of  114,829.    Elapsed: 13:14:45.\n",
            "  Batch 103,800  of  114,829.    Elapsed: 13:15:04.\n",
            "  Batch 103,840  of  114,829.    Elapsed: 13:15:22.\n",
            "  Batch 103,880  of  114,829.    Elapsed: 13:15:40.\n",
            "  Batch 103,920  of  114,829.    Elapsed: 13:15:59.\n",
            "  Batch 103,960  of  114,829.    Elapsed: 13:16:17.\n",
            "  Batch 104,000  of  114,829.    Elapsed: 13:16:35.\n",
            "  Batch 104,040  of  114,829.    Elapsed: 13:16:54.\n",
            "  Batch 104,080  of  114,829.    Elapsed: 13:17:12.\n",
            "  Batch 104,120  of  114,829.    Elapsed: 13:17:30.\n",
            "  Batch 104,160  of  114,829.    Elapsed: 13:17:49.\n",
            "  Batch 104,200  of  114,829.    Elapsed: 13:18:07.\n",
            "  Batch 104,240  of  114,829.    Elapsed: 13:18:25.\n",
            "  Batch 104,280  of  114,829.    Elapsed: 13:18:43.\n",
            "  Batch 104,320  of  114,829.    Elapsed: 13:19:02.\n",
            "  Batch 104,360  of  114,829.    Elapsed: 13:19:20.\n",
            "  Batch 104,400  of  114,829.    Elapsed: 13:19:38.\n",
            "  Batch 104,440  of  114,829.    Elapsed: 13:19:57.\n",
            "  Batch 104,480  of  114,829.    Elapsed: 13:20:15.\n",
            "  Batch 104,520  of  114,829.    Elapsed: 13:20:33.\n",
            "  Batch 104,560  of  114,829.    Elapsed: 13:20:52.\n",
            "  Batch 104,600  of  114,829.    Elapsed: 13:21:10.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 104,640  of  114,829.    Elapsed: 13:21:28.\n",
            "  Batch 104,680  of  114,829.    Elapsed: 13:21:47.\n",
            "  Batch 104,720  of  114,829.    Elapsed: 13:22:05.\n",
            "  Batch 104,760  of  114,829.    Elapsed: 13:22:23.\n",
            "  Batch 104,800  of  114,829.    Elapsed: 13:22:42.\n",
            "  Batch 104,840  of  114,829.    Elapsed: 13:23:00.\n",
            "  Batch 104,880  of  114,829.    Elapsed: 13:23:18.\n",
            "  Batch 104,920  of  114,829.    Elapsed: 13:23:37.\n",
            "  Batch 104,960  of  114,829.    Elapsed: 13:23:55.\n",
            "  Batch 105,000  of  114,829.    Elapsed: 13:24:13.\n",
            "  Batch 105,040  of  114,829.    Elapsed: 13:24:32.\n",
            "  Batch 105,080  of  114,829.    Elapsed: 13:24:50.\n",
            "  Batch 105,120  of  114,829.    Elapsed: 13:25:08.\n",
            "  Batch 105,160  of  114,829.    Elapsed: 13:25:27.\n",
            "  Batch 105,200  of  114,829.    Elapsed: 13:25:45.\n",
            "  Batch 105,240  of  114,829.    Elapsed: 13:26:03.\n",
            "  Batch 105,280  of  114,829.    Elapsed: 13:26:22.\n",
            "  Batch 105,320  of  114,829.    Elapsed: 13:26:40.\n",
            "  Batch 105,360  of  114,829.    Elapsed: 13:26:58.\n",
            "  Batch 105,400  of  114,829.    Elapsed: 13:27:17.\n",
            "  Batch 105,440  of  114,829.    Elapsed: 13:27:35.\n",
            "  Batch 105,480  of  114,829.    Elapsed: 13:27:53.\n",
            "  Batch 105,520  of  114,829.    Elapsed: 13:28:11.\n",
            "  Batch 105,560  of  114,829.    Elapsed: 13:28:30.\n",
            "  Batch 105,600  of  114,829.    Elapsed: 13:28:48.\n",
            "  Batch 105,640  of  114,829.    Elapsed: 13:29:07.\n",
            "  Batch 105,680  of  114,829.    Elapsed: 13:29:25.\n",
            "  Batch 105,720  of  114,829.    Elapsed: 13:29:43.\n",
            "  Batch 105,760  of  114,829.    Elapsed: 13:30:02.\n",
            "  Batch 105,800  of  114,829.    Elapsed: 13:30:20.\n",
            "  Batch 105,840  of  114,829.    Elapsed: 13:30:38.\n",
            "  Batch 105,880  of  114,829.    Elapsed: 13:30:56.\n",
            "  Batch 105,920  of  114,829.    Elapsed: 13:31:15.\n",
            "  Batch 105,960  of  114,829.    Elapsed: 13:31:33.\n",
            "  Batch 106,000  of  114,829.    Elapsed: 13:31:51.\n",
            "  Batch 106,040  of  114,829.    Elapsed: 13:32:10.\n",
            "  Batch 106,080  of  114,829.    Elapsed: 13:32:28.\n",
            "  Batch 106,120  of  114,829.    Elapsed: 13:32:46.\n",
            "  Batch 106,160  of  114,829.    Elapsed: 13:33:05.\n",
            "  Batch 106,200  of  114,829.    Elapsed: 13:33:23.\n",
            "  Batch 106,240  of  114,829.    Elapsed: 13:33:42.\n",
            "  Batch 106,280  of  114,829.    Elapsed: 13:34:00.\n",
            "  Batch 106,320  of  114,829.    Elapsed: 13:34:18.\n",
            "  Batch 106,360  of  114,829.    Elapsed: 13:34:36.\n",
            "  Batch 106,400  of  114,829.    Elapsed: 13:34:55.\n",
            "  Batch 106,440  of  114,829.    Elapsed: 13:35:13.\n",
            "  Batch 106,480  of  114,829.    Elapsed: 13:35:32.\n",
            "  Batch 106,520  of  114,829.    Elapsed: 13:35:51.\n",
            "  Batch 106,560  of  114,829.    Elapsed: 13:36:09.\n",
            "  Batch 106,600  of  114,829.    Elapsed: 13:36:28.\n",
            "  Batch 106,640  of  114,829.    Elapsed: 13:36:46.\n",
            "  Batch 106,680  of  114,829.    Elapsed: 13:37:05.\n",
            "  Batch 106,720  of  114,829.    Elapsed: 13:37:23.\n",
            "  Batch 106,760  of  114,829.    Elapsed: 13:37:42.\n",
            "  Batch 106,800  of  114,829.    Elapsed: 13:38:00.\n",
            "  Batch 106,840  of  114,829.    Elapsed: 13:38:19.\n",
            "  Batch 106,880  of  114,829.    Elapsed: 13:38:37.\n",
            "  Batch 106,920  of  114,829.    Elapsed: 13:38:56.\n",
            "  Batch 106,960  of  114,829.    Elapsed: 13:39:15.\n",
            "  Batch 107,000  of  114,829.    Elapsed: 13:39:33.\n",
            "  Batch 107,040  of  114,829.    Elapsed: 13:39:52.\n",
            "  Batch 107,080  of  114,829.    Elapsed: 13:40:11.\n",
            "  Batch 107,120  of  114,829.    Elapsed: 13:40:29.\n",
            "  Batch 107,160  of  114,829.    Elapsed: 13:40:48.\n",
            "  Batch 107,200  of  114,829.    Elapsed: 13:41:06.\n",
            "  Batch 107,240  of  114,829.    Elapsed: 13:41:25.\n",
            "  Batch 107,280  of  114,829.    Elapsed: 13:41:43.\n",
            "  Batch 107,320  of  114,829.    Elapsed: 13:42:02.\n",
            "  Batch 107,360  of  114,829.    Elapsed: 13:42:20.\n",
            "  Batch 107,400  of  114,829.    Elapsed: 13:42:39.\n",
            "  Batch 107,440  of  114,829.    Elapsed: 13:42:57.\n",
            "  Batch 107,480  of  114,829.    Elapsed: 13:43:15.\n",
            "  Batch 107,520  of  114,829.    Elapsed: 13:43:34.\n",
            "  Batch 107,560  of  114,829.    Elapsed: 13:43:52.\n",
            "  Batch 107,600  of  114,829.    Elapsed: 13:44:11.\n",
            "  Batch 107,640  of  114,829.    Elapsed: 13:44:29.\n",
            "  Batch 107,680  of  114,829.    Elapsed: 13:44:48.\n",
            "  Batch 107,720  of  114,829.    Elapsed: 13:45:06.\n",
            "  Batch 107,760  of  114,829.    Elapsed: 13:45:25.\n",
            "  Batch 107,800  of  114,829.    Elapsed: 13:45:43.\n",
            "  Batch 107,840  of  114,829.    Elapsed: 13:46:02.\n",
            "  Batch 107,880  of  114,829.    Elapsed: 13:46:20.\n",
            "  Batch 107,920  of  114,829.    Elapsed: 13:46:39.\n",
            "  Batch 107,960  of  114,829.    Elapsed: 13:46:57.\n",
            "  Batch 108,000  of  114,829.    Elapsed: 13:47:15.\n",
            "  Batch 108,040  of  114,829.    Elapsed: 13:47:34.\n",
            "  Batch 108,080  of  114,829.    Elapsed: 13:47:52.\n",
            "  Batch 108,120  of  114,829.    Elapsed: 13:48:11.\n",
            "  Batch 108,160  of  114,829.    Elapsed: 13:48:29.\n",
            "  Batch 108,200  of  114,829.    Elapsed: 13:48:48.\n",
            "  Batch 108,240  of  114,829.    Elapsed: 13:49:07.\n",
            "  Batch 108,280  of  114,829.    Elapsed: 13:49:26.\n",
            "  Batch 108,320  of  114,829.    Elapsed: 13:49:44.\n",
            "  Batch 108,360  of  114,829.    Elapsed: 13:50:02.\n",
            "  Batch 108,400  of  114,829.    Elapsed: 13:50:21.\n",
            "  Batch 108,440  of  114,829.    Elapsed: 13:50:39.\n",
            "  Batch 108,480  of  114,829.    Elapsed: 13:50:58.\n",
            "  Batch 108,520  of  114,829.    Elapsed: 13:51:16.\n",
            "  Batch 108,560  of  114,829.    Elapsed: 13:51:34.\n",
            "  Batch 108,600  of  114,829.    Elapsed: 13:51:53.\n",
            "  Batch 108,640  of  114,829.    Elapsed: 13:52:11.\n",
            "  Batch 108,680  of  114,829.    Elapsed: 13:52:30.\n",
            "  Batch 108,720  of  114,829.    Elapsed: 13:52:48.\n",
            "  Batch 108,760  of  114,829.    Elapsed: 13:53:07.\n",
            "  Batch 108,800  of  114,829.    Elapsed: 13:53:25.\n",
            "  Batch 108,840  of  114,829.    Elapsed: 13:53:44.\n",
            "  Batch 108,880  of  114,829.    Elapsed: 13:54:03.\n",
            "  Batch 108,920  of  114,829.    Elapsed: 13:54:21.\n",
            "  Batch 108,960  of  114,829.    Elapsed: 13:54:39.\n",
            "  Batch 109,000  of  114,829.    Elapsed: 13:54:58.\n",
            "  Batch 109,040  of  114,829.    Elapsed: 13:55:16.\n",
            "  Batch 109,080  of  114,829.    Elapsed: 13:55:35.\n",
            "  Batch 109,120  of  114,829.    Elapsed: 13:55:53.\n",
            "  Batch 109,160  of  114,829.    Elapsed: 13:56:11.\n",
            "  Batch 109,200  of  114,829.    Elapsed: 13:56:30.\n",
            "  Batch 109,240  of  114,829.    Elapsed: 13:56:49.\n",
            "  Batch 109,280  of  114,829.    Elapsed: 13:57:07.\n",
            "  Batch 109,320  of  114,829.    Elapsed: 13:57:26.\n",
            "  Batch 109,360  of  114,829.    Elapsed: 13:57:44.\n",
            "  Batch 109,400  of  114,829.    Elapsed: 13:58:02.\n",
            "  Batch 109,440  of  114,829.    Elapsed: 13:58:21.\n",
            "  Batch 109,480  of  114,829.    Elapsed: 13:58:39.\n",
            "  Batch 109,520  of  114,829.    Elapsed: 13:58:58.\n",
            "  Batch 109,560  of  114,829.    Elapsed: 13:59:16.\n",
            "  Batch 109,600  of  114,829.    Elapsed: 13:59:35.\n",
            "  Batch 109,640  of  114,829.    Elapsed: 13:59:53.\n",
            "  Batch 109,680  of  114,829.    Elapsed: 14:00:11.\n",
            "  Batch 109,720  of  114,829.    Elapsed: 14:00:30.\n",
            "  Batch 109,760  of  114,829.    Elapsed: 14:00:48.\n",
            "  Batch 109,800  of  114,829.    Elapsed: 14:01:07.\n",
            "  Batch 109,840  of  114,829.    Elapsed: 14:01:26.\n",
            "  Batch 109,880  of  114,829.    Elapsed: 14:01:45.\n",
            "  Batch 109,920  of  114,829.    Elapsed: 14:02:04.\n",
            "  Batch 109,960  of  114,829.    Elapsed: 14:02:23.\n",
            "  Batch 110,000  of  114,829.    Elapsed: 14:02:41.\n",
            "  Batch 110,040  of  114,829.    Elapsed: 14:03:00.\n",
            "  Batch 110,080  of  114,829.    Elapsed: 14:03:18.\n",
            "  Batch 110,120  of  114,829.    Elapsed: 14:03:37.\n",
            "  Batch 110,160  of  114,829.    Elapsed: 14:03:55.\n",
            "  Batch 110,200  of  114,829.    Elapsed: 14:04:13.\n",
            "  Batch 110,240  of  114,829.    Elapsed: 14:04:32.\n",
            "  Batch 110,280  of  114,829.    Elapsed: 14:04:50.\n",
            "  Batch 110,320  of  114,829.    Elapsed: 14:05:09.\n",
            "  Batch 110,360  of  114,829.    Elapsed: 14:05:28.\n",
            "  Batch 110,400  of  114,829.    Elapsed: 14:05:46.\n",
            "  Batch 110,440  of  114,829.    Elapsed: 14:06:05.\n",
            "  Batch 110,480  of  114,829.    Elapsed: 14:06:23.\n",
            "  Batch 110,520  of  114,829.    Elapsed: 14:06:42.\n",
            "  Batch 110,560  of  114,829.    Elapsed: 14:07:00.\n",
            "  Batch 110,600  of  114,829.    Elapsed: 14:07:18.\n",
            "  Batch 110,640  of  114,829.    Elapsed: 14:07:37.\n",
            "  Batch 110,680  of  114,829.    Elapsed: 14:07:55.\n",
            "  Batch 110,720  of  114,829.    Elapsed: 14:08:14.\n",
            "  Batch 110,760  of  114,829.    Elapsed: 14:08:32.\n",
            "  Batch 110,800  of  114,829.    Elapsed: 14:08:50.\n",
            "  Batch 110,840  of  114,829.    Elapsed: 14:09:09.\n",
            "  Batch 110,880  of  114,829.    Elapsed: 14:09:27.\n",
            "  Batch 110,920  of  114,829.    Elapsed: 14:09:45.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 110,960  of  114,829.    Elapsed: 14:10:04.\n",
            "  Batch 111,000  of  114,829.    Elapsed: 14:10:22.\n",
            "  Batch 111,040  of  114,829.    Elapsed: 14:10:40.\n",
            "  Batch 111,080  of  114,829.    Elapsed: 14:10:59.\n",
            "  Batch 111,120  of  114,829.    Elapsed: 14:11:17.\n",
            "  Batch 111,160  of  114,829.    Elapsed: 14:11:35.\n",
            "  Batch 111,200  of  114,829.    Elapsed: 14:11:54.\n",
            "  Batch 111,240  of  114,829.    Elapsed: 14:12:12.\n",
            "  Batch 111,280  of  114,829.    Elapsed: 14:12:30.\n",
            "  Batch 111,320  of  114,829.    Elapsed: 14:12:49.\n",
            "  Batch 111,360  of  114,829.    Elapsed: 14:13:07.\n",
            "  Batch 111,400  of  114,829.    Elapsed: 14:13:25.\n",
            "  Batch 111,440  of  114,829.    Elapsed: 14:13:44.\n",
            "  Batch 111,480  of  114,829.    Elapsed: 14:14:02.\n",
            "  Batch 111,520  of  114,829.    Elapsed: 14:14:21.\n",
            "  Batch 111,560  of  114,829.    Elapsed: 14:14:40.\n",
            "  Batch 111,600  of  114,829.    Elapsed: 14:14:58.\n",
            "  Batch 111,640  of  114,829.    Elapsed: 14:15:17.\n",
            "  Batch 111,680  of  114,829.    Elapsed: 14:15:35.\n",
            "  Batch 111,720  of  114,829.    Elapsed: 14:15:54.\n",
            "  Batch 111,760  of  114,829.    Elapsed: 14:16:12.\n",
            "  Batch 111,800  of  114,829.    Elapsed: 14:16:30.\n",
            "  Batch 111,840  of  114,829.    Elapsed: 14:16:49.\n",
            "  Batch 111,880  of  114,829.    Elapsed: 14:17:07.\n",
            "  Batch 111,920  of  114,829.    Elapsed: 14:17:26.\n",
            "  Batch 111,960  of  114,829.    Elapsed: 14:17:44.\n",
            "  Batch 112,000  of  114,829.    Elapsed: 14:18:02.\n",
            "  Batch 112,040  of  114,829.    Elapsed: 14:18:21.\n",
            "  Batch 112,080  of  114,829.    Elapsed: 14:18:39.\n",
            "  Batch 112,120  of  114,829.    Elapsed: 14:18:58.\n",
            "  Batch 112,160  of  114,829.    Elapsed: 14:19:16.\n",
            "  Batch 112,200  of  114,829.    Elapsed: 14:19:35.\n",
            "  Batch 112,240  of  114,829.    Elapsed: 14:19:53.\n",
            "  Batch 112,280  of  114,829.    Elapsed: 14:20:12.\n",
            "  Batch 112,320  of  114,829.    Elapsed: 14:20:31.\n",
            "  Batch 112,360  of  114,829.    Elapsed: 14:20:49.\n",
            "  Batch 112,400  of  114,829.    Elapsed: 14:21:08.\n",
            "  Batch 112,440  of  114,829.    Elapsed: 14:21:27.\n",
            "  Batch 112,480  of  114,829.    Elapsed: 14:21:45.\n",
            "  Batch 112,520  of  114,829.    Elapsed: 14:22:04.\n",
            "  Batch 112,560  of  114,829.    Elapsed: 14:22:23.\n",
            "  Batch 112,600  of  114,829.    Elapsed: 14:22:41.\n",
            "  Batch 112,640  of  114,829.    Elapsed: 14:23:00.\n",
            "  Batch 112,680  of  114,829.    Elapsed: 14:23:18.\n",
            "  Batch 112,720  of  114,829.    Elapsed: 14:23:37.\n",
            "  Batch 112,760  of  114,829.    Elapsed: 14:23:55.\n",
            "  Batch 112,800  of  114,829.    Elapsed: 14:24:14.\n",
            "  Batch 112,840  of  114,829.    Elapsed: 14:24:32.\n",
            "  Batch 112,880  of  114,829.    Elapsed: 14:24:51.\n",
            "  Batch 112,920  of  114,829.    Elapsed: 14:25:09.\n",
            "  Batch 112,960  of  114,829.    Elapsed: 14:25:28.\n",
            "  Batch 113,000  of  114,829.    Elapsed: 14:25:46.\n",
            "  Batch 113,040  of  114,829.    Elapsed: 14:26:05.\n",
            "  Batch 113,080  of  114,829.    Elapsed: 14:26:24.\n",
            "  Batch 113,120  of  114,829.    Elapsed: 14:26:42.\n",
            "  Batch 113,160  of  114,829.    Elapsed: 14:27:01.\n",
            "  Batch 113,200  of  114,829.    Elapsed: 14:27:19.\n",
            "  Batch 113,240  of  114,829.    Elapsed: 14:27:38.\n",
            "  Batch 113,280  of  114,829.    Elapsed: 14:27:56.\n",
            "  Batch 113,320  of  114,829.    Elapsed: 14:28:15.\n",
            "  Batch 113,360  of  114,829.    Elapsed: 14:28:33.\n",
            "  Batch 113,400  of  114,829.    Elapsed: 14:28:52.\n",
            "  Batch 113,440  of  114,829.    Elapsed: 14:29:10.\n",
            "  Batch 113,480  of  114,829.    Elapsed: 14:29:28.\n",
            "  Batch 113,520  of  114,829.    Elapsed: 14:29:47.\n",
            "  Batch 113,560  of  114,829.    Elapsed: 14:30:06.\n",
            "  Batch 113,600  of  114,829.    Elapsed: 14:30:24.\n",
            "  Batch 113,640  of  114,829.    Elapsed: 14:30:43.\n",
            "  Batch 113,680  of  114,829.    Elapsed: 14:31:01.\n",
            "  Batch 113,720  of  114,829.    Elapsed: 14:31:20.\n",
            "  Batch 113,760  of  114,829.    Elapsed: 14:31:38.\n",
            "  Batch 113,800  of  114,829.    Elapsed: 14:31:57.\n",
            "  Batch 113,840  of  114,829.    Elapsed: 14:32:15.\n",
            "  Batch 113,880  of  114,829.    Elapsed: 14:32:34.\n",
            "  Batch 113,920  of  114,829.    Elapsed: 14:32:52.\n",
            "  Batch 113,960  of  114,829.    Elapsed: 14:33:11.\n",
            "  Batch 114,000  of  114,829.    Elapsed: 14:33:29.\n",
            "  Batch 114,040  of  114,829.    Elapsed: 14:33:48.\n",
            "  Batch 114,080  of  114,829.    Elapsed: 14:34:06.\n",
            "  Batch 114,120  of  114,829.    Elapsed: 14:34:24.\n",
            "  Batch 114,160  of  114,829.    Elapsed: 14:34:43.\n",
            "  Batch 114,200  of  114,829.    Elapsed: 14:35:01.\n",
            "  Batch 114,240  of  114,829.    Elapsed: 14:35:20.\n",
            "  Batch 114,280  of  114,829.    Elapsed: 14:35:38.\n",
            "  Batch 114,320  of  114,829.    Elapsed: 14:35:57.\n",
            "  Batch 114,360  of  114,829.    Elapsed: 14:36:15.\n",
            "  Batch 114,400  of  114,829.    Elapsed: 14:36:34.\n",
            "  Batch 114,440  of  114,829.    Elapsed: 14:36:52.\n",
            "  Batch 114,480  of  114,829.    Elapsed: 14:37:11.\n",
            "  Batch 114,520  of  114,829.    Elapsed: 14:37:29.\n",
            "  Batch 114,560  of  114,829.    Elapsed: 14:37:48.\n",
            "  Batch 114,600  of  114,829.    Elapsed: 14:38:06.\n",
            "  Batch 114,640  of  114,829.    Elapsed: 14:38:26.\n",
            "  Batch 114,680  of  114,829.    Elapsed: 14:38:45.\n",
            "  Batch 114,720  of  114,829.    Elapsed: 14:39:03.\n",
            "  Batch 114,760  of  114,829.    Elapsed: 14:39:22.\n",
            "  Batch 114,800  of  114,829.    Elapsed: 14:39:41.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 14:39:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 0:32:06\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  114,829.    Elapsed: 0:00:19.\n",
            "  Batch    80  of  114,829.    Elapsed: 0:00:37.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-21-e09af3bddcfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# single value; the `.item()` function just returns the Python value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m# from the tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtotal_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbd116G8dry2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpA9bASAkYoF",
        "outputId": "9c2c1a1b-e842-45ed-c1c0-9cc665870d84"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.83</td>\n",
              "      <td>14:39:54</td>\n",
              "      <td>0:32:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.41         0.47           0.83      14:39:54         0:32:06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggdMVBDNkaCg",
        "outputId": "ee320e35-ad37-4b5f-fe86-7bd1779ea067"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dTlwipcknCZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTrbvhcol2L8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WIOhdePkm1U",
        "colab": {
          "referenced_widgets": [
            "3e4a428f4af8442e8e62723e86912c28"
          ]
        },
        "outputId": "98fc920b-6606-4973-c093-879e9267682e"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in tqdm(X_test):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        padding='max_length', \n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "# Create the DataLoader.\n",
        "# prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e4a428f4af8442e8e62723e86912c28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=96996.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KpFerNCkn-q",
        "colab": {
          "referenced_widgets": [
            "f6c30d5ab84a44019612ad69d10fa93c"
          ]
        },
        "outputId": "827adba0-9131-4f77-a25e-b43fda096c0e"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in tqdm(prediction_dataloader):\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 96,996 test sentences...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6c30d5ab84a44019612ad69d10fa93c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=12125.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C83CD4sxkrbg",
        "outputId": "2dc45c7c-e798-42d4-c7c6-2d56b61ea618"
      },
      "source": [
        "print(len(X_test), len(predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96996 12125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6kNFLmdk0PD",
        "outputId": "ae24cb78-bf44-4606-9ec2-fcde8fcc47de"
      },
      "source": [
        "pred = np.array([])\n",
        "for el in predictions:\n",
        "  pred = np.append(pred, el[:,1], axis=0)\n",
        "\n",
        "len(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH2eSnJduLgu",
        "outputId": "a134b566-4152-4fdc-d1e7-859c107580c2"
      },
      "source": [
        "pred[:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.54413056,  1.48203063,  1.48203063,  1.48203063, -2.50749898,\n",
              "        0.72748846,  1.48203063, -2.56993985,  1.48203063, -2.57356334,\n",
              "       -2.57347083,  1.48203063,  1.48203063, -2.55104661, -2.57108235,\n",
              "       -2.57215047,  1.48203063, -2.53483081, -2.39211774, -2.38202667,\n",
              "       -2.53483081, -2.56914878, -1.57004035, -2.35421348, -2.38605905,\n",
              "       -2.38605905, -2.57124257, -2.57333493,  0.53855199, -2.57100606,\n",
              "        0.53855199, -2.5726006 , -2.57234621,  0.53855199, -2.5730505 ,\n",
              "       -2.5723052 , -2.5643487 , -1.87705731, -2.56097007, -2.21519732,\n",
              "       -0.94997227, -2.57289696, -1.88028145, -1.69606876, -0.94997227,\n",
              "       -1.88028145, -1.37613451, -2.5715549 , -2.55786943,  1.49747467,\n",
              "       -2.41765428, -2.56927919, -2.56775928, -2.57188392, -2.57389188,\n",
              "       -2.39292574, -2.56224847, -1.93921006, -2.55776238, -2.55776238,\n",
              "       -2.54382896, -2.56224847, -2.56724906, -2.56719565, -2.20831561,\n",
              "       -2.56224847, -1.75298667, -2.57314539, -2.57292414, -2.54382896,\n",
              "       -2.56224847, -2.55776238, -2.57140136, -2.57314539, -2.56142068,\n",
              "       -1.61431754, -2.56978631, -2.57179165, -2.54637551, -2.57434106,\n",
              "       -2.24187136, -1.08076167, -2.44590569, -2.5742166 , -2.29168415,\n",
              "       -1.08076167, -2.56435895, -2.44590569, -2.53776217, -2.55961585,\n",
              "       -2.24187136, -2.57388568, -2.55107331, -2.54586911, -2.55168748,\n",
              "       -0.99389082, -1.08076167, -2.29168415, -1.08076167, -0.99389082])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7w6Z5aMk3hx",
        "outputId": "5858c804-1b6d-4433-f18f-60e49ed7d00a"
      },
      "source": [
        "import pandas as pd\n",
        "pd.Series(pred_edited).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    82601\n",
              "1    14395\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12ssMmGtk3PB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmP2QbZCmYI_"
      },
      "source": [
        "from  tqdm  import  tqdm \n",
        "import jsonlines\n",
        "def save_output(data, path):\n",
        "  res = []\n",
        "  cnt  = 0\n",
        "  with open('drive/MyDrive/rucos_test.jsonl', 'r', encoding='utf8') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "    for json_str in tqdm(json_list):\n",
        "      max = -10\n",
        "      item = json.loads(json_str)\n",
        "      text = item['passage']['text']\n",
        "      query = item['qas'][0]['query']\n",
        "      ans = item['passage']['entities']\n",
        "      for a in ans:\n",
        "        if data[cnt]>=max:\n",
        "          max=data[cnt]\n",
        "          d={\"idx\": item[\"idx\"],\n",
        "             \"text\": item[\"passage\"][\"text\"][a['start']:a['end']]\n",
        "              }\n",
        "        cnt+=1\n",
        "      \n",
        "      res.append(d)\n",
        "     # print(a)\n",
        "    with open(path, mode=\"w\") as file:\n",
        "      for line in sorted(res, key=lambda x: int(x.get(\"idx\"))):\n",
        "        line[\"idx\"] = int(line[\"idx\"])\n",
        "        file.write(f\"{json.dumps(line, ensure_ascii=False)}\\n\")\n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU28DST9mbqG",
        "colab": {
          "referenced_widgets": [
            "a6e167321de74d5388c276c0cfcc19dc"
          ]
        },
        "outputId": "0b699ead-f41c-48fe-ad4d-25bf79766899"
      },
      "source": [
        "save_output(pred, 'submission.jsonl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6e167321de74d5388c276c0cfcc19dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7257.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPtJIMonwpCr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZf1WGnawpCr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}